[
  {
    "objectID": "posts/2013_04_02_bats/index.html",
    "href": "posts/2013_04_02_bats/index.html",
    "title": "Bat cunnilingus and spurious results",
    "section": "",
    "text": "Thanks to my brother I became aware of an article about bat cunnilingus today (Maruthupandian and Marimuthu 2013). My brother, knowing how entertained I had been by a bat felating itself at Disney on my honeymoon, decided that this would be just the sort of article that I’d like. Knowing the kind of examples I put in my textbooks I suspect his email is the first of many. Anyway, this article suggests that male bats engage in cunnilingus with females. Female bats, that is. They have videos to prove it. Male bats like cunnilingus so much that they don’t just use it as foreplay, but they get stuck in afterwards as well. The article has two main findings:\n\nThe more that males (bats) engage in cunnilingus, the longer the duration of intercourse, \\(r\\) = .91 (see their Figure 1).\n\nThey tested this with a Pearson r, based on 8 observations (although each observation was the average of several data points I think – it’s not entirely clear how the authors came about these averages). They conclude that this behaviour may be due to sperm competition in that males sort of ‘clean out’ the area before they procreate. They argue that the longer intercourse duration supports this argument because longer duration = greater chance of paternity.\n\nThe more that males engage in pre-intercourse cunnilingus, the less they engage in post-intercourse cunnilingus, r = –.79 (see their Figure 2).\n\nThey again tested this with a Pearson r, based on 8 observations. They conclude “… the negative relationship between the duration of pre- and post-copulatory cunnilingus suggests the possibility of sperm competition. Thus, the male removes the sperm of competitors but apparently not its own – lick for longer before but less after copulation, if paternity uncertainty is high.”\nThere are several leaps of faith in their conclusions. Does longer duration necessarily imply greater chance of paternity? Also, if sperm competition is at the root of all of this then I’m not sure post coital cunilingus is really ever an adaptive strategy: consuming your own sperm hardly seems like the best method of impregnating your mate. Yes, I’m still talking about bats here, what you choose to do in your own free time is none of my business.\nEnough about Cunnilingus, what about Statistics?\nAnyway, I want to make a statistical point, not an evolutionary one. It struck me when looking at this article that finding 2 is probably spurious. Figure 2 looks very much like two outliers are making a relationship out of nothing. With only 8 observations they are likely to have a large impact. With 8 observations it is, of course, hard to say what’s an outlier and what isn’t; however, the figure was like a bat tongue to my brain: my juices were flowing. Fortunately, with so few observations we can approximate the data from the two figures. I emphasises that these are quick estimates of values based on the graphs and a ruler. We have three variables estimated from the paper: pre (pre-intercourse cunnilingus), post (post-intercourse cunnilingus), duration (duration of intercourse). We’re going to use R, if you don’t know how to use it then some imbecile called Andy Field has written a book on it that you could look at (Field, Miles, and Field 2012; Field 2025).\nLet’s load some packages that will be useful (if you don’t have them installed then install them) and input these approximate scores as shown below. They are displayed in Table 1.\n\nlibrary(WRS2) #wilcox robust functions\nlibrary(correlation)\nlibrary(boot)\nlibrary(tidyverse)\n\nbat &lt;- tibble(\n  pre = c(46, 50, 51, 52, 53, 53.5, 55, 59),\n  post = c(162, 140, 150, 140, 142, 138, 152, 122),\n  duration = c(14.4, 14.4, 14.9, 15.5, 15.4, 15.2, 15.3, 16.4)\n)\n\n\n\n\nTable 1: Approximation of data from Maruthupandian & Marimuthu (2013)\n\n\n\n\npre\npost\nduration\n\n\n\n46.0\n162\n14.4\n\n\n50.0\n140\n14.4\n\n\n51.0\n150\n14.9\n\n\n52.0\n140\n15.5\n\n\n53.0\n142\n15.4\n\n\n53.5\n138\n15.2\n\n\n55.0\n152\n15.3\n\n\n59.0\n122\n16.4\n\n\n\n\n\n\n\n\nNow lets replicate Figures 1 (see Figure 1) and 2 (see Figure 2) from the paper. As you can see the figures – more or less – replicate their data.\n\nggplot(data = bat, aes(x = pre, y = duration)) + \n  geom_point() +\n  stat_smooth(method = \"lm\") +\n  coord_cartesian(ylim = c(13, 18), xlim = c(44, 60)) +\n  theme_minimal()\n\n\n\n\n\n\nFigure 1: Replica of Maruthupandian & Marimuthu (2013) Figure 1\n\n\n\n\n\nggplot(data = bat, aes(x = pre, y = post)) + \n  geom_point() +\n  stat_smooth(method = \"lm\") +\n  coord_cartesian(ylim = c(85, 200), xlim = c(44, 60)) +\n  theme_minimal()\n\n\n\n\n\n\nFigure 2: Replica of Maruthupandian & Marimuthu (2013) Figure 2\n\n\n\n\nOK, let’s replicate their correlation coefficient estimates by executing:\n\ncorrelation(bat, p_adjust = \"none\")\n\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |     r |         95% CI |  t(6) |       p\n------------------------------------------------------------------\npre        |       post | -0.78 | [-0.96, -0.17] | -3.05 | 0.023* \npre        |   duration |  0.91 | [ 0.56,  0.98] |  5.30 | 0.002**\npost       |   duration | -0.75 | [-0.95, -0.10] | -2.79 | 0.032* \n\np-value adjustment method: none\nObservations: 8\n\n\nSo, we replicate the pre-intercourse cunnilingus (Pre) – duration correlation of .91 exactly (p= .002), and we more or less get the right value for the pre-post correlation: we get r = –.78 (p = .023) instead of -.79, but we’re within rounding error. So, it looks like our estimates of the raw data from the Figures in the article aren’t far off the real values at all. Just goes to show how useful graphs in papers can be for extracting the raw data. If I’m right and the data in Figure 2 are affected by the first and last case, we’d expect something different to happen if we calculate the correlation based on ranked scores (i.e. Spearman’s rho). Let’s try it:\n\ncorrelation(bat, method = \"spearman\", p_adjust = \"none\")\n\n# Correlation Matrix (spearman-method)\n\nParameter1 | Parameter2 |   rho |        95% CI |      S |      p\n-----------------------------------------------------------------\npre        |       post | -0.50 | [-0.90, 0.34] | 126.25 | 0.204 \npre        |   duration |  0.78 | [ 0.14, 0.96] |  18.61 | 0.023*\npost       |   duration | -0.51 | [-0.90, 0.32] | 127.01 | 0.195 \n\np-value adjustment method: none\nObservations: 8\n\n\nThe Pre-duration correlation has dropped from .91 to .78 (p = .023) but it’s still very strong. However, the pre-post correlation has changed fairly dramatically from -.79 to r = –.50 (p = .204) and is now not significant (although I wouldn’t want to read to much into that with an n = 8). What about if we try a robust correlation such as the percentile bend correlation described by Wilcox (2017)\n\npbcor(bat$pre, bat$post)\n\nCall:\npbcor(x = bat$pre, y = bat$post)\n\nRobust correlation coefficient: -0.3687\nTest statistic: -0.9714\np-value: 0.36884 \n\npbcor(bat$pre, bat$duration)\n\nCall:\npbcor(x = bat$pre, y = bat$duration)\n\nRobust correlation coefficient: 0.8522\nTest statistic: 3.9896\np-value: 0.0072 \n\n\nThe pre post correlation has changed dramatically from -.79 to r = –.37 (p = .369) and is now not significant (again I wouldn’t want to read to much into that with an n = 8, but it is now a much smaller effect than they’re reporting in the paper). The pre-duration correlation fares much better: it is still very strong and significant, r = .85 (p = .007). We could also try to estimate the population value of these two relationships by computing a robust confidence interval using bootstrapping. We’ll stick with Pearson r seeing as that’s the estimate that they used in the paper but you could try this with the other measures if you like.\nIn essence then, the true relationship between pre- and post-intercourse cunnilingus duration lies somewhere between about –1 and 0.6. In other words, it could be anything really, including zero.\n\nbootr &lt;-function(data, i){ \n  cor(data[i, 1], data[i, 2])\n  } \n\nbootprepost &lt;-boot(bat[1:2], bootr, 2000)\nboot.ci(bootprepost) \n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 2000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bootprepost)\n\nIntervals : \nLevel      Normal              Basic         \n95%   (-1.5951, -0.1754 )   (-2.0871, -0.5666 )  \n\nLevel     Percentile            BCa          \n95%   (-0.9927,  0.5278 )   (-0.9922,  0.5809 )  \nCalculations and Intervals on Original Scale\n\n\nFor the relationship between pre-intercourse bat cunnilingus and intercourse duration the true relationship is somewhere between r= .5 and .98. In other words, it’s likely to be – at the very worst – a strong and positive association.\n\nbootpreduration &lt;- boot(bat[c(1, 3)], bootr, 2000)\nboot.ci(bootpreduration)\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 2000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bootpreduration)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.6699,  1.1990 )   ( 0.8323,  1.2201 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.5954,  0.9832 )   ( 0.5306,  0.9805 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat does this tell us? Well, I’m primarily interested in using this as a demonstration of why it’s important to look at your data and to employ robust tests. I’m not trying to knock the research. Of course, in the process I am, inevitably, sort of knocking it. So, I think there are three messages here:\n\nTheir first finding that the more that males (bats) engage in cunnilingus, the longer the duration of intercourse is very solid. The population value could be less than the estimate they report, but it could very well be that large too. At the very worst it is still a strong association.\nThe less good news is that finding 2 (that the more that males engage in pre-intercourse cunnilingus, the less they engage in post-intercourse cunnilingus) is probably wrong. The best case scenario is that the finding is real but the authors have overestimated it. The worst case scenario is that the population effect is in the opposite direction to what the authors report, and there is, of course, a mid ground that there is simply no effect at all in the population (or one so small as to be not remotely important).\nIt’s also worth pointing out that the two extreme cases that have created this spurious result may in themselves be highly interesting observations. There may be important reasons why individual bats engage in unusually long or short bouts of cunnilingus (either pre or post intercourse) and finding out what factors affect this will be an interesting thing that the authors should follow up.\n\n\n\n\n\n\n\n\n\n\nReferences\n\nField, Andy P. 2025. Discovering Statistics Using R and RStudio. 2nd ed. London: Sage.\n\n\nField, Andy P., Jeremy N. V. Miles, and Zoe C. Field. 2012. Discovering Statistics Using R: And Sex and Drugs and Rock “n” Roll. London: Sage.\n\n\nMaruthupandian, Jayabalan, and Ganapathy Marimuthu. 2013. “Cunnilingus Apparently Increases Duration of Copulation in the Indian Flying Fox, Pteropus Giganteus.” Edited by R. Mark Brigham. PLoS ONE 8 (3): e59743. https://doi.org/10.1371/journal.pone.0059743.\n\n\nWilcox, Rand R. 2017. Introduction to Robust Estimation and Hypothesis Testing. 4th ed. Burlington, MA: Elsevier.\n\nCitationBibTeX citation:@online{field2013,\n  author = {Field, Andy},\n  title = {Bat Cunnilingus and Spurious Results},\n  date = {2013-04-02},\n  url = {https://profandyfield.com/posts/2013_04_02_bats/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2013. “Bat Cunnilingus and Spurious Results.”\nApril 2, 2013. https://profandyfield.com/posts/2013_04_02_bats/."
  },
  {
    "objectID": "posts/2015_09_28_mike_dean/index.html",
    "href": "posts/2015_09_28_mike_dean/index.html",
    "title": "The referee’s a …",
    "section": "",
    "text": "I’m a bit late on this particular bandwagon, but it’s a busy time what with the start of term and finishing writing textbook and all that. The textbook is also my excuse for having not written a blog for a year, well, that and the fact I rarely have anything interesting to say.\nAnyway, those of you who follow football (or soccer for our US friends) will know the flack that referees get. I am a regular at the stadium of the team I’ve supported1 since the age of 3 and like most football stadiums I regularly hear the chant of ‘The referee’s a wanker’ echoing around the ground. Referees have a tough job: the game is fast, often faster than they are, players can be a bit cheaty, and we have the benefit of TV replays which they (for some utterly inexplicable reason) do not. Nevertheless it’s annoying when they get stuff wrong.\n1 Incidentally, I’m very much of the opinion that people are perfectly entitled to support a different team to me, and that the football team you support isn’t a valid basis for any kind of negativity. If we all supported the same team it would be dull, and if everyone supported ‘my’ team, it’d be even harder for me to get tickets to games. So, you know, let’s be accepting of our differences and all that ….The more specific referee-related thing I often hear resonating around the particular stadium that I attend is ‘Oh dear me, Mike Dean is refereeing … he hates us quite passionately’ or something similar with a lot more swearing. This particular piece of folk wisdom reached dizzy new heights the weekend before last when he managed to ignore Diego Costa trying to superglue his hands to Laurent Koscielny’s face shortly before chest bumping him to the floor, and then sending Gabriel off for … well, I’m not really sure what. Indeed, the FA weren’t really sure what for either because they rescinded the red card and banned Costa for 3 matches. You can read the details here.\nSo, does Mike Dean really hate Arsenal? In another blog 7amkickoff tried to answer this question using data collated about Mike Dean. You can read it here. This blog has inspired me to go one step further and try to answer this question as a scientist would.\nHow does a scientist decide if Mike Dean really is a wanker?\nScientists try to work with scientific statements. ‘Mike Dean is a wanker’ may be the folklore at the Emirates, but it is not a scientific statement because we probably can’t agree on a working definition of what a wanker is (at least not in the refereeing sense). However, we can turn it into a scientific statement by changing the question to something like ‘Do arsenal lose more games when Mike Dean (MD) referees?’ This is what 7amkickoff tried to do. 7amkickoff presented data from 2009-2015 and concluded that ‘Arsenal’s win% in the Premier League since 2009 is 57% so a 24% win rate is quite anomalous’ (the 24% is the win rate under Dean). There are several problems with this simplistic view, a couple of them are:\n\nMD tends to referee Arsenal’s tougher games (opponents such as Chelsea, Manchester United and Manchester City), so we need to compare Arsenal’s win rate under MD to our win rate against only the same opponents as in the MD games. (In case you’re interested the full list of clubs is Birmingham, Blackburn, Burnley, C Palace, Charlton, Chelsea, Fulham, Man City, Man Utd, Newcastle, QPR, Stoke City, Tottenham, Watford, West Brom, West Ham, Wigan). If we compare against a broader set of opponents then it isn’t a fair comparison to MD: we are not comparing like for like.\nHow do we know that a win rate of 24% under MD isn’t statistically comparable to a win rate of 57%. They seem different, but couldn’t such a difference simply happen because of the usual random fluctuations in results? Or indeed because Arsenal are just bad at winning against ‘bigger’ teams and MD happens to officiate those games (see the point above)\n\nI’m going to use the same database as 7amkickoff and extend this analysis. I collected data from football-lineups.com for the past 10 years (2005-6 up to the Chelsea fixture on 19th Sept 2015). I am only looking at English Premier League (EPL) games. I have filtered the data to include only the opponents mentioned above, so we’ll get a fair comparison of Arsenal’s results under MD against their results against those same clubs when MD is not officiating. The data are here as a CSV file.\nA scientist essentially sets up two competing hypotheses. The first is that there is no effect of MD, that is Arsenal’s results under MD are exactly the same as under other referees. This is known as the null hypothesis. The second is the opposite: that there is an effect of MD, that is Arsenal’s results under MD are different compared to other referees. This is known as the alternative hypothesis. We can use statistical tests to compare these hypotheses.\nA frequentist approach\nTo grab the file into R and store in a tibble called arse, create a project in RStudio, put the data file in that project directory, and execute:\n\nlibrary(tidyverse)\narse &lt;- here::here(\"posts/2015_09_28_mike_dean/arsenal_md_results.csv\") |&gt;\n  read_csv() |&gt; \n  mutate(\n    MD = factor(MD, levels = 0:1, labels = c(\"Other\", \"MD\"))\n  )\n\nLet’s get a table of all EPL arsenal fixtures against the aforementioned teams since 2005, we get this, by running the following code in R:\n\nmd_tbl &lt;- xtabs(~MD + result, data = arse)\n\nTable 1 is a nice version of the resulting table.\n\n\n\nTable 1: Number of wins, losses and draws by Arsenal\n\n\n\n\n\nDraw\nLose\nWin\n\n\n\nOther\n33\n43\n115\n\n\nMD\n14\n11\n9\n\n\n\n\n\n\n\n\nOne way to test whether the profile of results is different for MD is to see whether there is a significant relationship between the variable MD vs Other and result. This test asks the question of whether the profile of draws to wins and loses is statistically different for MD than ‘other’. If we assume that games are independent events (which is a simplifying assumption because they won’t be) we can use a chi-square test. You can fit this model in R by running:\n\nlibrary(gmodels)\nCrossTable(md_tbl, fisher = TRUE, chisq = TRUE, sresid = TRUE, format = \"SPSS\")\n\n\n   Cell Contents\n|-------------------------|\n|                   Count |\n| Chi-square contribution |\n|             Row Percent |\n|          Column Percent |\n|           Total Percent |\n|            Std Residual |\n|-------------------------|\n\nTotal Observations in Table:  225 \n\n             | result \n          MD |     Draw  |     Lose  |      Win  | Row Total | \n-------------|-----------|-----------|-----------|-----------|\n       Other |       33  |       43  |      115  |      191  | \n             |    1.193  |    0.176  |    0.901  |           | \n             |   17.277% |   22.513% |   60.209% |   84.889% | \n             |   70.213% |   79.630% |   92.742% |           | \n             |   14.667% |   19.111% |   51.111% |           | \n             |   -1.092  |   -0.419  |    0.949  |           | \n-------------|-----------|-----------|-----------|-----------|\n          MD |       14  |       11  |        9  |       34  | \n             |    6.699  |    0.988  |    5.061  |           | \n             |   41.176% |   32.353% |   26.471% |   15.111% | \n             |   29.787% |   20.370% |    7.258% |           | \n             |    6.222% |    4.889% |    4.000% |           | \n             |    2.588  |    0.994  |   -2.250  |           | \n-------------|-----------|-----------|-----------|-----------|\nColumn Total |       47  |       54  |      124  |      225  | \n             |   20.889% |   24.000% |   55.111% |           | \n-------------|-----------|-----------|-----------|-----------|\n\n \nStatistics for All Table Factors\n\n\nPearson's Chi-squared test \n------------------------------------------------------------\nChi^2 =  15.01757     d.f. =  2     p =  0.0005482477 \n\n\n \nFisher's Exact Test for Count Data\n------------------------------------------------------------\nAlternative hypothesis: two.sided\np =  0.0005303779 \n\n \n       Minimum expected frequency: 7.102222 \n\n\nThe win rate under MD is 26.47% compared to 41.18% draws and 32.35% losses, under other referees it is 60.21%, 17.28% and 22.51% respectively. These are the comparable values to 7amkickoff but looking at 10 years and including only opponents that feature in MD games. The critical part of the output is the p = .0005. This is the probability that we would get the chi-square value we have IF the null hypothesis were true. In other words, if MD had no effect whatsoever on Arsenal’s results the probability of getting a test result of at least 15.12 would be 0.000548. In other words, very small indeed. Scientists do this sort of thing all of the time, and generally accept that if p is less than .05 then this supports the alternative hypothesis. That is we can assume it’s true. (In actual fact, although scientists do this they shouldn’t because this probability value tells us nothing about either hypothesis, but that’s another issue …) Therefore, by conventional scientific method, we would accept that the profile of results under MD is significantly different than under other referees. Looking at the values in the cells of the table, we can actually see that the profile is significantly worse under MD than other referees in comparable games. Statistically speaking, MD is a wanker (if you happen to support Arsenal).\nAs I said though, we made simplifying assumptions. Let’s look at the raw results, and this time factor in the fact that results with the same opponents will be more similar than results involving different opponents. That is, we can assume that Arsenal’s results against Chelsea will be more similar to each other than they will be to results against a different club like West Ham. What we do here is nest results within opponents. In doing so, we statistically model the fact that results against the same opposition will be similar to each other. This is known as a logistic multilevel model. What I am doing is predicting the outcome of winning the game (1 = win, 0 = not win) from whether MD refereed (1 = MD, 0 = other). I have fitted a random intercepts model, which says overall results will vary across different opponents, but also a random slopes model which entertains the possibility that the effect of MD might vary by opponent. The R code is this:\n\nlibrary(lme4)\nwin_ri&lt;-glmer(win ~ 1 + (1|Opponent), data = arse, family = binomial, na.action = na.exclude)\nwin_md&lt;-update(win_ri, .~. + MD)\nwin_rs&lt;-update(win_ri, .~ MD + (MD|Opponent))\nanova(win_ri, win_md, win_rs)\n\nData: arse\nModels:\nwin_ri: win ~ 1 + (1 | Opponent)\nwin_md: win ~ (1 | Opponent) + MD\nwin_rs: win ~ MD + (MD | Opponent)\n       npar    AIC    BIC  logLik deviance  Chisq Df Pr(&gt;Chisq)   \nwin_ri    2 302.41 309.24 -149.20   298.41                        \nwin_md    3 295.22 305.47 -144.61   289.22 9.1901  1   0.002433 **\nwin_rs    5 299.20 316.28 -144.60   289.20 0.0153  2   0.992396   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe summary of models shows that the one with the best fit is random intercepts and MD as a predictor. I can tell this because the model with MD as a predictor significantly improves the fit of the model (the p of 0.0024 is very small) but adding in the random slopes component does not improve the fit of the model hardly at all (because the p of 0.992 is very close to 1).\nLet’s look at the best fitting model (win_md):\n\nsummary(win_md)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: win ~ (1 | Opponent) + MD\n   Data: arse\n\n     AIC      BIC   logLik deviance df.resid \n   295.2    305.5   -144.6    289.2      222 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.6052 -0.7922  0.6046  0.7399  2.4786 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n Opponent (Intercept) 0.4614   0.6792  \nNumber of obs: 225, groups:  Opponent, 17\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)   0.5871     0.2512   2.337  0.01943 * \nMDMD         -1.2896     0.4427  -2.913  0.00358 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nMDMD -0.225\n\n\nThe important thing is whether the variable MD (which represents MD vs. other referees) is a ‘significant predictor’. Looking at the p-value of 0.00358,we can assess the probability that we would get a z-value at least as large (ignoring the minus sign) as -2.913 if the null hypothesis were true (i.e. if MD had no effect at all on Arsenal’s results). Again, because this value is less than 0.05, scientists would typically conclude that MD is a significant predictor of whether Arsenal win or not, even factoring in dependency between results when the opponent is the same. The value of the estimate (-1.2896) tells us about the strength and direction of the relationship and because our predictor variable is MD = 1, other = 0, and our outcome is win = 1 and no win = 0, and the value is negative it means that as MD increases (in other words as we move from having ‘other’ as a referee to having MD as a referee) the outcome decreases (that is, the probability of winning decreases). So, this analysis shows that MD significantly decreases the probability of Arsenal winning. The model is more complex but the conclusion is the same as the previous, simpler, model: statistically speaking, MD is a wanker (if you happen to support Arsenal).\nA Bayesian Approach\nThe frequentist approach above isn’t universally accepted because these probability values that I keep mentioning don’t allow us to test directly the plausibility of the null and alternative hypothesis. A different approach is to use a Bayes Factor. Bayes Factors quantify the ratio of the probability of the data under the alternative hypothesis relative to the null. A value of 1, therefore, means that the observed data are equally probable under the null and alternative hypotheses, values below 1 suggest that the data are more probable under the null hypotheses relative to the alternative. Bayes factors provide information about the probability of the data under the null hypothesis (relative to the alternative) whereas significance tests (as above) provide no evidence at all about the status of the null hypothesis. Bayes Factors are pretty easy to do using Richard Morey’s excellent BayesFactor package in R . There’s a lot more technical stuff to consider, which I won’t get into … for example, to do this properly we really need to set some prior believe in our hypothesis. However, Morey’s packages uses some default priors that represent relatively open minded beliefs (about MD in this case!). To get a Bayes Factor for our original contingency table you’d run:\n\nlibrary(BayesFactor)\nbayesMD = contingencyTableBF(md_tbl, sampleType = \"indepMulti\", fixedMargin = \"cols\")\nbayesMD\n\nBayes factor analysis\n--------------\n[1] Non-indep. (a=1) : 34.04903 ±0%\n\nAgainst denominator:\n  Null, independence, a = 1 \n---\nBayes factor type: BFcontingencyTable, independent multinomial\n\n\nThe resulting Bayes Factor of 34.05 is a lot bigger than 1. The fact it is bigger than 1 suggests that the probability of the data under the alternative hypothesis is 34 times greater then the probability of the data under the null. In other words, we should shift our prior beliefs towards the idea the MD is a wanker by a factor of about 34. Yet again, statistically speaking, MD is a wanker (if you happen to support Arsenal).\nConclusion\nThe aim of this blog is to take a tongue in cheek look at how we can apply statistics to a real-world question that vexes a great many people. (OK, the specific Mike Dean question only vexes Arsenal fans, but football fans worldwide are vexed by referees on a regular basis). With some publicly available data you can test these hypotheses, and reach conclusions based on data rather than opinion. That’s the beauty of statistical models.\nI’ll admit that to the casual reader this blog is going to be a lot more tedious than 7amkickoff’s. However, what I lack in readability I gain in applying some proper stats to the data. Whatever way you look at it, Mike Dean, statistically speaking does predict poorer outcomes for Arsenal. There could be any number of other explanations for these data, but you’d think that the FA might want to have a look at that. Arsenal’s results under Mike Dean are significantly different to under other referees, and these models show that this is more than simply the random fluctuations in results that happen with any sports team.\nOn a practical note, next time I’m at the emirates and someone says ‘Oh shit, it’s Mike Dean, he hates us …’ I will be able to tell him or her confidently that statistically speaking they have a point … well, at least in the sense that Arsenal are significantly more likely to lose when he referees!\n\n\nCitationBibTeX citation:@online{field2015,\n  author = {Field, Andy},\n  title = {The Referee’s a ...},\n  date = {2015-09-28},\n  url = {https://profandyfield.com/posts/2015_09_28_mike_dean/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2015. “The Referee’s a ...” September 28,\n2015. https://profandyfield.com/posts/2015_09_28_mike_dean/."
  },
  {
    "objectID": "pages/pubs.html",
    "href": "pages/pubs.html",
    "title": "Publications",
    "section": "",
    "text": "Brewin, C. R., & Field, A. P. (2024). Meta-analysis shows trauma memories in Posttraumatic Stress Disorder lack coherence: a response to Taylor et al. (2022). Clinical Psychological Science, , 21677026241240456. doi: 10.1177/21677026241240456\n\n\nDaly, J., De Luca, F., Berens, S. C., Field, A. P., Rusted, J. M., & Bird, C. M. (2024). The effect of apolipoprotein E genotype on spatial processing in humans: A meta-analysis and systematic review. Cortex, 177, 268-284. doi: 10.1016/j.cortex.2024.05.006\n\n\n\n\nMathur, S., Michelson, D., Shetty, T., Patel, V., & Field, A. P. (2023). Knowledge of problem solving (KOPS) scale: design and evaluation of a digitally administered competence measure for a common practice element in task-shared youth mental health interventions. Journal of Technology in Behavioral Science, , . doi: 10.1007/s41347-023-00356-9\n\n\nMathur, S., Weiss, H. A., Neuman, M., Field, A. P., Leurent, B., Shetty, T., J, J. E., Nair, P., Mathews, R., Malik, K., Michelson, D., & Patel, V. (2023). Coach-supported versus self-guided digital training course for a problem-solving psychological intervention for nonspecialists: protocol for a pre-post nested randomized controlled trial. JMIR Research Protocols, 12, e41981. doi: 10.2196/41981\n\n\nMathur, S., Weiss, H. A., Neuman, M., Leurent, B., Field, A. P., Shetty, T., J., J. E., Nair, P., Mathews, R., Malik, K., Michelson, D., & Patel, V. (2023). Developing knowledge-based psychotherapeutic competencies in non-specialist providers: A pre-post study with a nested randomised controlled trial of a coach-supported versus self-guided digital training course for a problem-solving psychological intervention in India. Cambridge Prisms: Global Mental Health, 10, e87. doi: 10.1017/gmh.2023.81\n\n\nTerry, J., Ross, R. M., Nagy, T., Salgado, M., Garrido-Vásquez, P., Sarfo, J. O., Cooper, S., Buttner, A. C., Lima, T. J. S., Öztürk, İ., Akay, N., Santos, F. H., Artemenko, C., Copping, L. T., Elsherif, M. M., Milovanović, I., Cribbie, R. A., Drushlyak, M. G., Swainston, K., Shou, Y., Leongómez, J. D., Palena, N., Abidin, F. A., Reyes-Rodríguez, M. F., He, Y., Abraham, J., Vatakis, A., Jankowsky, K., Schmidt, S. N. L., Grimm, E., González, D., Schmid, P., Ferreira, R. A., Rozgonjuk, D., Özhan, N., O’Connor, P. A., Zsido, A. N., Stiglic, G., Rhodes, D., Rodríguez, C., Ropovik, I., Enea, V., Nurwanti, R., Estudillo, A. J., Beribisky, N., Himawan, K. K., Geven, L. M., Hoogmoed, A. H., Bret, A., Chapman, J. E., Alter, U., Flack, Z. M., Hanna, D., Soltanlou, M., Banik, G., Adamkovič, M., Ven, S. H. G., Mosbacher, J. A., Şen, H. H., Anderson, J. R., Batashvili, M., Groot, K., Parker, M. O., Helmy, M., Ostroha, M. M., Gilligan-Lee, K. A., Egara, F. O., Barwood, M. J., Thomas, K., McMahon, G., Griffin, S. M., Nuerk, H., Counsell, A., Lindemann, O., Van Rooy, D., Wege, T. E., Lewis, J. E., Aczel, B., Monaghan, C., Al-Hoorie, A. H., Huber, J. F., Yapan, S., Garrido Vásquez, M. E., Callea, A., Ergiyen, T., Clay, J. M., Mertens, G., Topçu, F., Tutlu, M. G., Täht, K., Mikkor, K., Caso, L., Karner, A., Storm, M. M. C., Daroczy, G., Zein, R. A., Greco, A., Buchanan, E. M., Schmid, K., Hunt, T. E., De keersmaecker, J., Branney, P. E., Randell, J., Clark, O. J., Steltenpohl, C. N., Malu, B., Tekeş, B., Ramis, T., Agrigoroaei, S., Badcock, N. A., McAloney-Kocaman, K., Semenikhina, O. V., Graf, E. W., Lea, C., Ogba, K. T. U., Guppy, F. M., Warhurst, A. C., Lindsay, S., Al Khateeb, A., Scharnowski, F., Kwaadsteniet, L., Francis, K. B., Lecompte, M., Webster, L. A. D., Morsanyi, K., Forwood, S. E., Walters, E. R., Tip, L. K., Wagge, J. R., Lai, H. Y., Crossland, D. S., Darda, K. M., Flack, T. R., Leviston, Z., Brolly, M., Hills, S. P., Collins, E., Roberts, A. J., Cheung, W., Leonard, S., Verschuere, B., Stanley, S. K., Xenidou-Dervou, I., Ghasemi, O., Liew, T., Ansari, D., Guilaran, J., Penny, S. G., Bahnmueller, J., Hand, C. J., Rahajeng, U. W., Peterburg, D., Takacs, Z. K., Platow, M. J., & Field, A. P. (2023). Data from an International Multi-Centre Study of Statistics and Mathematics Anxieties and Related Variables in University Students (the SMARVUS Dataset). Journal of Open Psychology Data, , . doi: 10.5334/jopd.80\n\n\nVallorani, A., Gunther, K. E., Anaya, B., Burris, J. L., Field, A. P., LoBue, V., Buss, K. A., & Pérez-Edgar, K. (2023). Assessing bidirectional relations between infant temperamental negative affect, maternal anxiety symptoms and infant affect-biased attention across the first 24-months of life.. Developmental Psychology, 59, 364-376. doi: 10.1037/dev0001479\n\n\n\n\nBurris, J. L., Reider, L. B., Oleas, D. S., Gunther, K. E., Buss, K. A., Pérez‐Edgar, K., Field, A. P., & LoBue, V. (2022). Moderating effects of environmental stressors on the development of attention to threat in infancy. Developmental Psychobiology, 64, . doi: 10.1002/dev.22241\n\n\nReider, L. B., Bierstedt, L., Burris, J. L., Vallorani, A., Gunther, K., Buss, K. A., Pérez‐Edgar, K., Field, A. P., & LoBue, V. (2022). Developmental patterns of affective attention across the first 2 years of life. Child Development, 93, e607 - e621. doi: 10.1111/cdev.13831\n\n\nSladekova, M., Webb, L. E. A., & Field, A. P. (2022). Estimating the change in meta-analytic effect size estimates after the application of publication bias adjustment methods.. Psychological Methods, , . doi: 10.1037/met0000470\n\n\nTaylor, H., Cavanagh, K., Field, A. P., & Strauss, C. (2022). Do healthcare workers need a little Headspace? Findings from a multi-site definitive randomised controlled trial of an unguided digital mindfulness-based self-help intervention to reduce healthcare worker stress in comparison to an active control.. Journal of Medical Internet Research, 10, e31744. doi: 10.2196/31744\n\n\n\n\nDavey, G. C. L., Meeten, F., & Field, A. P. (2021). What’s worrying our students? Increasing worry levels over two decades and a new measure of student worry frequency and domains. Cognitive Therapy and Research, , . doi: 10.1007/s10608-021-10270-0\n\n\nPérez-Edgar, K., LoBue, V., Buss, K. A., Field, A. P., Team, T. L., Reider, L., Burris, J., Oleas, D., Zhou, A., Thomas, C., Leigh, S., Ostlund, B., Anaya, B., Gunther, K., Vallorani, A., Youatt, E., Smith, C., Promagan, N., Brown, K., Bierstedt, L., Pinzon, C., Revilla, K., Sarquez, M., Rajasekera, P., Fareedi, E., Kershner, A., McDoniel, M., Fu, X., Morales, S., MacNeill, L., Auday, E., Ermanni, B., Tucker, D., & Metcalf, K. (2021). Study Protocol: Longitudinal Attention and Temperament Study. Frontiers in Psychiatry, 12, . doi: 10.3389/fpsyt.2021.656958\n\n\n\n\nField, A. P., Lester, K. J., Cartwright-Hatton, S., Harold, G. T., Shaw, D. S., Natsuaki, M. N., Ganiban, J. M., Reiss, D., Neiderhiser, J. M., & Leve, L. D. (2020). Maternal and paternal influences on childhood anxiety symptoms: A genetically sensitive comparison. Journal of Applied Developmental Psychology, 68, 101123. doi: 10.1016/j.appdev.2020.101123\n\n\nDu, J., & Field, A. P. (2020). Adolescents’ peer friendship and anxiety and depression among first-generation immigrant BAME families in the uk. Genealogy, 4, 62. doi: 10.3390/genealogy4020062\n\n\nEvans, D., Gaysina, D., & Field, A. P. (2020). Internalizing symptoms and working memory as predictors of mathematical attainment trajectories across the primary–secondary education transition. Royal Society Open Science, 7, 191433. doi: 10.1098/rsos.191433\n\n\nEvans, D., & Field, A. P. (2020). Maths attitudes, school affect and teacher characteristics as predictors of maths attainment trajectories in primary and secondary education. Royal Society Open Science, 7: 200975, 25. doi: https://doi.org/10.1098/rsos.200975\n\n\nEvans, D., & Field, A. P. (2020). Predictors of mathematical attainment trajectories across the primary-to-secondary education transition: parental factors and the home environment. Royal Society Open Science, 7, 200422. doi: 10.1098/rsos.200422\n\n\nLoBue, V., Reider, L. B., Kim, E., Burris, J. L., Oleas, D. S., Buss, K. A., Pérez‐Edgar, K., & Field, A. P. (2020). The importance of using multiple outcome measures in infant research. Infancy, 25, 420-437. doi: 10.1111/infa.12339\n\n\n\n\n\nField, A. P., Evans, D., Bloniewski, T., & Kovas, Y. (2019). Predicting maths anxiety from mathematical achievement across the transition from primary to secondary education. Royal Society Open Science, 6, 191459. doi: 10.1098/rsos.191459\n\n\nBurris, J. L., Buss, K., LoBue, V., Pérez-Edgar, K., & Field, A. P. (2019). Biased attention to threat and anxiety: On taking a developmental approach. Journal of Experimental Psychopathology, 10, 204380871986071. doi: 10.1177/2043808719860717\n\n\nSchweizer, S., Satpute, A. B., Atzil, S., Field, A. P., Hitchcock, C., Black, M., Barrett, L. F., & Dalgleish, T. (2019). The impact of affective information on working memory: A pair of meta-analytic reviews of behavioral and neuroimaging evidence. Psychological Bulletin, 145, 566-609. doi: 10.1037/bul0000193\n\n\nWard, J., Field, A. P., & Chin, T. (2019). A meta-analysis of memory ability in synaesthesia. Memory, 0, 1-14. doi: 10.1080/09658211.2019.1646771\n\n\nWhale, R., Fialho, R., Field, A. P., Campbell, G., Tibble, J., Harrison, N. A., & Rolt, M. (2019). Factor analyses differentiate clinical phenotypes of idiopathic and interferon-alpha-induced depression. Brain, Behavior, and Immunity, 80, 519-524. doi: 10.1016/j.bbi.2019.04.035\n\n\n\n\nAyers, S., Crawley, R., Button, S., Thornton, A., Field, A. P., Flood, C., Lee, S., Eagle, A., Bradley, R., Moore, D., Gyte, G., & Smith, H. (2018). Evaluation of expressive writing for postpartum health: a randomised controlled trial. Journal of Behavioral Medicine, 41, 614-626. doi: 10.1007/s10865-018-9970-3\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., Cesarini, D., Chambers, C. D., Clyde, M., Cook, T. D., Boeck, P. D., Dienes, Z., Dreber, A., Easwaran, K., Efferson, C., Fehr, E., Fidler, F., Field, A. P., Forster, M., George, E. I., Gonzalez, R., Goodman, S., Green, E., Green, D. P., Greenwald, A. G., Hadfield, J. D., Hedges, L. V., Held, L., Ho, T. H., Hoijtink, H., Hruschka, D. J., Imai, K., Imbens, G., Ioannidis, J. P. A., Jeon, M., Jones, J. H., Kirchler, M., Laibson, D., List, J., Little, R., Lupia, A., Machery, E., Maxwell, S. E., McCarthy, M., Moore, D. A., Morgan, S. L., Munafó, M., Nakagawa, S., Nyhan, B., Parker, T. H., Pericchi, L., Perugini, M., Rouder, J., Rousseau, J., Savalei, V., Schönbrodt, F. D., Sellke, T., Sinclair, B., Tingley, D., Zandt, T. V., Vazire, S., Watts, D. J., Winship, C., Wolpert, R. L., Xie, Y., Young, C., Zinman, J., & Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2, 6-10. doi: 10.1038/s41562-017-0189-z\n\n\nCartwright‐Hatton, S., Ewing, D., Dash, S., Hughes, Z., Thompson, E. J., Hazell, C. M., Field, A. P., & Startup, H. (2018). Preventing family transmission of anxiety: Feasibility RCT of a brief intervention for parents. British Journal of Clinical Psychology, 57, 351-366. doi: 10.1111/bjc.12177\n\n\nCrawley, R., Ayers, S., Button, S., Thornton, A., Field, A. P., Lee, S., Eagle, A., Bradley, R., Moore, D., Gyte, G., & Smith, H. (2018). Feasibility and acceptability of expressive writing with postpartum women: a randomised controlled trial. BMC Pregnancy and Childbirth, 18, 75. doi: 10.1186/s12884-018-1703-7\n\n\nEvans, D., Borriello, G. A., & Field, A. P. (2018). A review of the academic and psychological impact of the transition to secondary education. Frontiers in Psychology, 9, . doi: 10.3389/fpsyg.2018.01482\n\n\nFlack, Z. M., Field, A. P., & Horst, J. S. (2018). The effects of shared storybook reading on word learning: A meta-analysis. Developmental Psychology, 54, 1334-1346. doi: http://dx.doi.org.ezproxy.sussex.ac.uk/10.1037/dev0000512\n\n\nGreenwood, K., Alford, K., O’Leary, I., Peters, E., Hardy, A., Cavanagh, K., Field, A. P., Visser, R., Fowler, D., Davies, M., Papamichail, A., & Garety, P. (2018). The U&I study: study protocol for a feasibility randomised controlled trial of a pre-cognitive behavioural therapy digital ‘informed choice’ intervention to improve attitudes towards uptake and implementation of CBT for psychosis. Trials, 19, 644. doi: 10.1186/s13063-018-3023-7\n\n\nReynolds, G., Field, A. P., & Askew, C. (2018). Reductions in Children’s Vicariously Learnt Avoidance and Heart Rate Responses Using Positive Modeling. Journal of Clinical Child & Adolescent Psychology, 47, 555-568. doi: 10.1080/15374416.2016.1138410\n\n\nStuijfzand, S., Creswell, C., Field, A. P., Pearcey, S., & Dodd, H. (2018). Research Review: Is anxiety associated with negative interpretations of ambiguity in children and adolescents? A systematic review and meta-analysis. Journal of Child Psychology and Psychiatry, 59, 1127-1142. doi: 10.1111/jcpp.12822\n\n\n\n\nField, A. P., & Wilcox, R. R. (2017). Robust statistical methods: A primer for clinical psychology and experimental psychopathology researchers. Behaviour Research and Therapy, 98, 19-38. doi: 10.1016/j.brat.2017.05.013\n\n\nBrown, T. A., & Field, A. P. (2017). Best practice guidelines for modern statistical methods in applied clinical research: Introduction to the Special Section. Behaviour Research and Therapy, 98, 1-3. doi: 10.1016/j.brat.2017.06.008\n\n\nReynolds, G., Field, A. P., & Askew, C. (2017). Learning to fear a second-order stimulus following vicarious learning. Cognition and Emotion, 31, 572-579. doi: 10.1080/02699931.2015.1116978\n\n\n\n\nAskew, C., Reynolds, G., Fielding-Smith, S., & Field, A. P. (2016). Inhibition of vicariously learned fear in children using positive modeling and prior exposure. J Abnorm Psychol, 125, 279-291.\n\n\nKruijt, A., Field, A. P., & Fox, E. (2016). Capturing dynamics of biased attention: are new attention variability measures the way forward?. Plos One, 11, e0166600. doi: 10.1371/journal.pone.0166600\n\n\nPearce, L. J., & Field, A. P. (2016). The impact of “scary” TV and film on children’s internalizing emotions: a meta-analysis. Human Communication Research, 42, 98-121. doi: doi:10.1111/hcre.12069\n\n\nWhite, L. K., Suway, J. G., Pine, D. S., Field, A. P., Lester, K. J., Muris, P., Bar-Haim, Y., & Fox, N. A. (2016). The cognitive and emotional effects of cognitive bias modification in interpretations in behaviorally inhibited youth. Journal of Experimental Psychopathology, 7, 499-510. doi: 10.5127/jep.053615\n\n\n\n\nField, A. P. (2015). Dread returns to Mega-Silly One. Health Psychology Review, 9, 15-20. doi: 10.1080/17437199.2013.879198\n\n\nBosmans, G., Dujardin, A., Field, A. P., Salemink, E., & Vasey, M. W. (2015). Fear acquisition through maternal verbal threat information in middle childhood: the role of children’s attachment to mother. Parenting-Science and Practice, 15, 288-294. doi: 10.1080/15295192.2015.1053336\n\n\nEwing, D. L., Monsen, J. J., Thompson, E. J., Cartwright-Hatton, S., & Field, A. (2015). A meta-analysis of transdiagnostic cognitive behavioural therapy in the treatment of child and young person anxiety disorders. Behavioural and Cognitive Psychotherapy, 43, 562-577. doi: 10.1017/s1352465813001094\n\n\nLester, K. J., Lisk, S. C., Mikita, N., Mitchell, S., Huijding, J., Rinck, M., & Field, A. P. (2015). The effects of verbal information and approach-avoidance training on children’s fear-related responses. Journal of Behavior Therapy and Experimental Psychiatry, 48, 40-49. doi: 10.1016/j.jbtep.2015.01.008\n\n\nReynolds, G., Field, A. P., & Askew, C. (2015). Preventing the development of observationally learnt fears in children by devaluing the model’s negative response. Journal of Abnormal Child Psychology, 43, 1355-1367. doi: 10.1007/s10802-015-0004-0\n\n\nSmith, H. E., Jones, C. J., Hankins, M., Field, A., Theadom, A., Bowskill, R., Horne, R., & Frew, A. J. (2015). The effects of expressive writing on lung function, quality of life, medication use, and symptoms in adults with asthma: a randomized controlled trial. Psychosomatic Medicine, 77, 429-437. doi: 10.1097/psy.0000000000000166\n\n\nWoodhouse, S., Ayers, S., & Field, A. P. (2015). The relationship between adult attachment style and post-traumatic stress symptoms: A meta-analysis. Journal Of Anxiety Disorders, 35, 103-117. doi: 10.1016/j.janxdis.2015.07.002\n\n\n\n\nReynolds, G., Field, A. P., & Askew, C. (2014). Effect of vicarious fear learning on children’s heart rate responses and attentional bias for novel animals.. Emotion, 14, 995-1006. doi: 10.1037/a0037225\n\n\n\n\nField, Z. C., & Field, A. P. (2013). How trait anxiety, interpretation bias and memory affect acquired fear in children learning about new animals. Emotion, 13, 409-423. doi: 10.1037/a0031147\n\n\nAskew, C., Dunne, G., Özdil, Z., Reynolds, G., & Field, A. P. (2013). Stimulus fear-relevance and the vicarious learning pathway to childhood fears.. Emotion, 13, 915-925. doi: 10.1037/a0032714\n\n\nHanrahan, F., Field, A. P., Jones, F. W., & Davey, G. C. L. (2013). A meta-analysis of cognitive therapy for worry in generalized anxiety disorder. Clin Psychol Rev, 33, 120-32. doi: 10.1016/j.cpr.2012.10.008\n\n\nUgland, C. C., Dyson, B. J., & Field, A. P. (2013). An ERP study of the interaction between verbal information and conditioning pathways to fear. Biol Psychol, 92, 69-81. doi: 10.1016/j.biopsycho.2012.02.003\n\n\n\n\nGrist, R. M., & Field, A. P. (2012). The mediating effect of cognitive development on children’s worry elaboration. J Behav Ther Exp Psychiatry, 43, 801-7. doi: 10.1016/j.jbtep.2011.11.002\n\n\nLester, K. J., Field, A. P., & Cartwright-Hatton, S. (2012). Maternal anxiety and cognitive biases towards threat in their own and their child’s environment. Journal of Family Psychology, 26, 756-66. doi: 10.1037/a0029711\n\n\nTrickey, D., Siddaway, A. P., Meiser-Stedman, R., Serpell, L., & Field, A. P. (2012). A meta-analysis of risk factors for post-traumatic stress disorder in children and adolescents. Clin Psychol Rev, 32, 122-38. doi: 10.1016/j.cpr.2011.12.001\n\n\n\n\nField, A. P., & Wright, D. B. (2011). A primer on using multilevel models in clinical and experimental psychopathology research.. Journal of Experimental Psychopathology, 2, 271-293. doi: 10.5127/jep.013711\n\n\nBroeren, S., Lester, K. J., Muris, P., & Field, A. P. (2011). They are afraid of the animal, so therefore I am too: Influence of peer modeling on fear beliefs and approach-avoidance behaviors towards animals in typically developing children. Behaviour Research and Therapy, 49, 50-57. doi: 10.1016/j.brat.2010.11.001\n\n\nBroeren, S., Muris, P., Bouwmeester, S., Field, A. P., & Voerman, J. S. (2011). Processing biases for emotional faces in 4- to 12-year-old non-clinical children: An exploratory study of developmental patterns and relationships with social anxiety and behavioral inhibition. Journal of Experimental Psychopathology, 2, 454-474. doi: 10.5127/jep.016611\n\n\nCartwright-Hatton, S., McNally, D., Field, A. P., Rust, S., Laskey, B., Dixon, C., Gallagher, B., Harrington, R., Miller, C., Pemberton, K., Symes, W., White, C., & Woodham, A. (2011). A new parenting-based group intervention for young anxious children: results of a randomized controlled trial. Journal of the American Academy of Child and Adolescent Psychiatry, 50, 242-251. doi: 10.1016/j.jaac.2010.12.015\n\n\nCreswell, C., Shildrick, S., & Field, A. P. (2011). Interpretation of ambiguity in children: a prospective study of associations with anxiety and parental interpretations. Journal of Child and Family Studies, 20, 240-250. doi: 10.1007/s10826-010-9390-7\n\n\nHuijding, J., Muris, P., Lester, K. J., Field, A. P., & Joosse, G. (2011). Training children to approach or avoid novel animals: Effects on self-reported attitudes and fear beliefs and information-seeking behaviors. Behaviour Research and Therapy, 49, 606-613. doi: 10.1016/j.brat.2011.06.005\n\n\nLester, K. J., Field, A. P., & Muris, P. (2011). Experimental modification of interpretation bias regarding social and animal fear in children. Journal Of Anxiety Disorders, 25, 697-705. doi: 10.1016/j.janxdis.2011.03.006\n\n\nLester, K. J., Field, A. P., & Muris, P. (2011). Experimental modification of interpretation bias about animal fear in young children: Effects on cognition, avoidance behaviour, anxiety vulnerability and physiological responding.. Journal of Clinical Child and Adolescent Psychology, 40, 864-877. doi: 10.1080/15374416.2011.618449\n\n\nPurkis, H. M., Lester, K. J., & Field, A. P. (2011). But what about the empress of Racnoss? The allocation of attention to spiders and doctor who in a visual search task is predicted by fear and expertise. Emotion, 11, 1484-1488. doi: 10.1037/a0024415\n\n\nWright, D. B., London, K., & Field, A. P. (2011). Using bootstrap estimation and the plug-in principle for clinical psychology data. Journal of Experimental Psychopathology, 2, 252–270. doi: doi:10.5127/jep.013611\n\n\n\n\nField, A. P., & Gillett, R. (2010). How to do a meta-analysis. British Journal of Mathematical & Statistical Psychology, 63, 665-694. doi: 10.1348/000711010x502733\n\n\nField, A. P., & Lester, K. J. (2010). Is there room for ‘development’ in developmental models of information processing biases to threat in children and adolescents?. Clinical Child and Family Psychology Review, 13, 315-332. doi: 10.1007/s10567-010-0078-8\n\n\nKelly, V. L., Barker, H., Field, A. P., Wilson, C., & Reynolds, S. (2010). Can Rachman’s indirect pathways be used to un-learn fear? A prospective paradigm to test whether children’s fears can be reduced using positive information and modelling a non-anxious response. Behaviour Research and Therapy, 48, 164-170. doi: 10.1016/j.brat.2009.10.002\n\n\nLester, K. J., Seal, K., Nightingale, Z. C., & Field, A. P. (2010). Are children’s own interpretations of ambiguous situations based on how they perceive their mothers have interpreted ambiguous situations for them in the past?. Journal Of Anxiety Disorders, 24, 102-108. doi: 10.1016/j.janxdis.2009.09.004\n\n\nMuris, P., & Field, A. P. (2010). The role of verbal threat information in the development of childhood fear. “Beware the Jabberwock!”. Clinical Child and Family Psychology Review, 13, 129-150. doi: 10.1007/s10567-010-0064-1\n\n\nSawyer, A., Ayers, S., & Field, A. P. (2010). Posttraumatic growth and adjustment among individuals with cancer or HIV/AIDS: A meta-analysis. Clinical Psychology Review, 30, 436-447. doi: 10.1016/j.cpr.2010.02.004\n\n\n\n\n\nField, A. (2009). Can humour make students love statistics?. Psychologist, 22, 210–213.\n\n\nField, A. P., & Nightingale, Z. C. (2009). What if Little Albert had escaped?. Clinical Child Psychology and Psychiatry, 14, 343-351.\n\n\nField, A. P., & Price-Evans, K. (2009). Temperament moderates the effect of the verbal threat information pathway on children’s heart rate responses to novel animals. Behaviour Research and Therapy, 47, 431-436. doi: 10.1016/j.brat.2009.01.020\n\n\nHuijding, J., Field, A. P., De Houwer, J., Vandenbosch, K., Rinck, M., & Oeveren, M. (2009). A behavioral route to dysfunctional representations: The effects of training approach or avoidance tendencies towards novel animals in children. Behaviour Research and Therapy, 47, 471-477. doi: 10.1016/j.brat.2009.02.011\n\n\nLester, K. J., Field, A. P., Oliver, S., & Cartwright-Hatton, S. (2009). Do anxious parents interpretive biases towards threat extend into their child’s environment?. Behaviour Research and Therapy, 47, 170-174. doi: 10.1016/j.brat.2008.11.005\n\n\nMuris, P., Rassin, E., Mayer, B., Smeets, G., Huijding, J., Remmerswaal, D., & Field, A. P. (2009). Effects of verbal information on fear-related reasoning biases in children. Behav Res Ther, 47, 206-214. doi: Doi 10.1016/J.Brat.2008.12.002\n\n\nWright, D. B., & Field, A. P. (2009). Giving your data the bootstrap. Psychologist, 22, 412-413.\n\n\n\n\nField, A. P., Cartwright-Hatton, S., Reynolds, S., & Creswell, C. (2008). Future directions for child anxiety theory and treatment. Cognition & Emotion, 22, 385-394. doi: 10.1080/02699930701842270\n\n\nField, A. P., Lascelles, K. R. R., Lester, K. J., Askew, C., & Davey, G. C. L. (2008). Evaluative conditioning: missing, presumed dead. Netherlands Journal of Psychology, 64, 46-64. doi: 10.1007/BF03076407\n\n\nField, A. P., Lawson, J., & Banerjee, R. (2008). The verbal threat information pathway to fear in children: The longitudinal effects on fear cognitions and the immediate effects on avoidance behavior. Journal of Abnormal Psychology, 117, 214-224. doi: 10.1037/0021-843x.117.1.214\n\n\nField, A. P., & Cartwright-Hatton, S. (2008). Shared and unique cognitive factors in social anxiety. International Journal of Cognitive Therapy, 1, 206-222. doi: 10.1521/ijct.2008.1.3.206\n\n\nField, A. P., & Lawson, J. (2008). The verbal information pathway to fear and subsequent causal learning in children. Cognition & Emotion, 22, 459-479. doi: 10.1080/02699930801886532\n\n\nAskew, C., Kessock-Philip, H., & Field, A. P. (2008). What happens when verbal threat information and vicarious learning combine?. Behavioural and Cognitive Psychotherapy, 36, 491-505. doi: 10.1017/s1352465808004402\n\n\nAskew, C., & Field, A. P. (2008). The vicarious learning pathway to fear 40 years on. Clinical Psychology Review, 28, 1249-1265. doi: 10.1016/j.cpr.2008.05.003\n\n\nCartwright-Hatton, S., Field, A., Creswell, C., & Reynolds, S. (2008). Research into anxiety of childhood: playing catch-up (to olympic standard). Behavioural and Cognitive Psychotherapy, 36, 377-378. doi: 10.1017/s1352465808004566\n\n\nMuris, P., & Field, A. P. (2008). Distorted cognition and pathological anxiety in children and adolescents. Cognition & Emotion, 22, 395-421. doi: 10.1080/02699930701843450\n\n\nPrice-Evans, K., & Field, A. P. (2008). A neglectful parenting style moderates the effect of the verbal threat information pathway on children’s heart rate responses to novel animals. Behavioural and Cognitive Psychotherapy, 36, 473-482. doi: 10.1017/s1352465808004396\n\n\n\n\nField, A. P., Ball, J. E., Kawycz, N. J., & Moore, H. (2007). Parent-child relationships and the verbal information pathway to fear in children: Two preliminary experiments. Behavioural and Cognitive Psychotherapy, 35, 473-486. doi: 10.1017/s1352465807003736\n\n\nField, A. P., & Schorah, H. (2007). The verbal information pathway to fear and heart rate changes in children. Journal of Child Psychology and Psychiatry, 48, 1088-1093. doi: 10.1111/j.1469-7610.2007.01772.x\n\n\nField, A. P., & Storksen-Coulson, H. (2007). The interaction of pathways to fear in childhood anxiety: A preliminary study. Behaviour Research and Therapy, 45, 3051-3059. doi: 10.1016/j.brat.2007.09.001\n\n\nAskew, C., & Field, A. P. (2007). Vicarious learning and the development of fears in childhood. Behaviour Research and Therapy, 45, 2616-2627. doi: 10.1016/j.brat.2007.06.008\n\n\nBrewin, C. R., Kleiner, J. S., Vasterling, J. J., & Field, A. P. (2007). Memory for emotionally neutral information in posttraumatic stress disorder: A meta-analytic investigation. Journal of Abnormal Psychology, 116, 448-463. doi: 10.1037/0021-843x.116.3.448\n\n\nLawson, J., Banerjee, R., & Field, A. P. (2007). The effects of verbal information on children’s fear beliefs about social situations. Behaviour Research and Therapy, 45, 21-37. doi: 10.1016/j.brat.2006.01.007\n\n\nMiles, J. N. V., & Field, A. P. (2007). Perspectives on significance testing.. The Irish Journal of Psychology, 28, 13-26.\n\n\n\n\nField, A. P. (2006). The behavioral inhibition system and the verbal information pathway to children’s fears. Journal of Abnormal Psychology, 115, 742-752. doi: 10.1037/0021-843x.115.4.742\n\n\nField, A. P. (2006). I don’t like it because it eats sprouts: Conditioning preferences in children. Behaviour Research and Therapy, 44, 439-455. doi: 10.1016/j.brat.2005.03.006\n\n\nField, A. P. (2006). Is conditioning a useful framework for understanding the development and treatment of phobias?. Clinical Psychology Review, 26, 857-875. doi: 10.1016/j.cpr.2005.05.010\n\n\nField, A. P. (2006). Watch out for the beast: Fear information and attentional bias in children. Journal of Clinical Child and Adolescent Psychology, 35, 431-439. doi: 10.1207/s15374424jccp3503_8\n\n\nPincus, T., Vogel, S., Burton, A. K., Santos, R., & Field, A. P. (2006). Fear avoidance and prognosis in back pain - A systematic review and synthesis of current evidence. Arthritis and Rheumatism, 54, 3999-4010. doi: 10.1002/art.22273\n\n\n\n\nField, A. P. (2005). Is the meta-analysis of correlation coefficients accurate when population correlations vary?. Psychological Methods, 10, 444-467. doi: 10.1037/1082-989x.10.4.444\n\n\nField, A. P., & Moore, A. C. (2005). Dissociating the effects of attention and contingency awareness on evaluative conditioning effects in the visual paradigm. Cognition & Emotion, 19, 217-243. doi: 10.1080/02699930441000292\n\n\nDe Houwer, J., Baeyens, F., & Field, A. P. (2005). Associative learning of likes and dislikes: Some current controversies and possible ways forward. Cognition & Emotion, 19, 161-174. doi: 10.1080/02699930441000265\n\n\n\n\nField, A. P., & Morgan, J. (2004). Post-event processing and the retrieval of autobiographical memories in socially anxious individuals. Journal Of Anxiety Disorders, 18, 647-663. doi: 10.1016/j.janxdis.2003.08.004\n\n\nAndrea, H., Beurskens, A., Kant, I. J., Davey, G. C. L., Field, A. P., & Schayck, C. P. (2004). The relation between pathological worrying and fatigue in a working population. Journal of Psychosomatic Research, 57, 399-407. doi: 10.1016/j.jpsychores.2003.09.013\n\n\nPincus, T., Williams, A. C. D., Vogel, S., & Field, A. P. (2004). The development and testing of the Depression, Anxiety, and Positive Outlook Scale (DAPOS). Pain, 109, 181-188.\n\n\n\n\nField, A. P. (2003). Can meta-analysis be trusted?. Psychologist, 16, 642-645.\n\n\nField, A. P. (2003). The problems in using Fixed-effects models of meta-analysis on real-world data. Understanding Statistics, 2, 77-96.\n\n\nField, A. P., Hamilton, S. J., Knowles, K. A., & Plews, E. L. (2003). Fear information and social phobic beliefs in children: a prospective paradigm and preliminary results. Behaviour Research and Therapy, 41, 113-123. doi: Pii s0005-7967(02)00050-5 10.1016/s0005-7967(02)00050-5\n\n\nField, A. P., & Lawson, J. (2003). Fear information and the development of fears during childhood: effects on implicit fear responses and behavioural avoidance. Behaviour Research and Therapy, 41, 1277-1293. doi: 10.1016/s0005-7967(03)00034-2\n\n\nDavey, G. C. L., Startup, H. M., Zara, A., MacDonald, C. B., & Field, A. P. (2003). The perseveration of checking thoughts and mood–as–input hypothesis. Journal of Behavior Therapy and Experimental Psychiatry, 34, 141-160. doi: 10.1016/S0005-7916(03)00035-1\n\n\n\n\nPincus, T., Burton, A. K., Vogel, S., & Field, A. P. (2002). A systematic review of psychological factors as predictors of chronicity/disability in prospective cohorts of low back pain. Spine (Phila Pa 1976), 27, E109-20.\n\n\n\n\nField, A. P. (2001). Meta-analysis of correlation coefficients: A Monte Carlo comparison of fixed- and random-effects methods. Psychological Methods, 6, 161-180. doi: 10.1037/1082-989x.6.2.161\n\n\nField, A. P. (2001). When all is still concealed: Are we closer to understanding the mechanisms underlying evaluative conditioning?. Consciousness and Cognition, 10, 559-566. doi: 10.1006/ccog.2001.0529\n\n\nField, A. P., Argyris, N. G., & Knowles, K. A. (2001). Who’s afraid of the big bad wolf: a prospective paradigm to test Rachman’s indirect pathways in children. Behaviour Research and Therapy, 39, 1259-1276. doi: 10.1016/s0005-7967(00)00080-2\n\n\n\n\nField, A. P. (2000). Evaluative conditioning is Pavlovian conditioning: Issues of definition, measurement, and the theoretical importance of contingency awareness. Consciousness and Cognition, 9, 41-49.\n\n\nField, A. P. (2000). I like it, but I’m not sure why: Can evaluative conditioning occur without conscious awareness?. Consciousness and Cognition, 9, 13-36. doi: 10.1006/ccog.1999.0402\n\n\nField, A. P. (2000). Research methodology in the social, behavioural and life sciences.. British Journal of Mathematical & Statistical Psychology, 53, 329-330.\n\n\nDavey, G. C. L., & Field, A. P. (2000). The “benefit” of Pavlovian conditioning - performance models, hidden costs, and innovation. Behavioral and Brain Sciences, 23, 253-+. doi: 10.1017/s0140525x00272439\n\n\n\n\n\nField, A. P., & Davey, G. C. L. (1999). Reevaluating evaluative conditioning: A nonassociative explanation of conditioning effects in the visual evaluative conditioning paradigm. Journal of Experimental Psychology-Animal Behavior Processes, 25, 211-224. doi: 10.1037/0097-7403.25.2.211\n\n\n\n\nField, A. P. (1998). A bluffer’s guide to sphericity. Newsletter of the Mathematical, Statistical and Computing Section of the British Psychological Society, 6, 13-22.\n\n\nField, A. P., & Davey, G. C. L. (1998). Evaluative conditioning: Arti-fact or -fiction? A reply to Baeyens, de Houwer, Vansteenwegen, and Eelen (1998). Learning and Motivation, 29, 475-491. doi: 10.1006/lmot.1998.1006\n\n\n\n\nField, A. P., & Davey, G. C. L. (1997). Conceptual conditioning: Evidence for an artifactual account of evaluative learning. Learning and Motivation, 28, 446-464. doi: 10.1006/lmot.1997.0980"
  },
  {
    "objectID": "pages/pubs.html#journal-articles",
    "href": "pages/pubs.html#journal-articles",
    "title": "Publications",
    "section": "",
    "text": "Brewin, C. R., & Field, A. P. (2024). Meta-analysis shows trauma memories in Posttraumatic Stress Disorder lack coherence: a response to Taylor et al. (2022). Clinical Psychological Science, , 21677026241240456. doi: 10.1177/21677026241240456\n\n\nDaly, J., De Luca, F., Berens, S. C., Field, A. P., Rusted, J. M., & Bird, C. M. (2024). The effect of apolipoprotein E genotype on spatial processing in humans: A meta-analysis and systematic review. Cortex, 177, 268-284. doi: 10.1016/j.cortex.2024.05.006\n\n\n\n\nMathur, S., Michelson, D., Shetty, T., Patel, V., & Field, A. P. (2023). Knowledge of problem solving (KOPS) scale: design and evaluation of a digitally administered competence measure for a common practice element in task-shared youth mental health interventions. Journal of Technology in Behavioral Science, , . doi: 10.1007/s41347-023-00356-9\n\n\nMathur, S., Weiss, H. A., Neuman, M., Field, A. P., Leurent, B., Shetty, T., J, J. E., Nair, P., Mathews, R., Malik, K., Michelson, D., & Patel, V. (2023). Coach-supported versus self-guided digital training course for a problem-solving psychological intervention for nonspecialists: protocol for a pre-post nested randomized controlled trial. JMIR Research Protocols, 12, e41981. doi: 10.2196/41981\n\n\nMathur, S., Weiss, H. A., Neuman, M., Leurent, B., Field, A. P., Shetty, T., J., J. E., Nair, P., Mathews, R., Malik, K., Michelson, D., & Patel, V. (2023). Developing knowledge-based psychotherapeutic competencies in non-specialist providers: A pre-post study with a nested randomised controlled trial of a coach-supported versus self-guided digital training course for a problem-solving psychological intervention in India. Cambridge Prisms: Global Mental Health, 10, e87. doi: 10.1017/gmh.2023.81\n\n\nTerry, J., Ross, R. M., Nagy, T., Salgado, M., Garrido-Vásquez, P., Sarfo, J. O., Cooper, S., Buttner, A. C., Lima, T. J. S., Öztürk, İ., Akay, N., Santos, F. H., Artemenko, C., Copping, L. T., Elsherif, M. M., Milovanović, I., Cribbie, R. A., Drushlyak, M. G., Swainston, K., Shou, Y., Leongómez, J. D., Palena, N., Abidin, F. A., Reyes-Rodríguez, M. F., He, Y., Abraham, J., Vatakis, A., Jankowsky, K., Schmidt, S. N. L., Grimm, E., González, D., Schmid, P., Ferreira, R. A., Rozgonjuk, D., Özhan, N., O’Connor, P. A., Zsido, A. N., Stiglic, G., Rhodes, D., Rodríguez, C., Ropovik, I., Enea, V., Nurwanti, R., Estudillo, A. J., Beribisky, N., Himawan, K. K., Geven, L. M., Hoogmoed, A. H., Bret, A., Chapman, J. E., Alter, U., Flack, Z. M., Hanna, D., Soltanlou, M., Banik, G., Adamkovič, M., Ven, S. H. G., Mosbacher, J. A., Şen, H. H., Anderson, J. R., Batashvili, M., Groot, K., Parker, M. O., Helmy, M., Ostroha, M. M., Gilligan-Lee, K. A., Egara, F. O., Barwood, M. J., Thomas, K., McMahon, G., Griffin, S. M., Nuerk, H., Counsell, A., Lindemann, O., Van Rooy, D., Wege, T. E., Lewis, J. E., Aczel, B., Monaghan, C., Al-Hoorie, A. H., Huber, J. F., Yapan, S., Garrido Vásquez, M. E., Callea, A., Ergiyen, T., Clay, J. M., Mertens, G., Topçu, F., Tutlu, M. G., Täht, K., Mikkor, K., Caso, L., Karner, A., Storm, M. M. C., Daroczy, G., Zein, R. A., Greco, A., Buchanan, E. M., Schmid, K., Hunt, T. E., De keersmaecker, J., Branney, P. E., Randell, J., Clark, O. J., Steltenpohl, C. N., Malu, B., Tekeş, B., Ramis, T., Agrigoroaei, S., Badcock, N. A., McAloney-Kocaman, K., Semenikhina, O. V., Graf, E. W., Lea, C., Ogba, K. T. U., Guppy, F. M., Warhurst, A. C., Lindsay, S., Al Khateeb, A., Scharnowski, F., Kwaadsteniet, L., Francis, K. B., Lecompte, M., Webster, L. A. D., Morsanyi, K., Forwood, S. E., Walters, E. R., Tip, L. K., Wagge, J. R., Lai, H. Y., Crossland, D. S., Darda, K. M., Flack, T. R., Leviston, Z., Brolly, M., Hills, S. P., Collins, E., Roberts, A. J., Cheung, W., Leonard, S., Verschuere, B., Stanley, S. K., Xenidou-Dervou, I., Ghasemi, O., Liew, T., Ansari, D., Guilaran, J., Penny, S. G., Bahnmueller, J., Hand, C. J., Rahajeng, U. W., Peterburg, D., Takacs, Z. K., Platow, M. J., & Field, A. P. (2023). Data from an International Multi-Centre Study of Statistics and Mathematics Anxieties and Related Variables in University Students (the SMARVUS Dataset). Journal of Open Psychology Data, , . doi: 10.5334/jopd.80\n\n\nVallorani, A., Gunther, K. E., Anaya, B., Burris, J. L., Field, A. P., LoBue, V., Buss, K. A., & Pérez-Edgar, K. (2023). Assessing bidirectional relations between infant temperamental negative affect, maternal anxiety symptoms and infant affect-biased attention across the first 24-months of life.. Developmental Psychology, 59, 364-376. doi: 10.1037/dev0001479\n\n\n\n\nBurris, J. L., Reider, L. B., Oleas, D. S., Gunther, K. E., Buss, K. A., Pérez‐Edgar, K., Field, A. P., & LoBue, V. (2022). Moderating effects of environmental stressors on the development of attention to threat in infancy. Developmental Psychobiology, 64, . doi: 10.1002/dev.22241\n\n\nReider, L. B., Bierstedt, L., Burris, J. L., Vallorani, A., Gunther, K., Buss, K. A., Pérez‐Edgar, K., Field, A. P., & LoBue, V. (2022). Developmental patterns of affective attention across the first 2 years of life. Child Development, 93, e607 - e621. doi: 10.1111/cdev.13831\n\n\nSladekova, M., Webb, L. E. A., & Field, A. P. (2022). Estimating the change in meta-analytic effect size estimates after the application of publication bias adjustment methods.. Psychological Methods, , . doi: 10.1037/met0000470\n\n\nTaylor, H., Cavanagh, K., Field, A. P., & Strauss, C. (2022). Do healthcare workers need a little Headspace? Findings from a multi-site definitive randomised controlled trial of an unguided digital mindfulness-based self-help intervention to reduce healthcare worker stress in comparison to an active control.. Journal of Medical Internet Research, 10, e31744. doi: 10.2196/31744\n\n\n\n\nDavey, G. C. L., Meeten, F., & Field, A. P. (2021). What’s worrying our students? Increasing worry levels over two decades and a new measure of student worry frequency and domains. Cognitive Therapy and Research, , . doi: 10.1007/s10608-021-10270-0\n\n\nPérez-Edgar, K., LoBue, V., Buss, K. A., Field, A. P., Team, T. L., Reider, L., Burris, J., Oleas, D., Zhou, A., Thomas, C., Leigh, S., Ostlund, B., Anaya, B., Gunther, K., Vallorani, A., Youatt, E., Smith, C., Promagan, N., Brown, K., Bierstedt, L., Pinzon, C., Revilla, K., Sarquez, M., Rajasekera, P., Fareedi, E., Kershner, A., McDoniel, M., Fu, X., Morales, S., MacNeill, L., Auday, E., Ermanni, B., Tucker, D., & Metcalf, K. (2021). Study Protocol: Longitudinal Attention and Temperament Study. Frontiers in Psychiatry, 12, . doi: 10.3389/fpsyt.2021.656958\n\n\n\n\nField, A. P., Lester, K. J., Cartwright-Hatton, S., Harold, G. T., Shaw, D. S., Natsuaki, M. N., Ganiban, J. M., Reiss, D., Neiderhiser, J. M., & Leve, L. D. (2020). Maternal and paternal influences on childhood anxiety symptoms: A genetically sensitive comparison. Journal of Applied Developmental Psychology, 68, 101123. doi: 10.1016/j.appdev.2020.101123\n\n\nDu, J., & Field, A. P. (2020). Adolescents’ peer friendship and anxiety and depression among first-generation immigrant BAME families in the uk. Genealogy, 4, 62. doi: 10.3390/genealogy4020062\n\n\nEvans, D., Gaysina, D., & Field, A. P. (2020). Internalizing symptoms and working memory as predictors of mathematical attainment trajectories across the primary–secondary education transition. Royal Society Open Science, 7, 191433. doi: 10.1098/rsos.191433\n\n\nEvans, D., & Field, A. P. (2020). Maths attitudes, school affect and teacher characteristics as predictors of maths attainment trajectories in primary and secondary education. Royal Society Open Science, 7: 200975, 25. doi: https://doi.org/10.1098/rsos.200975\n\n\nEvans, D., & Field, A. P. (2020). Predictors of mathematical attainment trajectories across the primary-to-secondary education transition: parental factors and the home environment. Royal Society Open Science, 7, 200422. doi: 10.1098/rsos.200422\n\n\nLoBue, V., Reider, L. B., Kim, E., Burris, J. L., Oleas, D. S., Buss, K. A., Pérez‐Edgar, K., & Field, A. P. (2020). The importance of using multiple outcome measures in infant research. Infancy, 25, 420-437. doi: 10.1111/infa.12339\n\n\n\n\n\nField, A. P., Evans, D., Bloniewski, T., & Kovas, Y. (2019). Predicting maths anxiety from mathematical achievement across the transition from primary to secondary education. Royal Society Open Science, 6, 191459. doi: 10.1098/rsos.191459\n\n\nBurris, J. L., Buss, K., LoBue, V., Pérez-Edgar, K., & Field, A. P. (2019). Biased attention to threat and anxiety: On taking a developmental approach. Journal of Experimental Psychopathology, 10, 204380871986071. doi: 10.1177/2043808719860717\n\n\nSchweizer, S., Satpute, A. B., Atzil, S., Field, A. P., Hitchcock, C., Black, M., Barrett, L. F., & Dalgleish, T. (2019). The impact of affective information on working memory: A pair of meta-analytic reviews of behavioral and neuroimaging evidence. Psychological Bulletin, 145, 566-609. doi: 10.1037/bul0000193\n\n\nWard, J., Field, A. P., & Chin, T. (2019). A meta-analysis of memory ability in synaesthesia. Memory, 0, 1-14. doi: 10.1080/09658211.2019.1646771\n\n\nWhale, R., Fialho, R., Field, A. P., Campbell, G., Tibble, J., Harrison, N. A., & Rolt, M. (2019). Factor analyses differentiate clinical phenotypes of idiopathic and interferon-alpha-induced depression. Brain, Behavior, and Immunity, 80, 519-524. doi: 10.1016/j.bbi.2019.04.035\n\n\n\n\nAyers, S., Crawley, R., Button, S., Thornton, A., Field, A. P., Flood, C., Lee, S., Eagle, A., Bradley, R., Moore, D., Gyte, G., & Smith, H. (2018). Evaluation of expressive writing for postpartum health: a randomised controlled trial. Journal of Behavioral Medicine, 41, 614-626. doi: 10.1007/s10865-018-9970-3\n\n\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E., Berk, R., Bollen, K. A., Brembs, B., Brown, L., Camerer, C., Cesarini, D., Chambers, C. D., Clyde, M., Cook, T. D., Boeck, P. D., Dienes, Z., Dreber, A., Easwaran, K., Efferson, C., Fehr, E., Fidler, F., Field, A. P., Forster, M., George, E. I., Gonzalez, R., Goodman, S., Green, E., Green, D. P., Greenwald, A. G., Hadfield, J. D., Hedges, L. V., Held, L., Ho, T. H., Hoijtink, H., Hruschka, D. J., Imai, K., Imbens, G., Ioannidis, J. P. A., Jeon, M., Jones, J. H., Kirchler, M., Laibson, D., List, J., Little, R., Lupia, A., Machery, E., Maxwell, S. E., McCarthy, M., Moore, D. A., Morgan, S. L., Munafó, M., Nakagawa, S., Nyhan, B., Parker, T. H., Pericchi, L., Perugini, M., Rouder, J., Rousseau, J., Savalei, V., Schönbrodt, F. D., Sellke, T., Sinclair, B., Tingley, D., Zandt, T. V., Vazire, S., Watts, D. J., Winship, C., Wolpert, R. L., Xie, Y., Young, C., Zinman, J., & Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2, 6-10. doi: 10.1038/s41562-017-0189-z\n\n\nCartwright‐Hatton, S., Ewing, D., Dash, S., Hughes, Z., Thompson, E. J., Hazell, C. M., Field, A. P., & Startup, H. (2018). Preventing family transmission of anxiety: Feasibility RCT of a brief intervention for parents. British Journal of Clinical Psychology, 57, 351-366. doi: 10.1111/bjc.12177\n\n\nCrawley, R., Ayers, S., Button, S., Thornton, A., Field, A. P., Lee, S., Eagle, A., Bradley, R., Moore, D., Gyte, G., & Smith, H. (2018). Feasibility and acceptability of expressive writing with postpartum women: a randomised controlled trial. BMC Pregnancy and Childbirth, 18, 75. doi: 10.1186/s12884-018-1703-7\n\n\nEvans, D., Borriello, G. A., & Field, A. P. (2018). A review of the academic and psychological impact of the transition to secondary education. Frontiers in Psychology, 9, . doi: 10.3389/fpsyg.2018.01482\n\n\nFlack, Z. M., Field, A. P., & Horst, J. S. (2018). The effects of shared storybook reading on word learning: A meta-analysis. Developmental Psychology, 54, 1334-1346. doi: http://dx.doi.org.ezproxy.sussex.ac.uk/10.1037/dev0000512\n\n\nGreenwood, K., Alford, K., O’Leary, I., Peters, E., Hardy, A., Cavanagh, K., Field, A. P., Visser, R., Fowler, D., Davies, M., Papamichail, A., & Garety, P. (2018). The U&I study: study protocol for a feasibility randomised controlled trial of a pre-cognitive behavioural therapy digital ‘informed choice’ intervention to improve attitudes towards uptake and implementation of CBT for psychosis. Trials, 19, 644. doi: 10.1186/s13063-018-3023-7\n\n\nReynolds, G., Field, A. P., & Askew, C. (2018). Reductions in Children’s Vicariously Learnt Avoidance and Heart Rate Responses Using Positive Modeling. Journal of Clinical Child & Adolescent Psychology, 47, 555-568. doi: 10.1080/15374416.2016.1138410\n\n\nStuijfzand, S., Creswell, C., Field, A. P., Pearcey, S., & Dodd, H. (2018). Research Review: Is anxiety associated with negative interpretations of ambiguity in children and adolescents? A systematic review and meta-analysis. Journal of Child Psychology and Psychiatry, 59, 1127-1142. doi: 10.1111/jcpp.12822\n\n\n\n\nField, A. P., & Wilcox, R. R. (2017). Robust statistical methods: A primer for clinical psychology and experimental psychopathology researchers. Behaviour Research and Therapy, 98, 19-38. doi: 10.1016/j.brat.2017.05.013\n\n\nBrown, T. A., & Field, A. P. (2017). Best practice guidelines for modern statistical methods in applied clinical research: Introduction to the Special Section. Behaviour Research and Therapy, 98, 1-3. doi: 10.1016/j.brat.2017.06.008\n\n\nReynolds, G., Field, A. P., & Askew, C. (2017). Learning to fear a second-order stimulus following vicarious learning. Cognition and Emotion, 31, 572-579. doi: 10.1080/02699931.2015.1116978\n\n\n\n\nAskew, C., Reynolds, G., Fielding-Smith, S., & Field, A. P. (2016). Inhibition of vicariously learned fear in children using positive modeling and prior exposure. J Abnorm Psychol, 125, 279-291.\n\n\nKruijt, A., Field, A. P., & Fox, E. (2016). Capturing dynamics of biased attention: are new attention variability measures the way forward?. Plos One, 11, e0166600. doi: 10.1371/journal.pone.0166600\n\n\nPearce, L. J., & Field, A. P. (2016). The impact of “scary” TV and film on children’s internalizing emotions: a meta-analysis. Human Communication Research, 42, 98-121. doi: doi:10.1111/hcre.12069\n\n\nWhite, L. K., Suway, J. G., Pine, D. S., Field, A. P., Lester, K. J., Muris, P., Bar-Haim, Y., & Fox, N. A. (2016). The cognitive and emotional effects of cognitive bias modification in interpretations in behaviorally inhibited youth. Journal of Experimental Psychopathology, 7, 499-510. doi: 10.5127/jep.053615\n\n\n\n\nField, A. P. (2015). Dread returns to Mega-Silly One. Health Psychology Review, 9, 15-20. doi: 10.1080/17437199.2013.879198\n\n\nBosmans, G., Dujardin, A., Field, A. P., Salemink, E., & Vasey, M. W. (2015). Fear acquisition through maternal verbal threat information in middle childhood: the role of children’s attachment to mother. Parenting-Science and Practice, 15, 288-294. doi: 10.1080/15295192.2015.1053336\n\n\nEwing, D. L., Monsen, J. J., Thompson, E. J., Cartwright-Hatton, S., & Field, A. (2015). A meta-analysis of transdiagnostic cognitive behavioural therapy in the treatment of child and young person anxiety disorders. Behavioural and Cognitive Psychotherapy, 43, 562-577. doi: 10.1017/s1352465813001094\n\n\nLester, K. J., Lisk, S. C., Mikita, N., Mitchell, S., Huijding, J., Rinck, M., & Field, A. P. (2015). The effects of verbal information and approach-avoidance training on children’s fear-related responses. Journal of Behavior Therapy and Experimental Psychiatry, 48, 40-49. doi: 10.1016/j.jbtep.2015.01.008\n\n\nReynolds, G., Field, A. P., & Askew, C. (2015). Preventing the development of observationally learnt fears in children by devaluing the model’s negative response. Journal of Abnormal Child Psychology, 43, 1355-1367. doi: 10.1007/s10802-015-0004-0\n\n\nSmith, H. E., Jones, C. J., Hankins, M., Field, A., Theadom, A., Bowskill, R., Horne, R., & Frew, A. J. (2015). The effects of expressive writing on lung function, quality of life, medication use, and symptoms in adults with asthma: a randomized controlled trial. Psychosomatic Medicine, 77, 429-437. doi: 10.1097/psy.0000000000000166\n\n\nWoodhouse, S., Ayers, S., & Field, A. P. (2015). The relationship between adult attachment style and post-traumatic stress symptoms: A meta-analysis. Journal Of Anxiety Disorders, 35, 103-117. doi: 10.1016/j.janxdis.2015.07.002\n\n\n\n\nReynolds, G., Field, A. P., & Askew, C. (2014). Effect of vicarious fear learning on children’s heart rate responses and attentional bias for novel animals.. Emotion, 14, 995-1006. doi: 10.1037/a0037225\n\n\n\n\nField, Z. C., & Field, A. P. (2013). How trait anxiety, interpretation bias and memory affect acquired fear in children learning about new animals. Emotion, 13, 409-423. doi: 10.1037/a0031147\n\n\nAskew, C., Dunne, G., Özdil, Z., Reynolds, G., & Field, A. P. (2013). Stimulus fear-relevance and the vicarious learning pathway to childhood fears.. Emotion, 13, 915-925. doi: 10.1037/a0032714\n\n\nHanrahan, F., Field, A. P., Jones, F. W., & Davey, G. C. L. (2013). A meta-analysis of cognitive therapy for worry in generalized anxiety disorder. Clin Psychol Rev, 33, 120-32. doi: 10.1016/j.cpr.2012.10.008\n\n\nUgland, C. C., Dyson, B. J., & Field, A. P. (2013). An ERP study of the interaction between verbal information and conditioning pathways to fear. Biol Psychol, 92, 69-81. doi: 10.1016/j.biopsycho.2012.02.003\n\n\n\n\nGrist, R. M., & Field, A. P. (2012). The mediating effect of cognitive development on children’s worry elaboration. J Behav Ther Exp Psychiatry, 43, 801-7. doi: 10.1016/j.jbtep.2011.11.002\n\n\nLester, K. J., Field, A. P., & Cartwright-Hatton, S. (2012). Maternal anxiety and cognitive biases towards threat in their own and their child’s environment. Journal of Family Psychology, 26, 756-66. doi: 10.1037/a0029711\n\n\nTrickey, D., Siddaway, A. P., Meiser-Stedman, R., Serpell, L., & Field, A. P. (2012). A meta-analysis of risk factors for post-traumatic stress disorder in children and adolescents. Clin Psychol Rev, 32, 122-38. doi: 10.1016/j.cpr.2011.12.001\n\n\n\n\nField, A. P., & Wright, D. B. (2011). A primer on using multilevel models in clinical and experimental psychopathology research.. Journal of Experimental Psychopathology, 2, 271-293. doi: 10.5127/jep.013711\n\n\nBroeren, S., Lester, K. J., Muris, P., & Field, A. P. (2011). They are afraid of the animal, so therefore I am too: Influence of peer modeling on fear beliefs and approach-avoidance behaviors towards animals in typically developing children. Behaviour Research and Therapy, 49, 50-57. doi: 10.1016/j.brat.2010.11.001\n\n\nBroeren, S., Muris, P., Bouwmeester, S., Field, A. P., & Voerman, J. S. (2011). Processing biases for emotional faces in 4- to 12-year-old non-clinical children: An exploratory study of developmental patterns and relationships with social anxiety and behavioral inhibition. Journal of Experimental Psychopathology, 2, 454-474. doi: 10.5127/jep.016611\n\n\nCartwright-Hatton, S., McNally, D., Field, A. P., Rust, S., Laskey, B., Dixon, C., Gallagher, B., Harrington, R., Miller, C., Pemberton, K., Symes, W., White, C., & Woodham, A. (2011). A new parenting-based group intervention for young anxious children: results of a randomized controlled trial. Journal of the American Academy of Child and Adolescent Psychiatry, 50, 242-251. doi: 10.1016/j.jaac.2010.12.015\n\n\nCreswell, C., Shildrick, S., & Field, A. P. (2011). Interpretation of ambiguity in children: a prospective study of associations with anxiety and parental interpretations. Journal of Child and Family Studies, 20, 240-250. doi: 10.1007/s10826-010-9390-7\n\n\nHuijding, J., Muris, P., Lester, K. J., Field, A. P., & Joosse, G. (2011). Training children to approach or avoid novel animals: Effects on self-reported attitudes and fear beliefs and information-seeking behaviors. Behaviour Research and Therapy, 49, 606-613. doi: 10.1016/j.brat.2011.06.005\n\n\nLester, K. J., Field, A. P., & Muris, P. (2011). Experimental modification of interpretation bias regarding social and animal fear in children. Journal Of Anxiety Disorders, 25, 697-705. doi: 10.1016/j.janxdis.2011.03.006\n\n\nLester, K. J., Field, A. P., & Muris, P. (2011). Experimental modification of interpretation bias about animal fear in young children: Effects on cognition, avoidance behaviour, anxiety vulnerability and physiological responding.. Journal of Clinical Child and Adolescent Psychology, 40, 864-877. doi: 10.1080/15374416.2011.618449\n\n\nPurkis, H. M., Lester, K. J., & Field, A. P. (2011). But what about the empress of Racnoss? The allocation of attention to spiders and doctor who in a visual search task is predicted by fear and expertise. Emotion, 11, 1484-1488. doi: 10.1037/a0024415\n\n\nWright, D. B., London, K., & Field, A. P. (2011). Using bootstrap estimation and the plug-in principle for clinical psychology data. Journal of Experimental Psychopathology, 2, 252–270. doi: doi:10.5127/jep.013611\n\n\n\n\nField, A. P., & Gillett, R. (2010). How to do a meta-analysis. British Journal of Mathematical & Statistical Psychology, 63, 665-694. doi: 10.1348/000711010x502733\n\n\nField, A. P., & Lester, K. J. (2010). Is there room for ‘development’ in developmental models of information processing biases to threat in children and adolescents?. Clinical Child and Family Psychology Review, 13, 315-332. doi: 10.1007/s10567-010-0078-8\n\n\nKelly, V. L., Barker, H., Field, A. P., Wilson, C., & Reynolds, S. (2010). Can Rachman’s indirect pathways be used to un-learn fear? A prospective paradigm to test whether children’s fears can be reduced using positive information and modelling a non-anxious response. Behaviour Research and Therapy, 48, 164-170. doi: 10.1016/j.brat.2009.10.002\n\n\nLester, K. J., Seal, K., Nightingale, Z. C., & Field, A. P. (2010). Are children’s own interpretations of ambiguous situations based on how they perceive their mothers have interpreted ambiguous situations for them in the past?. Journal Of Anxiety Disorders, 24, 102-108. doi: 10.1016/j.janxdis.2009.09.004\n\n\nMuris, P., & Field, A. P. (2010). The role of verbal threat information in the development of childhood fear. “Beware the Jabberwock!”. Clinical Child and Family Psychology Review, 13, 129-150. doi: 10.1007/s10567-010-0064-1\n\n\nSawyer, A., Ayers, S., & Field, A. P. (2010). Posttraumatic growth and adjustment among individuals with cancer or HIV/AIDS: A meta-analysis. Clinical Psychology Review, 30, 436-447. doi: 10.1016/j.cpr.2010.02.004\n\n\n\n\n\nField, A. (2009). Can humour make students love statistics?. Psychologist, 22, 210–213.\n\n\nField, A. P., & Nightingale, Z. C. (2009). What if Little Albert had escaped?. Clinical Child Psychology and Psychiatry, 14, 343-351.\n\n\nField, A. P., & Price-Evans, K. (2009). Temperament moderates the effect of the verbal threat information pathway on children’s heart rate responses to novel animals. Behaviour Research and Therapy, 47, 431-436. doi: 10.1016/j.brat.2009.01.020\n\n\nHuijding, J., Field, A. P., De Houwer, J., Vandenbosch, K., Rinck, M., & Oeveren, M. (2009). A behavioral route to dysfunctional representations: The effects of training approach or avoidance tendencies towards novel animals in children. Behaviour Research and Therapy, 47, 471-477. doi: 10.1016/j.brat.2009.02.011\n\n\nLester, K. J., Field, A. P., Oliver, S., & Cartwright-Hatton, S. (2009). Do anxious parents interpretive biases towards threat extend into their child’s environment?. Behaviour Research and Therapy, 47, 170-174. doi: 10.1016/j.brat.2008.11.005\n\n\nMuris, P., Rassin, E., Mayer, B., Smeets, G., Huijding, J., Remmerswaal, D., & Field, A. P. (2009). Effects of verbal information on fear-related reasoning biases in children. Behav Res Ther, 47, 206-214. doi: Doi 10.1016/J.Brat.2008.12.002\n\n\nWright, D. B., & Field, A. P. (2009). Giving your data the bootstrap. Psychologist, 22, 412-413.\n\n\n\n\nField, A. P., Cartwright-Hatton, S., Reynolds, S., & Creswell, C. (2008). Future directions for child anxiety theory and treatment. Cognition & Emotion, 22, 385-394. doi: 10.1080/02699930701842270\n\n\nField, A. P., Lascelles, K. R. R., Lester, K. J., Askew, C., & Davey, G. C. L. (2008). Evaluative conditioning: missing, presumed dead. Netherlands Journal of Psychology, 64, 46-64. doi: 10.1007/BF03076407\n\n\nField, A. P., Lawson, J., & Banerjee, R. (2008). The verbal threat information pathway to fear in children: The longitudinal effects on fear cognitions and the immediate effects on avoidance behavior. Journal of Abnormal Psychology, 117, 214-224. doi: 10.1037/0021-843x.117.1.214\n\n\nField, A. P., & Cartwright-Hatton, S. (2008). Shared and unique cognitive factors in social anxiety. International Journal of Cognitive Therapy, 1, 206-222. doi: 10.1521/ijct.2008.1.3.206\n\n\nField, A. P., & Lawson, J. (2008). The verbal information pathway to fear and subsequent causal learning in children. Cognition & Emotion, 22, 459-479. doi: 10.1080/02699930801886532\n\n\nAskew, C., Kessock-Philip, H., & Field, A. P. (2008). What happens when verbal threat information and vicarious learning combine?. Behavioural and Cognitive Psychotherapy, 36, 491-505. doi: 10.1017/s1352465808004402\n\n\nAskew, C., & Field, A. P. (2008). The vicarious learning pathway to fear 40 years on. Clinical Psychology Review, 28, 1249-1265. doi: 10.1016/j.cpr.2008.05.003\n\n\nCartwright-Hatton, S., Field, A., Creswell, C., & Reynolds, S. (2008). Research into anxiety of childhood: playing catch-up (to olympic standard). Behavioural and Cognitive Psychotherapy, 36, 377-378. doi: 10.1017/s1352465808004566\n\n\nMuris, P., & Field, A. P. (2008). Distorted cognition and pathological anxiety in children and adolescents. Cognition & Emotion, 22, 395-421. doi: 10.1080/02699930701843450\n\n\nPrice-Evans, K., & Field, A. P. (2008). A neglectful parenting style moderates the effect of the verbal threat information pathway on children’s heart rate responses to novel animals. Behavioural and Cognitive Psychotherapy, 36, 473-482. doi: 10.1017/s1352465808004396\n\n\n\n\nField, A. P., Ball, J. E., Kawycz, N. J., & Moore, H. (2007). Parent-child relationships and the verbal information pathway to fear in children: Two preliminary experiments. Behavioural and Cognitive Psychotherapy, 35, 473-486. doi: 10.1017/s1352465807003736\n\n\nField, A. P., & Schorah, H. (2007). The verbal information pathway to fear and heart rate changes in children. Journal of Child Psychology and Psychiatry, 48, 1088-1093. doi: 10.1111/j.1469-7610.2007.01772.x\n\n\nField, A. P., & Storksen-Coulson, H. (2007). The interaction of pathways to fear in childhood anxiety: A preliminary study. Behaviour Research and Therapy, 45, 3051-3059. doi: 10.1016/j.brat.2007.09.001\n\n\nAskew, C., & Field, A. P. (2007). Vicarious learning and the development of fears in childhood. Behaviour Research and Therapy, 45, 2616-2627. doi: 10.1016/j.brat.2007.06.008\n\n\nBrewin, C. R., Kleiner, J. S., Vasterling, J. J., & Field, A. P. (2007). Memory for emotionally neutral information in posttraumatic stress disorder: A meta-analytic investigation. Journal of Abnormal Psychology, 116, 448-463. doi: 10.1037/0021-843x.116.3.448\n\n\nLawson, J., Banerjee, R., & Field, A. P. (2007). The effects of verbal information on children’s fear beliefs about social situations. Behaviour Research and Therapy, 45, 21-37. doi: 10.1016/j.brat.2006.01.007\n\n\nMiles, J. N. V., & Field, A. P. (2007). Perspectives on significance testing.. The Irish Journal of Psychology, 28, 13-26.\n\n\n\n\nField, A. P. (2006). The behavioral inhibition system and the verbal information pathway to children’s fears. Journal of Abnormal Psychology, 115, 742-752. doi: 10.1037/0021-843x.115.4.742\n\n\nField, A. P. (2006). I don’t like it because it eats sprouts: Conditioning preferences in children. Behaviour Research and Therapy, 44, 439-455. doi: 10.1016/j.brat.2005.03.006\n\n\nField, A. P. (2006). Is conditioning a useful framework for understanding the development and treatment of phobias?. Clinical Psychology Review, 26, 857-875. doi: 10.1016/j.cpr.2005.05.010\n\n\nField, A. P. (2006). Watch out for the beast: Fear information and attentional bias in children. Journal of Clinical Child and Adolescent Psychology, 35, 431-439. doi: 10.1207/s15374424jccp3503_8\n\n\nPincus, T., Vogel, S., Burton, A. K., Santos, R., & Field, A. P. (2006). Fear avoidance and prognosis in back pain - A systematic review and synthesis of current evidence. Arthritis and Rheumatism, 54, 3999-4010. doi: 10.1002/art.22273\n\n\n\n\nField, A. P. (2005). Is the meta-analysis of correlation coefficients accurate when population correlations vary?. Psychological Methods, 10, 444-467. doi: 10.1037/1082-989x.10.4.444\n\n\nField, A. P., & Moore, A. C. (2005). Dissociating the effects of attention and contingency awareness on evaluative conditioning effects in the visual paradigm. Cognition & Emotion, 19, 217-243. doi: 10.1080/02699930441000292\n\n\nDe Houwer, J., Baeyens, F., & Field, A. P. (2005). Associative learning of likes and dislikes: Some current controversies and possible ways forward. Cognition & Emotion, 19, 161-174. doi: 10.1080/02699930441000265\n\n\n\n\nField, A. P., & Morgan, J. (2004). Post-event processing and the retrieval of autobiographical memories in socially anxious individuals. Journal Of Anxiety Disorders, 18, 647-663. doi: 10.1016/j.janxdis.2003.08.004\n\n\nAndrea, H., Beurskens, A., Kant, I. J., Davey, G. C. L., Field, A. P., & Schayck, C. P. (2004). The relation between pathological worrying and fatigue in a working population. Journal of Psychosomatic Research, 57, 399-407. doi: 10.1016/j.jpsychores.2003.09.013\n\n\nPincus, T., Williams, A. C. D., Vogel, S., & Field, A. P. (2004). The development and testing of the Depression, Anxiety, and Positive Outlook Scale (DAPOS). Pain, 109, 181-188.\n\n\n\n\nField, A. P. (2003). Can meta-analysis be trusted?. Psychologist, 16, 642-645.\n\n\nField, A. P. (2003). The problems in using Fixed-effects models of meta-analysis on real-world data. Understanding Statistics, 2, 77-96.\n\n\nField, A. P., Hamilton, S. J., Knowles, K. A., & Plews, E. L. (2003). Fear information and social phobic beliefs in children: a prospective paradigm and preliminary results. Behaviour Research and Therapy, 41, 113-123. doi: Pii s0005-7967(02)00050-5 10.1016/s0005-7967(02)00050-5\n\n\nField, A. P., & Lawson, J. (2003). Fear information and the development of fears during childhood: effects on implicit fear responses and behavioural avoidance. Behaviour Research and Therapy, 41, 1277-1293. doi: 10.1016/s0005-7967(03)00034-2\n\n\nDavey, G. C. L., Startup, H. M., Zara, A., MacDonald, C. B., & Field, A. P. (2003). The perseveration of checking thoughts and mood–as–input hypothesis. Journal of Behavior Therapy and Experimental Psychiatry, 34, 141-160. doi: 10.1016/S0005-7916(03)00035-1\n\n\n\n\nPincus, T., Burton, A. K., Vogel, S., & Field, A. P. (2002). A systematic review of psychological factors as predictors of chronicity/disability in prospective cohorts of low back pain. Spine (Phila Pa 1976), 27, E109-20.\n\n\n\n\nField, A. P. (2001). Meta-analysis of correlation coefficients: A Monte Carlo comparison of fixed- and random-effects methods. Psychological Methods, 6, 161-180. doi: 10.1037/1082-989x.6.2.161\n\n\nField, A. P. (2001). When all is still concealed: Are we closer to understanding the mechanisms underlying evaluative conditioning?. Consciousness and Cognition, 10, 559-566. doi: 10.1006/ccog.2001.0529\n\n\nField, A. P., Argyris, N. G., & Knowles, K. A. (2001). Who’s afraid of the big bad wolf: a prospective paradigm to test Rachman’s indirect pathways in children. Behaviour Research and Therapy, 39, 1259-1276. doi: 10.1016/s0005-7967(00)00080-2\n\n\n\n\nField, A. P. (2000). Evaluative conditioning is Pavlovian conditioning: Issues of definition, measurement, and the theoretical importance of contingency awareness. Consciousness and Cognition, 9, 41-49.\n\n\nField, A. P. (2000). I like it, but I’m not sure why: Can evaluative conditioning occur without conscious awareness?. Consciousness and Cognition, 9, 13-36. doi: 10.1006/ccog.1999.0402\n\n\nField, A. P. (2000). Research methodology in the social, behavioural and life sciences.. British Journal of Mathematical & Statistical Psychology, 53, 329-330.\n\n\nDavey, G. C. L., & Field, A. P. (2000). The “benefit” of Pavlovian conditioning - performance models, hidden costs, and innovation. Behavioral and Brain Sciences, 23, 253-+. doi: 10.1017/s0140525x00272439\n\n\n\n\n\nField, A. P., & Davey, G. C. L. (1999). Reevaluating evaluative conditioning: A nonassociative explanation of conditioning effects in the visual evaluative conditioning paradigm. Journal of Experimental Psychology-Animal Behavior Processes, 25, 211-224. doi: 10.1037/0097-7403.25.2.211\n\n\n\n\nField, A. P. (1998). A bluffer’s guide to sphericity. Newsletter of the Mathematical, Statistical and Computing Section of the British Psychological Society, 6, 13-22.\n\n\nField, A. P., & Davey, G. C. L. (1998). Evaluative conditioning: Arti-fact or -fiction? A reply to Baeyens, de Houwer, Vansteenwegen, and Eelen (1998). Learning and Motivation, 29, 475-491. doi: 10.1006/lmot.1998.1006\n\n\n\n\nField, A. P., & Davey, G. C. L. (1997). Conceptual conditioning: Evidence for an artifactual account of evaluative learning. Learning and Motivation, 28, 446-464. doi: 10.1006/lmot.1997.0980"
  },
  {
    "objectID": "pages/pubs.html#book-chapters",
    "href": "pages/pubs.html#book-chapters",
    "title": "Publications",
    "section": "Book chapters",
    "text": "Book chapters\n2013\n\n\nField, A. (2013). Demystifying statistics: bring your imprimatur … to the laughter. In Bilham, T. (Eds.), For the Love of Learning (pp. 109-113). London: Macmillan Education UK.\n\n2012\n\n\nField, A. P. (2012). Meta-analysis in clinical psychology research. In Comer, J. S., & Kendall, P. C. (Ed.), The Oxford Handbook of Research Strategies for Clinical Psychology (pp. ). Oxford: Oxford University Press..\n\n2011\n\n\nField, A. P., Hadwin, J. A., & Lester, K. J. (2011). Information processing biases in child and adolescent anxiety: evidence and origins. In Silverman, W. K., & Field, A. P. (Ed.), Anxiety disorders in children and adolescents: research, assessment and intervention (pp. 103–128). Cambridge: Cambridge University Press.\n\n\nField, A. P., & Purkis, H. M. (2011). Associative learning and phobias. In M. Haselgrove, ., & L. Hogarth, . (Ed.), Clinical applications of learning theory (pp. 49-73). Hove: Psychology Press.\n\n\nField, A. P., & Purkis, H. M. (2011). The role of learning in the aetiology of child and adolescent fear and anxiety. In Silverman, W. K., & Field, A. P. (Ed.), Anxiety disorders in children and adolescents: research, assessment and intervention (pp. 227-256). Cambridge: Cambridge University Press.\n\n\nMuris, P., & Field, A. P. (2011). The normal development of fear in children and adolescents. In Silverman, W. K., & Field, A. P. (Ed.), Anxiety disorders in children and adolescents: research, assessment and intervention (pp. 76-89). Cambridge: Cambridge University Press.\n\n2010\n\n\nField, A. P. (2010). Non-Sadistical Methods for Teaching Statistics. In , ., & , . (Ed.), Teaching Psychology in Higher Education (pp. 134-163). : John Wiley & Sons, Ltd.\n\n\nField, A. P., & Lester, K. J. (2010). Learning of Information processing biases in anxious children and adolescents. In Hadwin, J. A., & Field, A. P. (Ed.), Information processing biases and anxiety: A developmental perspective (pp. 253-278). Chichester: Wiley-Blackwell.\n\n\nHadwin, J. A., & Field, A. P. (2010). An introduction to the study of information processing biases in childhood anxiety: Theoretical and methodological issues. In Hadwin, J. A., & Field, A. P. (Ed.), Information processing biases and anxiety: A developmental perspective (pp. 1-17). Chichester: Wiley-Blackwell.\n\n\nHuijding, J., Wiers, R. W., & Field, A. P. (2010). The assessment of fear-related automatic associations in children.. In Hadwin, J. A., & Field, A. P. (Ed.), Information processing biases and anxiety: A developmental perspective (pp. 151-182). Chichester: Wiley-Blackwell.\n\n\nNightingale, Z. C., Field, A. P., & Kindt, M. (2010). The emotional Stroop task in anxious children. In Hadwin, J. A., & Field, A. P. (Ed.), Information processing biases and anxiety: A developmental perspective (pp. 47-75). Hoboken, NJ, US: Wiley Blackwell.\n\n2009\n\n\nField, A. P. (2009). Meta-analysis. In Millsap, R. E., & Maydeu-Olivares, A. (Ed.), The SAGE Handbook of Quantitative Methods in Psychology (pp. 404-422). London: Sage.\n\n2007\n\n\nField, A. P. (2007). Analysis of variance. In Salkind, N. J. (Eds.), Encyclopedia of Measurement and Statistics (pp. 32-35). Thousand Oaks: CA: Sage.\n\n\nField, A. P. (2007). Homogeneity of variance. In Salkind, N. J. (Eds.), Encyclopedia of Measurement and Statistics (pp. 442-444). Thousand Oaks: CA: Sage.\n\n\nField, A. P. (2007). Kurtosis. In Salkind, N. J. (Eds.), Encyclopedia of Measurement and Statistics (pp. 522-523). Thousand Oaks: CA: Sage.\n\n\nField, A. P. (2007). One-way analysis of variance. In Salkind, N. J. (Eds.), Encyclopedia of Measurement and Statistics (pp. 713-716). Thousand Oaks: CA: Sage.\n\n2005\n\n\nField, A. P. (2005). Eta and eta-squared. In Everitt, B. S., & Howell, D. C. (Ed.), Encyclopedia of Statistics in Behavioral Science (pp. 658-659). Chichester: Wiley.\n\n\nField, A. P. (2005). Intraclass correlation. In Everitt, B., & Howell, D. C. (Ed.), Encyclopedia of statistics in behavioral science (pp. 948–954). New York: Wiley.\n\n\nField, A. P. (2005). Kendall’s Coefficient of Concordance. In Everitt, B., & Howell, D. C. (Ed.), Encyclopedia of Statistics in Behavioral Science (pp. 1010–1011). New York: Wiley.\n\n\nField, A. P. (2005). Meta-analysis. In Miles, J., & Gilbert, P. (Ed.), A handbook of research methods in clinical and health psychology (pp. 295-308). Oxford: Oxford University Press.\n\n\nField, A. P. (2005). Sir Ronald Aylmer Fisher. In Everitt, B. S., & Howell, D. C. (Ed.), Encyclopedia of statistics in behavioral science (pp. 658-659). Chichester: Wiley.\n\n\nField, A. P., & Davey, G. C. L. (2005). Experimental methods in clinical and health research. In Miles, J. M. V., & Gilbert, P. (Ed.), A handbook of research methods in clinical and health psychology (pp. 175-184). Oxford: Oxford University Press.\n\n2001\n\n\nField, A. P., & Davey, G. C. L. (2001). Conditioning models of childhood anxiety.. In Silverman, W. K., & Treffers, P. A. (Ed.), Anxiety Disorders in Children and Adolescents: Research, Assessment and Intervention (pp. 187–211). Cambridge: Cambridge University Press."
  },
  {
    "objectID": "posts/2017_11_17_dsus5/index.html",
    "href": "posts/2017_11_17_dsus5/index.html",
    "title": "DSUS5 has arrived!",
    "section": "",
    "text": "The fifth edition of Discovering Statistics Using IBM SPSS Statistics has just landed (or so I am told). For those that use the book I thought it might be helpful to run through what’s changed.\n\nGeneral changes\n\nIt might sound odd if you’ve never done a new edition of a textbook, but it can be quite hard to quantify (or remember) what you have changed. I know I spent a ridiculous number of hours working on it, so I must have changed a lot, but when I list the tangibles it seems uninspiring. Here’s an exercise for you. Take something you wrote 5 years ago and re-write it. The chances are the content won’t change but you’ll express yourself better and it’ll take you a bit of time to do the re-writing. The piece will have improved (hopefully), but the content is probably quite similar. The improvement lies in some crack of intangibility. Anyway, assuming you did the exercise (which of course no-one in their right mind would), multiply that effort by 1000/(number of pages you just re-wrote) and that’s what I spent early 2017 doing.\nSo, the first major change is that I did a lot of re-structuring and re-writing that doesn’t change the content, as such, but I believe does improve the experience of reading my drivel. It’s a bit less drivel-y, you might say. With respect to the tangibles (I’ve plagiarised myself from the preface here …):\n\n\nIBM SPSS compliance: This edition was written using version 25 of IBM SPSS Statistics. IBM releases new editions of SPSS Statistics more often than I bring out new editions of this book, so, depending on when you buy the book, it may not reflect the latest version. I\n\n\nNew! Chapter: In the past four years the open science movement has gained a lot of momentum. Chapter 3 is new and discusses issues relevant to this movement such as p-hacking, HARKing, researcher degrees of freedom, and pre-registration of research. It also has an introduction to Bayesian statistics.\n\n\nNew! Bayes: Statistical times are a-changing, and it’s more common than it was four years ago to encounter Bayesian methods in social science research. IBM SPSS Statistics doesn’t really do Bayesian estimation, but you can implement Bayes factors. Several chapters now include sections that show how to obtain and interpret Bayes factors. Chapter 3 also explains what a Bayes factor is.\n\n\nNew! Robust methods: Statistical times are a-changing … oh, hang on, I just said that. Although IBM SPSS Statistics does bootstrap (if you have the premium version), there are a bunch of statistics based on trimmed data that are available in R. I have included several sections on robust tests and syntax to do them (using the R plugin).\n\n\nNew! Pointless fiction: Having got quite into writing a statistics textbook in the form of a fictional narrative (An Adventure in Statistics) I staved off boredom by fleshing out Brian and Jane’s story (which goes with the diagrammatic summaries at the end of each chapter). Of course, it is utterly pointless, but maybe someone will enjoy the break from the stats.\n\n\nNew! Misconceptions: Since the last edition my cat of 20 years died, so I needed to give him a more spiritual role. He has become the Correcting Cat, and he needed a foil, so I created the Misconception Mutt, who has a lot of common misconceptions about statistics. So, the mutt (based on my cocker spaniel, who since I wrote the update has unexpectedly died leaving a gaping emotional vacuum in my life) gets stuff wrong and the cat appears from the spiritual ether to correct him. All of which is an overly elaborate way to point out some common misconceptions.\n\n\nNew-ish! The linear model theme: In the past couple of editions of this book I’ve been keen to scaffold the content on the linear model to focus on the commonalities between models traditionally labelled as regression, ANOVA, ANCOVA, t-tests, etc. I’ve always been mindful of trying not to alienate teachers who are used to the historical labels, but I have again cranked the general linear model theme up a level.\n\n\nNew-ish! Characters: I loved working with James Iles on An Adventure in Statistics so much that I worked with him to create new versions of the characters in the book (and other design features like their boxes). They look awesome. Given that I was overhauling the characters, I decided Smart Alex should be a woman this time around.\n\n\nObvious stuff: I’ve re-created all of the figures, and obviously updated the SPSS Statistics screenshots and output.\n\n\nFeedback-related changes: I always collate feedback from readers and instructors and feed that into new editions. Lots of little things will have changed resulting from user-feedback. One obvious example, is with the examples in the book. I tweaked quite a few examples this time around (Smart Alex and within the main book). It’s hard to remember everything, but most tweaks were aimed at trying to avoid lazy stereotypes: for example, I changed a lot of examples based on sex differences, I changed a suicide example etc. The style of the book hasn’t changed (the people who like it will still like it, and the people who don’t still won’t) but sometimes an example that seemed like a good idea in 2005 doesn’t seem so great in 2017.\n\n\n\nChapter-by-chapter changes\n\nEvery chapter got a thorough re-write, but here are the tangible changes:\n\n\nChapter 1 (Doing research): I re-wrote and expanded the discussion of hypotheses. I changed my beachy head example to be about memes and how they follow normal distributions. I used some google analytics data to illustrate this.\n\n\nChapter 2 (Statistical theory): I restructured this chapter around the acronym of SPINE (thanks to a colleague, Jennifer Mankin, for distracting me from the acronym that more immediately sprang to my childish mind), so you’ll notice that subheadings/structure has changed and so on. The content is all there, just rewritten and reorganized into a better narrative. I expanded my description of null hypothesis significance testing (NHST).\n\n\nChapter 3 (Current thinking in statistics): This chapter is completely new. It co-opts some of the critique of NHST that used to be in Chapter 2 but moves this into a discussion of open science, p-hacking, HARKing, researcher degrees of freedom, pre-registration, and ultimately Bayesian statistics (primarily Bayes factors).\n\n\nChapter 4 (IBM SPSS Statistics): Obviously reflects changes to SPSS Statistics since the previous edition. There’s a new section on ‘extending’ SPSS Statistics that covers installing the PROCESS tool, the Essentials for R plugin and installing the WRS2 package (for robust tests).\n\n\nChapter 5 (Graphs): No substantial changes other than reflecting the new layout and output from the chart editor. I tweaked a few examples.\n\n\nChapter 6 (Assumptions): The content is more or less as it was. I have a much stronger steer away from tests of normality and homogeneity (I still cover them but mainly as a way of telling people not to use them) because I now offer some robust alternatives to common tests.\n\n\nChapter 7 (Nonparametric models): No substantial changes to content.\n\n\nChapter 8 (Correlation): I completely rewrote the section on partial correlations.\n\n\nChapter 9 (The linear model): I restructured this chapter a bit and wrote new sections on robust regression and Bayesian regression.\n\n\nChapter 10 (t-tests): I did an overhaul of the theory section to tie it in more with the linear model theme. I wrote new sections on robust and Bayesian tests of two means.\n\n\nChapter 11 (Mediation and moderation): No substantial changes to content, just better written.\n\n\nChapters 12–13 (GLM 1–2): I changed the main example to be about puppy therapy. I thought that the Viagra example was a bit dated, and I needed an excuse to get some photos of my spaniel into the book. (I might have avoided doing this had I know the crappy hand that fate would subsequently deal my beloved hound, but he’s in there just to make it super hard for me to look at those chapters and teach from them.). I wrote new sections on robust and Bayesian (Chapter 12 only) variants of these models.\n\n\nChapter 14 (GLM 3): I tweaked the example – it’s still about the beer-goggles effect, but I linked it to some real research so that the findings now reflect some actual science that’s been done (and it’s not about sex differences any more). I added sections on robust and Bayesian variants of models for factorial designs.\n\n\nChapters 15–16 (GLM 4–5): I added some theory to Chapter 14 to link it more closely to the linear model (and to the content of Chapter 21). I give a clearer steer now to ignoring Mauchly’s test and routinely applying a correction to F (although, if you happen to like Mauchly’s test, I doubt that the change is dramatic enough to upset you). I added sections on robust variants of models for repeated-measures designs. I added some stuff on pivoting trays in tables. I tweaked the example in Chapter 16 a bit so that it doesn’t compare males and females but instead links to some real research on dating strategies.\n\n\nChapter 17 (MANOVA), Chapter 18 (Factor analysis), Chapter 19 (Categorical data), Chapter 20 (Logistic regression), Chapter 21 (Multilevel models): Just rewritten, structural tweaks and so on but no major content changes.\n\n\n\nInternational editions\n\nNothing to do with me, but this time around if you live in North America you’ll get a book like this:\n\n\n\nCover of the European edition\n\n\nIn the rest of the world it’ll look like this:\n\n\n\nCover of the ‘European’rest of the world’ edition\n\n\nThe basic difference is in the page size and formatting. The North American edition has wider pages and a three column layout, the standard edition doesn’t. The content is exactly the same (I say this confidently despite the fact that I haven’t actually seen the proofs for the North American edition so I have no idea whether the publishers changed my UK spellings to US spellings or edited out anything they secretly wished I hadn’t put in the book.)\nSo there you have it. Needless to say I hope that those using the book think that things have got better …\n\n\n\nCitationBibTeX citation:@online{field2017,\n  author = {Field, Andy},\n  title = {DSUS5 Has Arrived!},\n  date = {2017-11-17},\n  url = {https://profandyfield.com/posts/2017_11_17_dsus5/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2017. “DSUS5 Has Arrived!” November 17, 2017.\nhttps://profandyfield.com/posts/2017_11_17_dsus5/."
  },
  {
    "objectID": "posts/2016_02_17_retraction/index.html",
    "href": "posts/2016_02_17_retraction/index.html",
    "title": "To retract or to not retract, that is the question",
    "section": "",
    "text": "Amazingly I haven’t written a blog since September last year, it’s almost as though I have better things to do (or have no ideas about topics … or have nothing interesting to say). It’s more the lack of ideas/interesting things to say, oh, and other people are so much better at statistics blogging than I am (see Dan Lakens for example). Still, twitter provided me with inspiration this morning as reports filtered through of the latest in a long line of Psychological Science retractions. This particular one is for an article by Fisher et al. (2015) in which they showed (according to retraction watch) that ‘women prefer to wear makeup when there is more testosterone present in their saliva’.  The full details of the retraction are also helpfully described by retraction watch if you’re interested. The main reason for the retraction though as described by the authors was as follows (see here):“Our article reported linear mixed models showing interactive effects of testosterone level and perceived makeup attractiveness on women’s makeup preferences. These models did not include random slopes for the term perceived makeup attractiveness, and we have now learned that the Type 1 error rate can be inflated when by-subject random slopes are not included (Barr, Levy, Scheepers, & Tily, 2013). Because the interactions were not significant in reanalyses that addressed this issue, we are retracting this article from the journal.”The purpose of this blog is to explain why I believe (other things being equal) the authors should have published a correction and not retracted the article. Much of what I think isn’t specific to this example, it just happens to have been triggered by it.\n\nTo retract …\n\n\nI assume that the authors’ decision to retract is motivated by a desire to rid the world of false knowledge. By retracting, the original paper is removed from the universe thus reducing the risk of ‘false knowledge’ on this topic spreading. A correction would not minimise the risk that the original article was cited or followed up by other researchers unless it was sort of tagged onto the end of the paper. If a correction appears as a separate paper then it may well be overlooked. However, I think this is largely a pragmatic issue for the publishers to sort out: just make it impossible for someone to get the original paper without also getting the correction. Job done.\n\n\n\n\n\nTo not retract …\n\n\nIf you read the full account of the retraction, the authors fitted a model, published the details of that model in the supplementary information with the paper and then posted their data the Open Science Framework for others to use. They have been completely transparent. Someone else re-analysed the data and included the aforementioned random slope, and alerted the authors to the differences in the model (notably this crucial interaction term). The authors retracted the paper. I would argue that a correction would be better for the following reasons.\n\n\n\n\nUndeserved repetitional damage\n\n\n\nOne of the things that really bugs me about science these days (especially psychology) is the witch-hunt-y-ness of it (yes, that’s not a real word). Scientists happily going about their business with good intentions, make bad decisions and suddenly everyone is after their head. This is evidenced by the editor feeling the need to make this comment in the retraction: “I would like to add an explicit statement that there is every indication that this retraction is entirely due to an honest mistake on the part of the authors.” The editor is attempting damage limitation for the authors.\n\n\n\n\n\nThe trouble is that retractions come with baggage ranging from ‘the scientists don’t know what they’re doing’ (at best) to hints that they have deliberately misled everyone for their own gain. This baggage is unnecessary. Don’t get me wrong, I’ve seen people do terrible things with data (in the vast majority of cases out of ignorance, not deceit) and I’m convinced that the incentive structures in academia are all wrong (quantity is valued over quality), but deep down I still like to believe that scientists care about science/knowledge. Given how open they have been with their analysis and data, these scientists strike me as being people who care about science They are to be applauded for their openness, and not burdened with the baggage of retraction. A correction would have better reflected their honesty and integrity.\n\nRetraction implies there is one correct way to model the data\n\n\nRetracting the paper implies ‘we did it wrong’. Did the authors analyse their data incorrectly though? Here’s some food for thought. Raphael Silberzahn and colleagues published a paper in which they gave the same research question and the same data set to 29 research teams and examined how they addressed the question (there is an overview of the paper here, and the paper itself is available here). Essentially they found a lot of variability in what statistical models were applied to answer the question including tobit regression, logistic regression (sometimes multilevel, sometimes not), poisson regression (sometimes multilevel, sometimes not), spearman’s correlation, OLS regression, WLS regression, Bayesian logistic regression (sometimes multilevel, sometimes not). You get the gist. The resulting odds ratios for the effect ranged from 0.89 to 2.93 (although all but 2 were &gt; 1). Confidence intervals for these odds ratios ranged in width quite widely. The positive thing was that if you look at Figure 1 in the paper, despite variation in the models applied, there was a fair bit of consensus in the odds ratio and confidence intervals produced (about half of the point estimates/CIs  - the ones from team 26 to team 9 - line up pretty well despite the varying models applied). However, it goes to show that give a data set and a question to 29 research teams and they will analyse it differently. Is there one correct model? Are 28 teams wrong and 1 team correct. No, data analysis is always about decisions, and although there can be unequivocally wrong decisions, there is rarely only one correct decision.So, Fisher and colleagues didn’t include a random slope, someone else did. This change in model specification affected the model parameters and p-values. Is the inclusion of the random slope any more correct than it’s exclusion? That’s somewhat a matter of opinion. Of course, its exclusion could have led to a Type I error (if you fixate on p-values), but the more interesting question is why it changes the model, how it changes it and what the implications are moving forward. The message (for me) from the Silberzahn paper is that if any of us let other scientists loose with our data, they would probably do different things with it that would affect the model parameters and p-values. Just as has happened here. The logic of this particular retraction is that every scientist should retract every paper they have ever published on the grounds that there were probably other models that could have been fit, and if they had been then the parameter estimates in the paper would be different. A correction (rather than retraction) would have allowed readers and researcher in this field to consider the findings in the light of the difference that the random slope makes to the model.\n\n\nRetraction devalues the original study\n\nHere’s how science works. People generate theories, they transform them into testable hypotheses, they collect data, they evaluate the evidence for their hypothesis. Then other people get interested in the same theory and collect more data and this adds to the collective knowledge on the topic. Sometimes the new data contradicts the old data, in which case people update their beliefs. We do not, however, retract all of the old papers because this new one has thrown up different evidence. That would be silly, and yet I think that is all that has happened here with Fisher et al.’s paper. They fitted one model to the data, drew some conclusions, then someone else moved forward with the data and found something different. Retraction implies that the original study was of no value whatsoever, it must be hidden away never to be seen. Regardless of how you analyse the data, if the study was methodologically sound (I don’t know if it was - I can’t access it because its been retracted) then it adds value to the research question irrespective of the significance of an interaction in the model. A retraction removes this knowledge from the world, it becomes a file drawer paper rather than information that is out in the open. We are deprived of the evidence within the paper (including how that evidence changes depending on what model you fit to the data). A correction allows this evidence to remain public, and better still updates that evidence in the light of new analysis in useful ways …\n\nRetraction provides the least useful information about the research question\n\n\nBy retracting this study we are none the wiser about the hypothesis. All we know is that a p-value that was below &lt; .05 flipped to the other side of that arbitrary threshold when a random slope was included in the model. It could have changed from .049 to .051 for all we know, in which case the associated parameter has most likely not really changed much at all. It might have changed from .00000000001 to .99, in which case the impact has been more dramatic. A retraction deprives us of this information. In a correction, the authors could present the new model, its parameters and confidence intervals (incidentally, on the topic of which I recommend Richard Morey’s recent paper) and we could see how things have changed as a result of including the random slope. A correction provides us with specific and detailed evidence with which we can update our beliefs from the original paper. A correction allows the reader to determine what they believe. A retraction provides minimal and (I’d argue) unhelpful information about how the model changed, and about how to update our beliefs about the research question. All we are left with is to throw the baby out with the bathwater and pretend, like the authors, that the study never happened. If the methods were sound, then the study is valuable, and the new analysis is not damning but simply sheds new light on the hypotheses being tested. A retraction tells us little of any use.\n\n\n\n\n\nWhere to go …\n\n\nWhat this example highlights to me is how science needs to change, and how the publication process also needs to change. Science moves forward through debate, through people challenging ideas, and this is a good example. If the paper were in a PLoS style journal that encourages debate/comment then a retraction would not have been necessary. Instead, the models and conclusions could have been updated for all to see, the authors could have updated their conclusions based on these new analyses, and knowledge on the topic would have advanced. You’d end up with a healthy debate instead of evidence being buried. One of the challenges of open science and the OSF is to convince scientists that by making their data public they are not going to end up in these situations where they are being witch hunted, or pressured into retractions. Instead, we need to embrace systems that allow us to present different angles on the same data, to debate conclusions, and to strive for truth by looking at the same data from different perspectives … and for none of that to be perceived as a bad thing. Science will be better for it.\n\n\n\nReferences\n\n\n\nFisher, C. I., Hahn, A. C., DeBruine, L. M., & Jones, B. C. (2015). Women’s preference for attractive makeup tracks changes in their salivary testosterone. Psychological Science, 26, 1958–1964. doi:10.1177/0956797615609900\n\n\n\n\nCitationBibTeX citation:@online{field2016,\n  author = {Field, Andy},\n  title = {To Retract or to Not Retract, That Is the Question},\n  date = {2016-02-17},\n  url = {https://profandyfield.com/posts/2016_02_17_retraction/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2016. “To Retract or to Not Retract, That Is the\nQuestion.” February 17, 2016. https://profandyfield.com/posts/2016_02_17_retraction/."
  },
  {
    "objectID": "posts/2012_10_02_graham/index.html",
    "href": "posts/2012_10_02_graham/index.html",
    "title": "You can’t trust your PhD supervisor",
    "section": "",
    "text": "My Ex Ph.D. supervisor Graham Davey posted a blog this morning about 10 ways to create false knowledge in psychology. It’s a tongue-in-cheek look at various things that academics do for various reasons. Two of his 10 points have a statistical theme, and they raise some issues in my mind. I could walk the 3 meters between my office and Graham’s to discuss these, or rib him gently about it next time I see him in the pub, but I thought it would be much more entertaining to write my own blog about it. A blog about a blog, if you will. Perhaps he’ll reply with a blog about a blog about a blog, and I can reply with a blog about a blog about a blog about a blog, and then we can end up in some kind of blog-related negative feedback loop that wipes us both from existence so that we’d never written the blogs in the first place. But that would be a paradox. Anyway, I digress.Before I continue, let me be clear that during my PhD Graham taught me everything I consider worth knowing about the process of science, theory, psychopathology and academic life. So, I tend to listen to what he says (unless it’s about marriage or statistics) very seriously. The two points I want to focus on are:2.  Do an experiment but make up or severely massage the data to fit your hypothesis. This is an obvious one, but is something that has surfaced in psychological research a good deal recently (http://bit.ly/QqF3cZ;http://nyti.ms/P4w43q).Clearly the number of high profile retractions/sackings in recent times suggests that there is a lot of this about (not just in psychology). However, I think there is a more widespread problem than deliberate manipulation of data. For example, I remember reading somewhere about (I think) the Dirk Smeeters case or it might have been the Stapel one (see, I’m very scientific and precise); in any case, the person in question (perhaps it was someone entirely different), had claimed that they hadn’t thought they were doing anything wrong when applying the particular brand of massage therapy that they had applied to their data. So, although there are high profile cases of fraud that have been delved into, I think there is a wider problem of people simply doing the wrong thing with their data because they don’t know any better. I remind you of  Hoekstra, Henk, Kiers and Johnson’s recent study that asked recent postgraduate students about assumptions in their data, this paper showed (sort of) that recent postgraduate researchers don’t seem to check assumptions. I’d be very surprised if it’s just postgraduates. I would bet that assumptions, what they mean, when they matter and what to do about them are all concepts that are poorly understood amongst many very experiences researchers (not just within psychology). My suspicions are largely founded on the fact that I have only relatively recently really started to understand why and when these things matter, and I’m a geek who takes an interest in these things. I also would like to bet that the misunderstandings about assumptions and robustness of tests stem from being taught by people who poorly understand these things. I’m reminded of Haller & Kraus’ (2002) study showing that statistics teachers misunderstood p-values. The fourth edition of my SPSS book (plug: out early 2013) is the first book in which I really feel that I have handled the teaching of assumptions adequately - so I’m not at all blameless in all of this mess. (See two recently blogs on Normality and Homogeneity also.)I’d really like to do a study looking at more experienced researcher’s basic understanding of assumptions (a follow up to Hoekstra’s study on a more experienced sample, and with more probing questions) just to see whether my suspicions are correct. Maybe I should email Hoekstra and see if they’re interested because, left to my own devices, I’ll probably never get around to it.Anyway, my point is that I think it’s not just deliberate fraud that creates false knowledge, there is also a problem of well-intentioned and honest folk simply not understanding what to do, or when to do it.3.  Convince yourself that a significant effect at p=.055 is real. How many times have psychologists tested a prediction only to find that the critical comparison just misses the crucial p=.05 value? How many times have psychologists then had another look at the data to see if it might just be possible that with a few outliers removed this predicted effect might be significant? Strangely enough, many published psychology papers are just creeping past the p=.05 value – and many more than would be expected by chance! Just how many false psychology facts has that created? (http://t.co/6qdsJ4Pm).This is a massive over-simplification because an effect of p = .055 is ‘real’ and might very well be ‘meaningfiul’. Conversely, an effect with p &lt; .001 might very well be meaningless. To my mind it probably matters very little if a p is .055 or .049. I’m not suggesting I approve of massaging your data, but really this point illustrates how wedded psychologists are to the idea of effects somehow magically becoming ‘real’ or ‘meaningful’ once p drifts below .05. There’s a few points to make here:First, all effects are ‘real’. There should never be a decision being made by anyone about whether an effect is real or not real. They’re all real. It’s just that some are large and some are small. There is a decision about whether an effect is meaningful, and that decision should be made within the context of the research question.Second, I think an equally valid way to create ‘false knowledge’ is to publish studies based on huge samples reporting loads of small and meaningless effects that are highly significant. Imagine you look at the relationship between statistical knowledge and eating curry. You test 1 million people and find that there is a highly significant negative relationship, r = -.002, p &lt; .001. You conclude that eating curry is a 'real' effect - it is meaningfully related to poorer statistical knowledge. There are two issues here: (1) in a sample of 1 million people the effect size estimate will be very precise, and the confidence interval very narrow. So we know the true effect in the population is going to be very close indeed to -.002. In other words, there is basically no effect in the population - eating curry and statistical knowledge have such a weak relationship that you may as well forget about it. (2) anyone trying to replicate this effect in a sample substantially smaller than 1 million is highly unlikely to get a significant result. You've basically published an effect that is 'real' if you use p &lt; .05 to define your reality, but is utterly meaningless and won't replicate (in terms of p) in small samples.Third, there is a wider problem than people massage their ps. You have to ask why people massage their ps. The answer to that is because psychology is so hung up on p-values. Over 10 years since the APA published their report on statistical reporting (Wilkinson, 1999) there has been no change in the practice of applying the all-or-nothing thinking of accepting results as ‘real’ if p &lt; .05. It's true that Wilkinson's report has had a massive impact in the frequency with which effect sizes and confidence intervals are reported, but (in my experience which is perhaps not representative) these effect sizes are rarely interpreted with any substance and it is still the p-value that drives decisions made by reviewers and editors.This whole problem would go away if ‘meaning’ and ‘substance’ of effects were treated not as a dichotomous decision, but as a point along a continuum. You quantify your effect, you construct a confidence interval around it, and you interpret it within the context of the precision that your sample size allows. This way, studies with large samples could no longer focus on meaningless but significant effects, instead the researcher could say (given  the high level of precision they have) that the effects in the population (the true effects if you like) are likely to be about the size that they observed and interpret accordingly. In small studies, rather than throwing out the baby with the bathwater, large effects could be given some creditability but with the caveat that the estimates in the study lack precision. This is where replication is useful. No need to massage data - researchers just give it to the reader as it is, interpret it and apply the appropriate caveats etc. One consequence of this might be that rather than publishing a single small study with massaged data to get p &lt; .05, researchers might be encouraged to replicate their own study a few times and report them all in a more substantial paper. Doing so would mean that across a few studies you could show (regardless of p) the likely size of the effect in the population.That turned into a bigger rant than I was intending ….\n\nReferences\n\n\n\nHaller, H., & Kraus, S. (2002). Misinterpretations of Significance: A Problem Students Share with Their Teachers? MPR-Online, 7(1), 1-20. \n\n\nWilkinson, L. (1999). Statistical Methods in Psychology Journals: Guidelines and Explanations. American Psychologist, 54(8), 594-604. \n\n\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {You Can’t Trust Your {PhD} Supervisor},\n  date = {2012-10-02},\n  url = {https://profandyfield.com/posts/2012_10_02_graham/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “You Can’t Trust Your PhD Supervisor.”\nOctober 2, 2012. https://profandyfield.com/posts/2012_10_02_graham/."
  },
  {
    "objectID": "posts/2012_08_06_normality/index.html",
    "href": "posts/2012_08_06_normality/index.html",
    "title": "Assumptions Part 1: Normality",
    "section": "",
    "text": "…. I didn’t grow a pair of breasts. If you didn’t read my last blog that comment won’t make sense, but it turns out that people like breasts so I thought I’d mention them again. I haven’t written a lot of blogs, but my frivolous blog about growing breasts as a side effect of some pills was (by quite a large margin) my most viewed blog. It’s also the one that took me the least time to write and that I put the least thought into. I think the causal factor might be the breasts.This blog isn’t about breasts, it’s about normality. Admittedly the normal distribution looks a bit like a nipple-less breast, but it’s not one: I’m very happy that my wife does not sport two normal distributions upon her lovely chest. I like stats, but not that much …\n\nAssumptions\n\nAnyway, I recently stumbled across this paper. The authors sent a sample of postgrads (with at least 2 years research experience) a bunch of data analysis scenarios and asked them how they would analyze the data. They were interested in whether or not, and how these people checked the assumptions of the tests they chose to use. The good news was that they chose the correct test (although given all of the scenarios basically required a general linear model of some variety that wasn’t hard). However, not many of them checked assumptions. The conclusion as that people don’t understand assumptions or how to test themI get asked about assumptions a lot. I also have to admit to hating the chapter on assumptions in my SPSS and R books. Well, hate is a strong word, but I think it toes a very conservative and traditional line. In my recent update of the SPSS book (out early next year before you ask) I completely re-wrote this chapter. It takes a very different approach to thinking about assumptions.Most of the models we fit to data sets are based on the general linear model, (GLM) which means that any assumption that applies to the GLM (i.e., regression) applies to virtually everything else. You don’t really need to memorize a list of different assumptions for different tests: if it’s a GLM (e.g., ANOVA, regression etc.) then you need to think about the assumptions of regression. The most important ones are:\n\n\nLinearity\n\n\nNormality (of residuals)\n\n\nHomoscedasticity (aka homogeneity of variance)\n\n\nIndependence of errors.\n\n\n\n\nWhat Does Normality Affect?\n\nFor this post I’ll discuss normality. If you’re thinking about normality, then you need to think about 3 things that rely on normality:\n\n\nParameter estimates: That could be an estimate of the mean, or a b in regression (and a b in regression can represent differences between means). Models have error (i.e., residuals), and if these residuals are normally distributed in the population then using the method of least squares to estimate the parameters (the bs) will produce better estimates than other methods.\n\n\nConfidence intervals: whenever you have a parameter, you usually want to compute a confidence interval (CI) because it’ll give you some idea of what the population value of the parameter is. We use values of the standard normal distribution to compute the confidence interval: using values of the standard normal distribution makes sense only if the parameter estimates actually come from one.\n\n\nSignificance tests: we often test parameters against a null value (usually we’re testing whether b is different from 0). For this process to work, we assume that the parameter estimates have a normal distribution. We assume this because the test statistics that we use (such as the t, F and chi-square), have distributions related to the normal. If parameter estimates don’t have a normal distribution then p-values won’t be accurate. \n\n\n\n\nWhat Does The Assumption Mean?\n\nPeople often think that your data need to be normally distributed, and that’s what many people test. However, that’s not the case. What matters is that the residuals in the population are normal, and the sampling distribution of parameters is normal. However, we don’t have access to the sampling distribution of parameters or population residuals; therefore, we have to guess at what might be going on by testing the data instead.\n\nWhen Does The Assumption Matter?\n\nHowever, the central limit theorem tells us that no matter what distribution things have, the sampling distribution will be normal if the sample is large enough. How large is large enough is another matter entirely and depends a bit on what test statistic you want to use. So bear that in mind. However, oversimplifying things a bit, we could say:\n\n\nConfidence intervals: For confidence intervals around a parameter estimate to be accurate, that estimate must come from a normal distribution. The central limit theorem tells us that in large samples, the estimate will have come from a normal distribution regardless of what the sample or population data look like. Therefore, if we are interested in computing confidence intervals then we don’t need to worry about the assumption of normality if our sample is large enough. (There is still the question of how large is large enough though.) You can easily construct bootstrap confidence intervals these days, so if your interest is confidence intervals then why not stop worrying about normality and use bootstrapping instead?\n\n\nSignificance tests: For significance tests of models to be accurate the sampling distribution of what’s being tested must be normal. Again, the central limit theorem tells us that in large samples this will be true no matter what the shape of the population. Therefore, the shape of our data shouldn’t affect significance tests provided our sample is large enough. (How large is large enough depends on the test statistic and the type of non-normality. Kurtosis for example tends to screw things up quite a bit.) You can make a similar argument for using bootstrapping to get a robust p if p is your thing.\n\n\nParameter Estimates: The method of least squares will always give you an estimate of the model parameters that minimizes error, so in that sense you don’t need to assume normality of anything to fit a linear model and estimate the parameters that define it (Gelman & Hill, 2007). However, there are other methods for estimating model parameters, and if you happen to have normally distributed errors then the estimates that you obtained using the method of least squares will have less error than the estimates you would have got using any of these other methods. \n\n\n\n\nSummary\n\nIf all you want to do is estimate the parameters of your model then normality doesn’t really matter. If you want to construct confidence intervals around those parameters, or compute significance tests relating to those parameters then the assumption of normality matters in small samples, but because of the central limit theorem we don’t really need to worry about this assumption in larger samples. The question of how large is large enough is a complex issue, but at least you know now what parts of your analysis will go screwy if the normality assumption is broken..This blog is based on excerpts from the forthcoming 4th edition of ‘Discovering Statistics Using SPSS: and sex and drugs and rock ‘n’ roll’.\n\n\n\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {Assumptions {Part} 1: {Normality}},\n  date = {2012-08-06},\n  url = {https://profandyfield.com/posts/2012_08_06_normality/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “Assumptions Part 1: Normality.” August\n6, 2012. https://profandyfield.com/posts/2012_08_06_normality/."
  },
  {
    "objectID": "posts/2012_07_21_bonferroni/index.html",
    "href": "posts/2012_07_21_bonferroni/index.html",
    "title": "Bonferroni correcting lots of correlations",
    "section": "",
    "text": "Someone posed me this question:\n\nSome of my research, if not all of it (:-S) will use multiple correlations. I’m now only considering those correlations that are less than .001. However, having looked at bonferroni corrections today – testing 49 correlations require an alpha level of something lower than 0.001. So essentially meaning that correlations have to be significant at .000. Am I correct on this? The calculator that I am using from the internet says that with 49 correlational tests, with an alpha level of 0.001 – there is chance of finding a significant result in approximately 5% of the time. Some people have said to me that in personality psychology this is okay – but I personally feel wary about publishing results that could essentially be regarded as meaningless. Knowing that you probably get hammered every day for answers to stats question, I can appreciate that you might not get back to me. However – if you can, could you give me your opinion on using multiple correlations? Just seems a clunky method for finding stuff out.\n\nIt seemed like the perfect opportunity for a rant, so here goes. My views on this might differ a bit from conventional wisdom, so might not get you published, but this is my take on it:\n\nNull hypothesis significance testing (i.e. looking at p-values) is a deeply flawed process. Stats people know it’s flawed, but everyone does it anyway. I won’t go into the whys and wherefors of it being flawed but I touch on a few things here and to a lesser extent here. Basically, the whole idea of determining ‘significance’ based on an arbitrary cut off for a p-value is stupid. Fisher didn’t think it was a good idea, Neyman and Pearson didn’t think it was a good idea, and the whole thing dates back to prehistoric times when we didn’t have computers to compute exact p-values for us.\nBecause of the above, Bonferroni correcting when you’ve done a billion tests is even more ridiculous because your alpha level will be so small that you will almost certainly make Type II errors and lots of them. Psychologists are so scared of Type I errors, that they forget about Type II errors.\nCorrelation coefficients are effect sizes. We don’t need a p-value to interpret them. The p-value adds precisely nothing of value to a correlation coefficient other than to potentially fool you into thinking that a small effect is meaningful or that a large effect is not (depending on your sample size). I don’t care how small your p-value is, an r = .02 or something is crap. If your sample size is fairly big then the correlation should be a precise estimate of the population effect (bigger sample = more precise). What does add value is a confidence interval for r, because it gives you limits within which the true (population) value is likely to lie.\n\nSo, in a nutshell, I would (personally) not even bother with p-values in this situation because, at best, they add nothing of any value, and, at worst, they will mislead you. I would, however, get confidence intervals for your many correlations (and if you bootstrap the CIs, which you can on SPSS, then all the better). I would then interpret effects based on the size of r and the likely size of the population effect (which the confidence intervals tells you). Of course reviewers and PhD examiners might disagree with me on this, but they’re wrong:-) Ahhhhhh, that feels better.\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {Bonferroni Correcting Lots of Correlations},\n  date = {2012-07-21},\n  url = {https://profandyfield.com/posts/2012_07_21_bonferroni/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “Bonferroni Correcting Lots of\nCorrelations.” July 21, 2012. https://profandyfield.com/posts/2012_07_21_bonferroni/."
  },
  {
    "objectID": "posts/2012_07_19_tails/index.html",
    "href": "posts/2012_07_19_tails/index.html",
    "title": "One-tailed tests",
    "section": "",
    "text": "I’ve been thinking about writing a blog on one-tailed tests for a while. The reason is that one of the changes I’m making in my re-write of DSUS4 is to alter the way I talk about one-tailed tests. You might wonder why I would want to alter something like that – surely if it was good enough for the third edition then it’s good enough for the fourth? Textbook writing is quite an interesting process because when I wrote the first edition, I was very much younger, and to some extent the content was driven by what I saw in other textbooks. Even as the book has evolved over certain editions, the publishers will get feedback from lecturers who use the book, I get emails from people who use the book, and so, again, content gets driven a bit by what people who use the book want and expect to see. People expect to learn about one-tailed tests in an introductory statistics book and I haven’t wanted to disappoint them. However, as you get older you also get more confident about having an opinion on things. So, although I have happily entertained one-tailed tests in the past, in more recent years I have felt that they are one of the worse aspects of hypothesis testing that should probably be discouraged.\nYesterday I got the following question landing in my inbox, which was the perfect motivator to write this blog and explain why I’m trying to deal with one-tailed tests very differently in the new edition of DSUS:\n\nI need some advice and thought you may be able to help. I have a one-tailed hypothesis, ego depletion will increase response times on a Stroop task. The data is parametric and I am using a related T-Test. Before depletion the Stroop performance mean is 70.66 (12.36). After depletion the Stroop performance mean is 61.95 (10.36). The t-test is, t(138) = 2.07, p = .02 (one-tailed). Although the t-test comes out significant, it goes against what I have hypothesised. That Stroop performance decreased rather than increased after depletion. So it goes in the other direction. How do I acknowledge this in a report? I have done this so far. Is it correct?\n“Although the graph suggests there was a decrease in Stroop performance times after ego-depletion. Before ego-depletion (M = 0.66, SD = 12.36) after ego-depletion (M = 61.95, SD = 10.36), a t-test showed there was a significance between Stroop performance phase one and two t(138) = 10.94, p &lt;.001 (one-tailed).”\n\nThis question illustrates perfectly the confusion people have about one-tailed tests. The author quite rightly wants to acknowledge that the effect was in the opposite direction, but quite wrongly still wants to report the effect … and why not, effects in the opposite direction and interesting and intriguing and any good scientists wants to explain interesting findings.\nThe trouble is that my answer to the question of what to do when you get a significant one-tailed p-value but the effect is in the opposite direction to what you predicted is (and I quote my re-written chapter 2 here):\n\nif you do a one-tailed test and the results turn out to be in the opposite direction to what you predicted you must ignore them, resist all temptation to interpret them, and accept (no matter how much it pains you) the null hypothesis. If you don’t do this, then you have done a two-tailed test using a different level of significance from the one you set out to use\n\nQuoting some edited highlights of the new section I wrote on one-tailed tests, one-tailed tests are problematic for three reasons\n\nAs the question I was sent illustrates, when scientists see interesting and unexpected findings their natural instinct is to want to explain them. Therefore, one-tailed tests are dangerous because like a nice piece of chocolate cake when you’re on a diet, they waft the smell of temptation under your nose. You know you shouldn’t eat the cake, but it smells so nice, and looks so tasty that you shovel it down your throat. Many a scientist’s throat has a one-tailed effect in the opposite direction to that predicted wedged in it, turning their face red (with embarrassment).\nOne-tailed tests are appropriate only if a result in the opposite direction to the expected direction would result in exactly the same action as a non-significant result (Ruxton and Neuhaeuser 2010; Lombardi and Hurlbert 2009). This can happen, for example, if a result in the opposite direction would be theoretically meaningless or impossible to explain even if you wanted to (Kimmel 1957). Another situation would be if, for example, you’re testing a new drug to treat depression. You predict it will be better than existing drugs. If it is not better than existing drugs (non-significant p) you would not approve the drug; however it was significantly worse than existing drugs (significant p but in the opposite direction) you would also not approve the drug. In both situations, the drug is not approved.\nOne-tailed tests encourage cheating. If you do a two-tailed test and find that your p is .06, then you would conclude that your results were not significant (because .06 is bigger than the critical value of .05). Had you done this test one tailed however, the p you would get would be half of the two tailed value (.03). This one-tailed value would be significant at the conventional level. Therefore, if a scientist finds a two-tailed p that is just non-significant, they might be tempted to pretend that they’d always intended to do a one-tailed test, half the p value to make it significant and report that significant value. Partly this problem exists because of journal’s obsessions with p-values, which therefore rewards significance. This reward might be enough of a temptation for some people to half their p-value just to get a significant effect. This practice is cheating (for reasons explained in one of the Jane Superbrain boxes in Chapter 2 of my SPSS/SAS/R books). Of course, I’d never suggest that scientists would half their p-values just so that they become significant, but it is interesting that two recent surveys of practice in ecology journals concluded that “all uses of one-tailed tests in the journals surveyed seemed invalid.” [@lombardi2009], and that only 1 in 17 papers using one-tailed tests were justified in doing so (Ruxton and Neuhaeuser 2010).\n\nFor these reasons, DSUS4 onwards discourages the use of one-tailed tests unless there’s a very good reason to use one (e.g., 2 above).\nPS Thanks to Shane Lindsay who, a while back now, sent me the Lombardi and Ruxton papers.\n\n\n\n\n\n\n\nReferences\n\nKimmel, H. D. 1957. “Three Criteria for the Use of One-Tailed Tests.” Psychological Bulletin 54: 351–53. https://doi.org/10.1037/h0046737.\n\n\nLombardi, Celia M., and Stuart H. Hurlbert. 2009. “Misprescription and Misuse of One-Tailed Tests.” Austral Ecology 34 (June): 447–68. https://doi.org/10.1111/j.1442-9993.2009.01946.x.\n\n\nRuxton, Graeme D., and Markus Neuhaeuser. 2010. “When Should We Use One-Tailed Hypothesis Testing?” Methods in Ecology and Evolution 1 (June): 114–17. https://doi.org/10.1111/j.2041-210X.2010.00014.x.\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {One-Tailed Tests},\n  date = {2012-07-19},\n  url = {https://profandyfield.com/posts/2012_07_19_tails/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “One-Tailed Tests.” July 19, 2012. https://profandyfield.com/posts/2012_07_19_tails/."
  },
  {
    "objectID": "pages/packages.html",
    "href": "pages/packages.html",
    "title": "R Packages",
    "section": "",
    "text": "I have written the following packages for R.\n\n\n\n\n\n\nThe discovr package contains interactive tutorials for learning R that accompany my book [Discovering Statistics Using R and RStudio]. The tutorials are written using a package called learnr. Once a tutorial is running it’s a bit like reading excerpts of the book but with places where you can practice the R code that you have just been taught. The discovr package is free and offered to support tutors and students using my textbook. You can find out about the package at the companion website and install the package from github.\n\n\n\n\n\n\n\n\nThe adventr package contains interactive tutorials for learning R that accompany my book An adventure in statistics. The tutorials are written using a package called learnr. Once a tutorial is running it teaches you how to use R to run the analyses within the textbook (and more). You can find out about the package at the companion website and install the package from github.\n\n\n\n\n\n\n\n\nThe metahelpr package. The goal of metahelpr is to offer tutorials and helper functions for conducting meta-analysis using the metafor package (Viechtbauer 2010). The package contains some helper functions that I often use when I conduct meta-analysis. The tutorials are written using a package called learnr. Find out more and install the package from github.\n\n\n\n\n\n\nReferences\n\nViechtbauer, Wolfgang. 2010. “Conducting Meta-Analyses in {R} with the {Metafor} Package.” https://doi.org/10.18637/jss.v036.i03."
  },
  {
    "objectID": "discoverse/htdre/index.html#resources",
    "href": "discoverse/htdre/index.html#resources",
    "title": "How to Design and Report Experiments",
    "section": "Resources",
    "text": "Resources\n\nOrder from SAGE"
  },
  {
    "objectID": "discoverse/dsus/index.html",
    "href": "discoverse/dsus/index.html",
    "title": "Discovering Statistics Using IBM SPSS Statistics",
    "section": "",
    "text": "Winner of the British Psychological Society Book Award 2007"
  },
  {
    "objectID": "discoverse/dsus/index.html#resources",
    "href": "discoverse/dsus/index.html#resources",
    "title": "Discovering Statistics Using IBM SPSS Statistics",
    "section": "Resources",
    "text": "Resources\n\nCompanion website for students\nCompanion website for instructors\nOrder from SAGE"
  },
  {
    "objectID": "discoverse/dsus/index.html#inspiring-quotes",
    "href": "discoverse/dsus/index.html#inspiring-quotes",
    "title": "Discovering Statistics Using IBM SPSS Statistics",
    "section": "Inspiring quotes",
    "text": "Inspiring quotes\nHere are some quotes from the publishers about various editions of the book:\n\n“In this brilliant new edition Andy Field has introduced important new introductory material on statistics that the student will need and was missing at least in the first edition. This book is the best blend that I know of a textbook in statistics and a manual on SPSS. It is a balanced composite of both topics, using SPSS to illustrate important statistical material and, through graphics, to make visible important approaches to data analysis. There are many places in the book where I had to laugh, and that’s saying a lot for a book on statistics. His excellent style engages the reader and makes reading about statistics fun’” - David C Howell, Professor Emeritus, University of Vermont\n“The new edition of Field’s textbook confirms its place as the best statistics text for undergraduate social science students. It provides support for those less confident about statistical analysis whilst having sufficient depth that it will still be valuable to more mathematically experienced people. There is a focus throughout on the practical aspects of data analysis and interpretation whilst at the same time emphasizing the importance of rigour and a good understating of theory essential reading” Dr Ian Walker, Department of Psychology, University of Bath"
  },
  {
    "objectID": "discoverse/dsus/index.html#description",
    "href": "discoverse/dsus/index.html#description",
    "title": "Discovering Statistics Using IBM SPSS Statistics",
    "section": "Description",
    "text": "Description\nThis is what the publishers, SAGE, have to say on their web site (I don’t write this guff …):\n\nWith its unique combination of humour and step-by-step instruction, this award-winning book is the statistics lifesaver for everyone. From initial theory through to regression, factor analysis and multilevel modelling, Andy Field animates statistics and SPSS software with his famously bizarre examples and activities.\nFeatures:\n\nFlexible coverage to support students across disciplines and degree programmes\nCan support classroom or lab learning and assessment\nAnalysis of real data with opportunities to practice statistical skills\nHighlights common misconceptions and errors\nA revamped online resource that uses video, case studies, datasets, testbanks and more to help students negotiate project work, master data management techniques, and apply key writing and employability skills\nCovers the range of versions of IBM SPSS Statistics©.\n\nAll the online resources above (video, case studies, datasets, testbanks) can be easily integrated into your institution’s virtual learning environment or learning management system. This allows you to customize and curate content for use in module preparation, delivery and assessment."
  },
  {
    "objectID": "discoverse/dsus/index.html#new-to-the-6th-edition",
    "href": "discoverse/dsus/index.html#new-to-the-6th-edition",
    "title": "Discovering Statistics Using IBM SPSS Statistics",
    "section": "New to the 6th Edition",
    "text": "New to the 6th Edition\nEvery chapter has had a thorough edit/rewrite. First of all, a few general things across chapters:\n\nIBM SPSS compliance: This edition was written using version 29 of IBM SPSS Statistics. IBM release new editions of SPSS Statistics more often than I bring out new editions of this book, so, depending on when you buy the book, it may not reflect the latest version. This shouldn’t worry you because the procedures covered in this book are unlikely to be affected (see Section 4.2).\nTheory: Chapter 6 was completely rewritten to be the main source of theory for the general linear model (although I pre-empt this chapter with gentler material in Chapter 2). In general, whereas I have shied away from being too strict about distinguishing parameters from their estimates, my recent teaching experiences have convinced me that I can afford to be a bit more precise without losing readers.\nEffect sizes: IBM SPSS Statistics will now, in some situations, produce Cohen’s d so there is less ‘hand calculation’ of effect sizes in the book, and I have tended to place more emphasis on partial eta-square in the general linear model chapters.\n\nHere is a chapter-by-chapter run down of the more substantial changes:\n\nChapter 1 (Doing research): tweaks, not substantial changes.\nChapter 2 (Statistical theory): I expanded the section on null hypothesis significance testing to include a concrete example of calculating a p-value. I expanded the section on estimation to include a description of maximum likelihood. I expanded the material on probability density functions.\nChapter 3 (Current thinking in statistics): The main change is that I rewrote the section on the intentions of the researcher and p-values to refer back to the new example in Chapter 2. I hope this makes the discussion more concrete.\nChapter 4 (IBM SPSS Statistics): Obviously reflects changes to SPSS since the previous edition. I expanded the sections on currency variables and data formats, and changed the main example in the chapter. The introduction of the workbook format now means the chapter has sections on using SPSS in both classic and workbook mode. The structure of the chapter has changed a bit as a result.\nChapter 5 (visualizing data): No substantial changes, I tweaked a few examples.\nChapter 6 (Bias and model assumptions): This chapter was entirely rewritten. It now does the heavy lifting of introducing the linear model. The first half of the chapter includes some more technical material (which can be skipped) on assumptions of ordinary least squares estimation. I removed most of the material on the split file command and frequencies to focus more on the explore command.\nChapter 7 (Nonparametric models): No substantial changes to content other than updates to the SPSS material (which has changed quite a bit).\nChapter 8 (Correlation): Lots changed in SPSS (e.g., you can obtain confidence intervals for correlations). I overhauled the theory section to link to the updated Chapter 6.\nChapter 9 (The linear model): Some theory moved out into Chapter 6, so this chapter now has more focus on the ‘doing’ than the theory.\nChapter 10 (t-tests): I revised some theory to fit with the changes to Chapter 6.\nChapter 11 (Mediation and moderation): I removed the section on dummy variables and instead expanded the section on dummy coding in Chapter 12. Removing this material made space for a new example using two mediators. I updated all the PROCESS tool material.\nChapters 12 (GLM 1): I expanded the section on dummy coding (see previous chapter). The effect size material is more focused on partial eta-squared.\nChapter 13 (GLM 2): I framed the material on homogeneity of regression slopes more in terms of fitting parallel slopes and non-parallel slopes models in an attempt to clarify what assumptions we are and are not making with ANCOVA models. I expanded the section on Bayesian models.\nChapter 14 (GLM 3): I restructured the theoretical material on interactions and simple effects to bring it to the front of the chapter (and to link back to Chapter 11). In SPSS you can now run simple effects through dialog boxes and perform post hoc tests on interactions, so I replaced the sections on using syntax and expanded my advice on using these methods. I removed the Labcoat Leni section based on work by Nicolas Guéguen because of concerns that have been raised about his research practices and the retraction of some of his other studies.\nChapter 15 (GLM 4): I changed both examples in this chapter (so it’s effectively a complete rewrite) to be about preventing an alien invasion using sniffer dogs.\nChapters 16–17 (GLM 5 and MANOVA): These chapters have not changed substantially.\nChapter 18 (Factor analysis): This chapter has had some theory added. In particular, I have added sections on parallel analysis (including how to conduct it). I have also expanded the reliability theory section. Although the examples are the same, the data file itself has changed (for reasons related to adding the sections on parallel analysis).\nChapters 19 (Categorical data): No major changes here.\nChapter 20 (Logistic regression): I have removed the section on multinomial logistic regression to make room for an expanded theory section on binary logistic regression. I felt like the chapter covered a lot of ground without actually giving students a good grounding in what logistic regression does. I had lots of ideas about how to rewrite the theory section, and I’m very pleased with it, but something had to make way. I also changed the second example (penalty kicks) slightly to allow me to talk about interactions in binary logistic regression and to reinforce how to interpret logistic models (which I felt was lacking in previous editions).\nChapter 21 (Multilevel models): Wow, this was a gateway to a very unpleasant dimension for me. This chapter is basically a complete rewrite. I expanded the theory section enormously and also included more practical advice. To make space the section on growth models was removed, but it’s fair to say that I think this version will give readers a much better grounding in multilevel models. The main example changed slightly (new data, but still on the theme of cosmetic surgery)."
  },
  {
    "objectID": "discoverse/dsuj/index.html#resources",
    "href": "discoverse/dsuj/index.html#resources",
    "title": "Discovering Statistics Using JASP",
    "section": "Resources",
    "text": "Resources\n\nCompanion website for students\nCompanion website for instructors\nOrder from SAGE"
  },
  {
    "objectID": "discoverse.html",
    "href": "discoverse.html",
    "title": "The Discoverse",
    "section": "",
    "text": "The discover-verse (or discoverse for short) is a universe of books and associated websites to help you to learn statistics in the way you want.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscovering Statistics Using R and RStudio\n\n\n\nR\n\n\nStatistics Theory\n\n\n\n\n\n\n\nAndy P. Field\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscovering Statistics Using JASP\n\n\n\nJASP\n\n\nStatistics Theory\n\n\n\n\n\n\n\nAndy P. Field, Eric-Jan Wagenmakers, Johnny Doorn\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscovering Statistics Using IBM SPSS Statistics\n\n\n\nSPSS\n\n\nStatistics Theory\n\n\n\n\n\n\n\nAndy P. Field\n\n\nFeb 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn Adventure in Statistics\n\n\n\nStatistics Theory\n\n\n\n\n\n\n\nAndy P. Field\n\n\nMar 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscovering Statistics Using SAS\n\n\n\nSAS\n\n\nStatistics Theory\n\n\n\n\n\n\n\nAndy P. Field, Jeremy Miles\n\n\nFeb 1, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Design and Report Experiments\n\n\n\nMethodology\n\n\nStatistics Theory\n\n\n\n\n\n\n\nAndy P. Field, Graham Hole\n\n\nJan 1, 2003\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "DSUS5 has arrived!\n\n\n\nBooks\n\n\n\nBlatant plug for the latest edition of my SPSS textbook\n\n\n\nAndy Field\n\n\nNov 17, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStinkFiske\n\n\n\nResearch critique\n\n\n\nDiscussion of Susan Fiske’s ‘methodological terrorists’ comments\n\n\n\nAndy Field\n\n\nJan 3, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you’re not doing something different, you’re not doing anything at all.\n\n\n\nBooks\n\n\n\nBlatant plug for my new textbook\n\n\n\nAndy Field\n\n\nApr 28, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMax or No Max?\n\n\n\nSepultura\n\n\nR\n\n\nStatistics\n\n\n\nAre sepultura better with or without Max Cavelera?\n\n\n\nAndy Field\n\n\nMar 29, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo retract or to not retract, that is the question\n\n\n\nRetraction\n\n\n\nDiscussion about retraction\n\n\n\nAndy Field\n\n\nFeb 17, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe referee’s a …\n\n\n\nArsenal\n\n\nR\n\n\nStatistics\n\n\nMike Dean\n\n\nReferees\n\n\nFootball\n\n\nSoccer\n\n\n\nTongue in cheek look at Mike Dean’s refereeing decisions\n\n\n\nAndy Field\n\n\nSep 28, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerhaps my oxytocin was low when I read this paper\n\n\n\nOxytocin\n\n\nR\n\n\nStatistics\n\n\nresearch critique\n\n\n\nCritique of work on oxytocin and happiness\n\n\n\nAndy Field\n\n\nOct 31, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBat cunnilingus and spurious results\n\n\n\nR\n\n\nStatistics\n\n\nRobust methods\n\n\nResearch critique\n\n\n\nCritique of work on bat cunnilingus\n\n\n\nAndy Field\n\n\nApr 2, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFAQ #1: K-S Tests in SPSS\n\n\n\nSPSS\n\n\nStatistics\n\n\n\nAnswering a question about the K-S test in IBM SPSS Statistics\n\n\n\nAndy Field\n\n\nNov 14, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can’t trust your PhD supervisor\n\n\n\nOpen science\n\n\nResearcher degrees of freedom\n\n\nBad science\n\n\n\nComments on some stuff my ex-PhD supervisor said\n\n\n\nAndy Field\n\n\nOct 2, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssumptions Part 2: Homogeneity of Variance/Homoscedasticity\n\n\n\nStatistics\n\n\nOLS linear models\n\n\nThe assumption of homoscedasticity\n\n\n\nA discussion of the assumption of homoscedasticity\n\n\n\nAndy Field\n\n\nSep 13, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssumptions Part 1: Normality\n\n\n\nStatistics\n\n\nOLS linear models\n\n\nThe assumption of normality\n\n\n\nA discussion of the assumption of normality\n\n\n\nAndy Field\n\n\nAug 6, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSide effects\n\n\n\nStatistics\n\n\nStatistical literacy\n\n\nSide effects\n\n\n\nA discussion of the importance of statistical literacy\n\n\n\nAndy Field\n\n\nAug 1, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonferroni correcting lots of correlations\n\n\n\nStatistics\n\n\nBonferroni correction\n\n\nCorrelation\n\n\nMultiple tests\n\n\n\nA discussion of Conferroni corrections\n\n\n\nAndy Field\n\n\nJul 21, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSPSS is not dead\n\n\n\nStatistics\n\n\nOne-tailed tests\n\n\n\nA discussion of the use of IBM SPSS Statistics\n\n\n\nAndy Field\n\n\nJul 20, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne-tailed tests\n\n\n\nStatistics\n\n\nOne-tailed tests\n\n\n\nA discussion of using one-tailed tests\n\n\n\nAndy Field\n\n\nJul 19, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRock makes you racist … apparently\n\n\n\nResearch critique\n\n\n\nA critque of research that newspapers claim show that rock makes you rascist\n\n\n\nAndy Field\n\n\nJul 18, 2012\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "discoverse/ais/index.html#resources",
    "href": "discoverse/ais/index.html#resources",
    "title": "An Adventure in Statistics",
    "section": "Resources",
    "text": "Resources\n\n“Sometimes you must trust that you have the ability to find the answers yourself” Milton\n\n\nA blog about the book\nCompanion website\nInteractive tutorials for R\nBuy from SAGE"
  },
  {
    "objectID": "discoverse/ais/index.html#about",
    "href": "discoverse/ais/index.html#about",
    "title": "An Adventure in Statistics",
    "section": "About",
    "text": "About\n\n“I wasn’t sure how we’d got to this place, or how to leave it.” Zach Slade\n\nWill Zach find Alice, the missing love of his life, and save the world? Will he survive the bridge of death? Can he escape the zombie horde? Statistically speaking the odds don’t look good…. Reluctant hero Zach Slade wakes up to find that his soul mate Alice has vanished. To find her, he must solve a puzzle using the only clue he has – Alice’s unfinished research report. If only he hadn’t skipped science class to form a band. The more Zach unravels the enigma of reality, the more he sense that something is very wrong. Did Alice ever exist? Who is the mysterious Professor Milton? What is causing people to forget who they are? And why is everyone intent on teaching him statistics? Join Zach on his bizarre journey … It will transform your understanding of statistics forever."
  },
  {
    "objectID": "discoverse/ais/index.html#audience",
    "href": "discoverse/ais/index.html#audience",
    "title": "An Adventure in Statistics",
    "section": "Audience",
    "text": "Audience\nThis book is aimed at people with no prior knowledge of statistics."
  },
  {
    "objectID": "discoverse/ais/index.html#whats-it-about",
    "href": "discoverse/ais/index.html#whats-it-about",
    "title": "An Adventure in Statistics",
    "section": "What’s it about?",
    "text": "What’s it about?\nAt a simple level ‘an adventure in statistics’ is a story about Zach searching for Alice, and seeking the truth, but it’s also about the unlikely friendship he develops with a sarcastic cat, it’s about him facing his fear of science and numbers, it’s about him learning to believe in himself. It’s a story about love, about not forgetting who you are. It’s about searching for the heartbeats that hide in the gaps between you and the people you love. It’s about having faith in others. Of course, it’s also about fitting models, robust methods, classical and Bayesian estimation, significance testing and whole bunch of other tedious statistical things, but hopefully you’ll be so engrossed in the story that you won’t notice them. Or they might be a welcome relief from the terrible fiction. Time will tell."
  },
  {
    "objectID": "discoverse/ais/index.html#whats-the-difference-to-my-other-textbooks",
    "href": "discoverse/ais/index.html#whats-the-difference-to-my-other-textbooks",
    "title": "An Adventure in Statistics",
    "section": "What’s the difference to my other textbooks?",
    "text": "What’s the difference to my other textbooks?\nMy Discovering Statistics Using … range focuses on doing statistics using specific software packages (e.g., IBM SPSS Statistics, R, SAS) and do not spend much time on introductory concepts. An Adventure in Statistics does the opposite: it teaches the foundations of statistics from the bottom up focusing on theory, concepts and interpretation rather than software packages (because my other books already do that). As such, it is complimentary to my other books: it provides the grass roots introduction to statistics that my other books do not have space to provide. I will be producing some free materials to accompany the book to show how to use (most likely R, IBM SPSS Statistics and, possible, JASP) to reproduce what is in the book."
  },
  {
    "objectID": "discoverse/ais/index.html#awards",
    "href": "discoverse/ais/index.html#awards",
    "title": "An Adventure in Statistics",
    "section": "Awards",
    "text": "Awards\n\n“It’s stupid, stupid words, stupid symbols and even more stupid pictures.” Zach Slade\n\n\n2023: APEX Award for Publication Excellence: Print Media - Education & Training\n2017: Shortlisted for the British Psychological Society Book Award\n2016: The Association of Learned & Professional Society Publishers Award for Innovation in Publishing\n2016: British Book Design and Production Awards (Primary, Secondary and Tertiary Education category)"
  },
  {
    "objectID": "discoverse/ais/index.html#reviews",
    "href": "discoverse/ais/index.html#reviews",
    "title": "An Adventure in Statistics",
    "section": "Reviews",
    "text": "Reviews\n\n” I have at last encountered a book that provides solid, innovative statistics instruction alongside lessons in coding. And it’s fair to say that it does so like no other … If only I’d had this book back in grad school.” American Scientist. Reviewed by Katie L. Burke.\n“Field has succeeded in bringing a refreshing new approach to learning statistical methods, in this easy-to-follow and engaging guide.” The Psychologist, Reviewed by Stacey A. Bedwell."
  },
  {
    "objectID": "discoverse/ais/index.html#contents",
    "href": "discoverse/ais/index.html#contents",
    "title": "An Adventure in Statistics",
    "section": "Contents",
    "text": "Contents\n\nChapter list\n\nChapter 1: Why you need science\nChapter 2: Reporting research, variables and measurement\nChapter 3: Summarizing Data\nChapter 4: Fitting models (central tendency)\nChapter 5: Presenting data\nChapter 6: z-scores\nChapter 7: Probability\nChapter 8: Inferential statistics\nChapter 9: Robust estimation\nChapter 10: Hypothesis testing\nChapter 11: Modern approaches to theory testing\nChapter 12: Assumptions\nChapter 13: Relationships\nChapter 14: The general linear model\nChapter 15: comparing two means\nChapter 16: Comparing several means\nChapter 17: Factorial designs\n\n\n\nAlphabetic list of selected topics covered\nANOVA (including robust methods and Bayesian approaches), assumptions (additivity, homoskedasticity, linearity, independent errors, normality etc.), bar charts, Bayes factors, Bayesian methods, Bayes theorem, bias (sources and correcting for it), boxplots, central limit theorem, chi-square test, confidence intervals, correlation (including robust methods and Bayesian approaches), effect sizes, Fisher’s exact test, frequency distributions, histograms, IQR, likelihood ratio, mean, median, meta-analysis, mode, null hypothesis significance testing (including power, Type I and II errors, error rates, criticisms), probability theory (classical and empirical), range, regression (including robust methods and Bayesian approaches), robust estimation, sampling theory, sampling distributions, scatterplots, standard deviation, standard error, t-tests (including robust methods and Bayesian approaches), variance, z-scores."
  },
  {
    "objectID": "discoverse/dsur/index.html#the-second-edition",
    "href": "discoverse/dsur/index.html#the-second-edition",
    "title": "Discovering Statistics Using R and RStudio",
    "section": "The second edition",
    "text": "The second edition\nThe first edition of this book is now quite out of date. The good news is that I’been working on an update for the past 4+ years! I hope to finish it soon.\n\n\n\n\n\n\nIn the meantime, I have written a package of R tutorials the discovr package that contains a lot of the new material, and you can find out about the new edition at the companion website."
  },
  {
    "objectID": "discoverse/dsur/index.html#resources",
    "href": "discoverse/dsur/index.html#resources",
    "title": "Discovering Statistics Using R and RStudio",
    "section": "Resources",
    "text": "Resources\n\nCompanion website for students\nCompanion website for instructors old edition\nOrder from SAGE"
  },
  {
    "objectID": "discoverse/dsusas/index.html#resources",
    "href": "discoverse/dsusas/index.html#resources",
    "title": "Discovering Statistics Using SAS",
    "section": "Resources",
    "text": "Resources\n\nCompanion website for instructors\nOrder from SAGE"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andy Field",
    "section": "",
    "text": "I am Professor of Quantitative Methods at the University of Sussex, UK. I’ve published a lot of research papers, blah blah blah, but no-one has ever read them, or would want to. The chances are if you’re here it’s because of one of my statistics textbooks and you don’t need to be told that I write statistics textbooks, but I do."
  },
  {
    "objectID": "index.html#education-and-societies",
    "href": "index.html#education-and-societies",
    "title": "Andy Field",
    "section": "Education and Societies",
    "text": "Education and Societies\n\n2021: RStudio certified trainer (RStudio)\n2017-present: Chartered Statistician (Royal Statistical Society)\n2010–present: Fellow of the Academy of Social Sciences\n2009–present: Fellow of the Higher Teaching Academy\n1994–97: Ph.D. (Psychology). University of Sussex, Brighton, UK\n1991–94: B.Sc. (Psychology): City, University of London, UK."
  },
  {
    "objectID": "index.html#awards",
    "href": "index.html#awards",
    "title": "Andy Field",
    "section": "Awards",
    "text": "Awards\n\n2024: School of Psychology Teaching Award (University of Sussex, Statistics)\n2023, 2020, 2019, 2018, 2016, 2015: Education Award (University of Sussex, Statistics)\n2017: British Psychological Society book award (shortlisted)\n2016: British Book Design and Production Awards (shortlisted)\n2016: Association of Learned & Professional Society Publishers Award for Innovation in Publishing (Shortlisted)\n2015: University Teaching Innovation Prize (University of Sussex).\n2010: National Teaching Fellowship (HEA, Teaching Statistics)\n2007: British Psychological Society Book Award (Winner)\n2006: British Psychological Society Award for Excellence in the Teaching of Psychology.\n2001: Prize for Excellence and Innovation in Teaching (University of Sussex)"
  },
  {
    "objectID": "index.html#skills-and-hobies",
    "href": "index.html#skills-and-hobies",
    "title": "Andy Field",
    "section": "Skills and hobies",
    "text": "Skills and hobies\nStatistics, R, Drumming, Guitar"
  },
  {
    "objectID": "posts/2012_07_18_rock_racism/index.html",
    "href": "posts/2012_07_18_rock_racism/index.html",
    "title": "Rock makes you racist … apparently",
    "section": "",
    "text": "Like buses, you don’t get a blog for weeks and then two come at once. I saw today this headline: Does listening to rock make you racist? Seven minutes of Bruce Spri… in the daily mail online. They also included a helpful picture of Scott Weiland wearing a pseudo-nazi outfit (well, it was a black shirt, with a bit of a poor choice of peaked cap) to ‘reflect the association between rock and white people’. ‘The association between rock and white people’, bugger me, it’s as though bad brains, living colour, 24-7 spyz, Animals as Leaders, bodycount (shall I go on?) or those collaborations between public enemy and anthrax had never happened. In the world of the Daily Mail, rock makes you a racist, simple as. Now they’ve got the science to back it up. Mothers and fathers everywhere protect your children from this evil and rancid puff of Satan’s anal smoke that pervades society in the form of ‘rock music’, it will infect their brains and make them racists. I’d have thought this would be a good thing as far as the Daily Mail are concerned given this, and this, and this, and, well, every other article they publish.\n\n\nAnyway, enough about the Daily Mail. The point is, this piece of research has been seized on by many a website, including theNME who have for years been trying to find a good reason to justify looking down their self-important noses at rock and heavy metal. Now they have one: it makes us all racist. Or does it?\n\n\nThe study in question is this one: LaMarre et al. (2012): Does the Music Matter? Examining Differentia…\n\n\nIt’s based on Helen LaMarre’s doctoral thesis. I don’t want to get into bashing this study because I suspect like most scientists who find their studies spreading like wildfire across the internet, they at no point said that listening to Bruce Springsteen makes you a racist. It’s easy to bash any study – nothing is perfect. My issue here is with the way the study is presented by the media.\n\n\nEssentially, in this study they took 148 undergrads (all Caucasian otherwise it doesn’t really make sense), and sat them in a waiting room for 7 minutes during which one of three types of music was played:\n\n\n\nMainstream rock: The White Stripes, Bon Jovi, Bruce Springsteen, Van Morrison, Foo Fighters (2 songs), Radiohead\n\n\nRadical white power rock (i.e. racist dickhead rock): Prussian Blue (2 songs), Screwdriver, Bound for Glory, Max Resist (2 songs)\n\n\nTop 40 Pop: Justin Timberlake (3 songs), Fergie and Akon (2 songs), Fergie (withour Akon), Gwen Stefani (with Akon, who gets about a bit), Gwen Stefani (2 songs), Rihanna.\n\n\n\nAt the end of this they were asked to allocate $500,000, as percentage chunks, to four student groups based on descriptions of those groups. The descriptions depicted White American, African American, Arab American and Latino American student groups. So, for example, if you wanted to make equal allocations, then you would respond 25%, 25%, s5%, 25%. They found that when listening to pop music the allocations were fairly even (means of 24.02, 25.49, 24.02, 24.76), after rock music they allocated more to the white American student group (M = 35) compared to all of the others (all Ms around 21). After listening to right wing music, allocations were higher to White American students (M = 39.47) than to African (M = 16.09), Arab (M = 14.58) and Latina (M = 25.58) students.\n\n\nStatistically speaking these are pretty decent sized effects (huge in some cases). However, a few things to consider in making your own mind up about whether this shows that 7 minutes of Bruce Springsteen makes you a racist:\n\n\n\nIs a control group of pop music appropriate? A no music control group (just being in the waiting room) would give you a better baseline of people’s natural responses. The pop music (I’m not really familiar with it, but judging by song titles) was quite love oriented, so it’s possible that hearing songs about love etc. puts you in a good mood, and in a good mood you make more balanced allocations of the funds. I don’t know this to be true, it’s a hypothesis. However, I think a no music control group is a better baseline than any other form of music, because you can then assess whether a particular genre changes things compared to nothing at all. We could then see whether rock music affects allocations negatively, or pop music affects them positively. As it stands we just know the genres differ, but we don’t know whether pop makes you fairer or rock makes you unfair, or both.\n\n\nIs it the music that matters? This kind of research is very difficult to do because you’re not just manipulating the genre of music, you’re manipulating all sorts of other confounds that systematically vary with your independent variable. One example in this study is (arguably) aggression (rock is arguably more aggressive than pop, right wing rock is undoubtedly more aggressive than lots of other things). So here, you have a pattern of the rockier the music, the more money was allocated to White American students, but is it just because of a mood induction? Is it that the more of a negative mood you’re in, the more biased you are to the same race? (It would be an interesting finding in itself that people show a same race bias when they’re in a bad mood, but it would undermine the conclusion that rock music per se causes a same-race bias because there are lots of things that might put you in a bad mood other than rock music. Reading the daily mail, for example.) The problem here is that rock wasn’t pitted against, say hardcore hip hop, or better still perhaps some minor threat or fugazi who are very aggressive but promote very liberal themes in their lyrics. No measures of mood were taken so we don’t know whether there was a mood effect at all, and we certainly don’t know whether it’s the genre that matters, the lyrics, or the tone of the music. As I said, it’s really hard to match all of the variables that you might want to match, but the press portray the research in very simplistic terms and it’s not that’s simple.\n\n\nWhat about individual differences? When asked what music the people listened to the most common response was pop (the details of this questionnaire are sketchy so I’m not entirely sure what question was asked). So, in effect you’ve got a bunch of people who probably don’t listen to rock much, who are played rock in a waiting room. Some other people were played music that they ‘prefer’ (pop) and they are subsequently fair minded and nice than those played less familiar and less preferred music (rock). You’d really need some kind of measure of people’s preference and then look for an interaction between genre and preference. Maybe it’s simply that when you’re subjected to music that you don’t particularly like you show a same-race bias? This goes back to the mood effects problem. Again, what’s needed here is a bit more research that delves into how you’re affected by familiarity of the music, whether it’s music you actually like: by having a wider range of genres (not just rock and pop), different groups of people with different tastes (and from different racial backgrounds) we might be able to pick apart some of these potential confounds.\n\n\nThe money allocation task: arguably the money allocation task magnifies the effect. You have 100% to allocate over 4 boxes. You have to allocate exactly 100%. So, let’s imagine you’re fair minded and allocate across the boxes as 25%, 25%, 25%, 25%. Job done. Let’s say you change you’re mind and decide that you want to give box 1 an extra percent: 26%, 25%, 25%, 25%. You’ve now allocated 101% and that’s not allowed. So, you’d have to remove a 1% from another box to complete the task as requested. So perhaps you decide box 2 is your least favourite so you now allocate: 26%, 24%, 25%, 25%. You have allocated 100% and you have completed the task as requested. My point is that a small preference for box 1 (you wanted to add 1%) gets doubled because to do this you have to subtract some from one or more of the other boxes: a 1% difference between box 1 and 2 is doubled to a 2% difference. I’m not saying that this means that the results are nonsense or anything like that, but I am saying that it has probably magnified the effects reported because a slight preference for one group will be magnified simply because to increase funds to that group you have to take them away from another.\n\n\n\nThese are just a few points off the top of my head. Of course, I’m a huge rock and metal fan and I have my own biases: years of listening to slayer have not made me a Satanist anymore than years of listening to public enemy made me anti-white (although it did give me an enlightening new perspective on many things). I’m prepared to be proved wrong, but on the basis of this study I’m not concerned that I’ll wake up tomorrow as a raving racist. So, like I said this blog is more about how the press portray what is actually a very complex research question in a completely idiotic way. I always like reading studies about music preferences and this, like many I have read, pose interesting questions about the effect that music has on us and how we study it. There are lots of methodological issues that arise in trying to control the appropriate confounds if you’re trying to make statements about genres of music. There are also lots of interesting questions about what aspects of music effect people (so digging below the rather arbitrary classifications of rock, pop, rap or indie) and how these characteristics interact with the personality types of people that listen to them to affect cognition and emotion.\n\n\nRight, I’m off to listen to some Devin Townsend, after which I’m going to start a campaign to shut down all bad coffee outlets. Ziltoid ……..\n\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {Rock Makes You Racist … Apparently},\n  date = {2012-07-18},\n  url = {https://profandyfield.com/posts/2012_07_18_rock_racism/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “Rock Makes You Racist … Apparently.”\nJuly 18, 2012. https://profandyfield.com/posts/2012_07_18_rock_racism/."
  },
  {
    "objectID": "posts/2012_07_20_spss/index.html",
    "href": "posts/2012_07_20_spss/index.html",
    "title": "SPSS is not dead",
    "section": "",
    "text": "This blog was published recently showing that the use of R continues to grow in academia. One of the graphs (Figure 1) showed citations (using google scholar) of different statistical packages in academic papers\n\nAt face value, this graph implies a very rapid decline in SPSS use since 2005. I sent a tongue in cheek tweet about this graph, and this perhaps got interpreted that I thought SPSS use was on the decline. So, I thought I’d write this blog. The thing about this graph is it deals with citations in academic papers. The majority of people do not cite the package they use to analyse their data, so this might just reflect a decline in people stating that they used SPSS in papers. Also, it might be that users of software such as R are becomming more inclined to cite the package to encourage others to use it (stats package preference does for some people mimic the kind of religious fervor that causes untold war and misery. Most packages have their pros and cons and some people should get a grip). Also, looking at my annotations on Figure 1 you can see that the decline in SPSS is in no way matched by an upsurge in the use of R/Stata/Systat. This gap implies some mysterious ghost package that everyone is suddenly using but is not included on this graph. Or perhaps people are just ditching SPSS for qualitative analysis or doing it by handJ\n\n\nIf you really want to look at the decline/increase of package use then there are other metrics you could use. This article details lots of them. For example you could look at how much people talk about packages online (Figure 2).\n\nBased on this R seems very popular and SPSS less so. However, you can’t really compare R and SPSS here because R is more difficult to use than SPSS (I doubt that this is simply my opinion, I reckon you could demonstrate empirically that the average user prefers the SPSS GUI to R’s command interface if you could be bothered). People are, therefore, more likely to seek help on discussion groups for R than they are for SPSS. It’s perhaps not an index of popularity so much as usability.\n\n\nThere are various other interesting metrics discussed in the aforementioned article. Perhaps the closest we can get to an answer to package popularity (but not decline in use) is survey data on what tools people use for data mining. Figure 3 shows that people most frequently report R, SPSS and SAS. Of course this is a snapshot and doesn’t tell us about usage change. However, it shows that SPSS is still up there. I’m not sure what types of people were surveyed for this figure, but I suspect it was professional statisticians/business analysts rather than academics (who would probably not describe their main purpose as data mining). This would also explain the popularity of R, which is very popular amongst people who crunch numbers for a living.\n\nTo look at the decline or not of SPSS in academia what we really need is data about campus licenses over the past few years. There were mumblings about Universities switching from SPSS after IBM took over and botched the campus agreement, but I’m not sure how real those rumours were. In any case, the teething problems from the IBM take over seem to be over (at least most people have stopped moaning about them). Of course, we can’t get data on campus licenses because it’s sensitive data that IBM would be silly to put in the public domain. I strongly suspect campus agreements have not declined though. If they have, IBM will be doing all that they can (and they are an enormously successful company) to restore them because campus agreements are a huge part of SPSS’s business.\n\n\nAlso, I doubt campus agreements have declined because they will stop for two main reasons (1) SPSS isn’t used by anyone anymore, (2) the cost become prohibitive. These two reasons are related obviously – the point at which they stop the agreement will be a function of cost and campus usage. In terms of campus usage, If you grew up using SPSS as an undergraduate or postgraduate, you’re unlikely to switch software later in your academic career (unless you’re a geek like me who ‘enjoys’ learning R). So, I suspect the demand is still there. In terms of cost, as I said, I doubt IBM are daft enough to price themselves out of the market.\n\n\nSo, despite my tongue in cheek tweet, I very much doubt that there is a mass exodus from SPSS. Why would there be? Although some people tend to be a bit snooty about SPSS, it’s a very good bit of software: A lot of what it does, it does very well. There are things I don’t like about it (graphs, lack of robust methods, their insistence on moving towards automated analysis), but there’s things I don’t like about R too. Nothing is perfect, but SPSS’s user-friendly interface allows thousands of people who are terrified of stats to get into it and analyse data and, in my book, that’s a very good thing.\n\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {SPSS Is Not Dead},\n  date = {2012-07-20},\n  url = {https://profandyfield.com/posts/2012_07_20_spss/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “SPSS Is Not Dead.” July 20, 2012. https://profandyfield.com/posts/2012_07_20_spss/."
  },
  {
    "objectID": "posts/2012_08_01_side_effects/index.html",
    "href": "posts/2012_08_01_side_effects/index.html",
    "title": "Side effects",
    "section": "",
    "text": "I know I have been a bit rubbish with blogs recently, but I’m massively behind with the Discovering Statistics Using SPSS update, and these things fall by the wayside. Also, I can so rarely find anything remotely interesting to say, let alone blog about. If it were a blog about music then I could write all day. Anyway … So, while writing the DSUS update I was unwell for a couple of months. It turned out to (probably) be stress related (updating a book involves a lot of long days, late nights, and pressure). Unlike women who sensibly go to the doctor when they feel ill, men do not. However, I did eventually do the un-manly thing and go to my doctor. She prescribed some pills. In one of my other blogs I talked about key statistical skills that we should try to teach undergrads, and as I read the instructions of these pills it occurred to me that this is a good example of where the world would be a better place if people left university understanding statistics a bit better, and providing useful statistical information, therefore became the norm.\nLike a diligent patient, I read the instruction leaflet with the pills. Like most instruction leaflets with pills they had an un-amusing list of possible side effects. These side effects were helpfully listed as common, uncommon and rare. Common ones included headache, stomache aches and feeling sick (Ok, I can handle that), uncommon ones were dizziness, liver disease which might make my eyes yellow, rash, sleepiness or trouble sleeping (but not both). The rare ones included liver failure resulting in brain damage, bleeding at the lips, eyes, mouth, nose and genitals and development of breasts in men. Excuse me? Did it say ‘development of breasts in men’?\nYes it did.\nHere’s a photo to prove it.\n\nI’ll admit that I don’t know much about human anatomy, but based on the little I do know, it seems intuitive that my immune system, if reacting badly to something like a drug, might overload my liver and make it explode, or give me kidney failure. I also know that feeling sick and having flu-like symptoms is part and parcel of your immune system kicking into action. But why on earth would my body respond to a nasty drug by sprouting breasts? Perhaps because having them would make me more likely to visit my doctor.\nAnyway, back to the tenuous link to stats. Whenever I read this sort of thing (which fortunately isn’t often) I usually feel that I’d rather put up with whatever it is that’s bothering me than run the risk of, for example, bleeding from my penis or getting brain damage. I might feel differently if I had enough information to assess the risk. What do they mean by ‘uncommon’ or ‘rare’: 1/100, 1/1,000, 1/billion? Wouldn’t it be nice if we could have a bit more information, maybe even an odds ratio – that way I could know, for example, that if I take the pill I’d be 1.2 times more likely to grow breasts than if I don’t. That way we could better assess the likelihood of these adverse events, which if you’re as neurotic as me, would be very helpful. The campaign for more stats on drug instruction leaflets starts here.\nAnyway, after all that I took the pill, went to sleep and dreamt of the lovely new breasts that I’d have in the morning …\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {Side Effects},\n  date = {2012-08-01},\n  url = {https://profandyfield.com/posts/2012_08_01_side_effects/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “Side Effects.” August 1, 2012. https://profandyfield.com/posts/2012_08_01_side_effects/."
  },
  {
    "objectID": "posts/2012_09_13_homoscedasticity/index.html",
    "href": "posts/2012_09_13_homoscedasticity/index.html",
    "title": "Assumptions Part 2: Homogeneity of Variance/Homoscedasticity",
    "section": "",
    "text": "My last blog was about the assumption of normality, and this one continues the theme by looking at homogeneity of variance (or homoscedasticity to give it its even more tongue-twisting name). Just to remind you, I’m writing about assumptions because this paper showed (sort of) that recent postgraduate researchers don’t seem to check them. Also, as I mentioned before, I get asked about assumptions a lot. Before I get hauled up before a court for self-plaigerism I will be up front and say that this is an edited extract from the new edition of my Discovering Statistics book. If making edited extracts of my book available for free makes me a bad and nefarious person then so be it. \n\nAssumptions: A reminder\n\nNow, I’m even going to self-plagiarize my last blog to remind you that most of the models we fit to data sets are based on the general linear model, (GLM). This fact means that any assumption that applies to the GLM (i.e., regression) applies to virtually everything else. You don’t really need to memorize a list of different assumptions for different tests: if it’s a GLM (e.g., ANOVA, regression etc.) then you need to think about the assumptions of regression. The most important ones are: \n\n\nLinearity\n\n\nNormality (of residuals) \n\n\nHomoscedasticity (aka homogeneity of variance) \n\n\nIndependence of errors. \n\n\n\n\nWhat Does Homoscedasticity Affect? \n\nLike normality, if you’re thinking about homoscedasticity, then you need to think about 3 things: \n\n\nParameter estimates: That could be an estimate of the mean, or a b in regression (and a b in regression can represent differences between means). if we assume equality of variance then the estimates we get using the method of least squares will be optimal. \n\n\nConfidence intervals: whenever you have a parameter, you usually want to compute a confidence interval (CI) because it’ll give you some idea of what the population value of the parameter is. \n\n\nSignificance tests: we often test parameters against a null value (usually we’re testing whether b is different from 0). For this process to work, we assume that the parameter estimates have a normal distribution. \n\n\n\n\nWhen Does The Assumption Matter? \n\nWith reference to the three things above, let’s look at the effect of heterogeneity of variance/heteroscedasticity: \n\n\nParameter estimates: If variances for the outcome variable differ along the predictor variable then the estimates of the parameters within the model will not be optimal. The method of least squares (known as ordinary least squares, OLS), which we normally use, will produce ‘unbiased’ estimates of parameters even when homogeneity of variance can’t be assumed, but better estimates can be achieved using different methods, for example, by using weighted least squares (WLS) in which each case is weighted by a function of its variance. Therefore, if all you care about is estimating the parameters of the model in your sample then you don’t need to worry about homogeneity of variance in most cases: the method of least squares will produce unbiased estimates (Hayes & Cai, 2007). However, if you even better estimates, then use weighted least squares regression to estimate the parameters. \n\n\nConfidence intervals: unequal variances/heteroscedasticity creates a bias and inconsistency in the estimate of the standard error associated with the parameter estimates in your model (Hayes & Cai, 2007). As such, your confidence intervals and significance tests for the parameter estimates will be biased, because they are computed using the standard error. Confidence intervals can be ‘extremely inaccurate’ when homogeneity of variance/homoscedasticity cannot be assumed (Wilcox, 2010). \n\n\nSignificance tests: same as above. \n\n\n\n\nSummary \n\nIf all you want to do is estimate the parameters of your model then homoscedasticity doesn’t really matter: if you have heteroscedasticity then using weighted least squares to estimate the parameters will give you better estimates, but the estimates from ordinary least squares will be ‘unbiased’ (although not as good as WLS). If you’re interested in confidence intervals around the parameter estimates (bs), or significance tests of the parameter estimates then homoscedasticity does matter. However, many tests have variants to cope with these situations; for example, the t-test, the Brown-Forsythe and Welch adjustments in ANOVA, and numerous robust variants described by Wilcox (2010) and explained, for R, in my book (Field, Miles, & Field, 2012) \n\nDeclaration\n\n This blog is based on excerpts from the forthcoming 4th edition of ‘Discovering Statistics Using SPSS: and sex and drugs and rock ‘n’ roll’. \n\nReferences\n\n\n\n\nField, A. P., Miles, J. N. V., & Field, Z. C. (2012). Discovering statistics using R: And sex and drugs and rock ‘n’ roll. London: Sage. \n\n\nHayes, A. F., & Cai, L. (2007). Using heteroskedasticity-consistent standard error estimators in OLS regression: An introduction and software implementation. Behavior Research Methods, 39(4), 709-722. \n\n\nWilcox, R. R. (2010). Fundamentals of modern statistical methods: substantially improving power and accuracy. New York: Springer.\n\n\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {Assumptions {Part} 2: {Homogeneity} of\n    {Variance/Homoscedasticity}},\n  date = {2012-09-13},\n  url = {https://profandyfield.com/posts/2012_09_13_homoscedasticity/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “Assumptions Part 2: Homogeneity of\nVariance/Homoscedasticity.” September 13, 2012. https://profandyfield.com/posts/2012_09_13_homoscedasticity/."
  },
  {
    "objectID": "posts/2012_11_14_ks/index.html",
    "href": "posts/2012_11_14_ks/index.html",
    "title": "FAQ #1: K-S Tests in SPSS",
    "section": "",
    "text": "I decided to start a series of blogs on questions that I get asked a lot. When I say a series I’m probably raising expectation unfairly: anyone who follows this blog will realise that I’m completely crap at writing blogs. Life gets busy. Sometimes I need to sleep. But only sometimes.Anyway, I do get asked a lot about why there are two ways to do the Kolmogorov-Smirnov (K-S) test in SPSS. In fact, I got an email only this morning. I knew I’d answered this question many times before, but I couldn’t remember where I might have saved a response. Anyway, I figured if I just blog about it then I’d have a better idea of where I’d written a response. So, here it is. Anyway, notwithstanding my reservations about using the K-S test (you’ll have to wait until edition 4 of the SPSS book), there are three ways to get one from SPSS:\n\n\nAnalyze&gt;explore&gt;plots&gt; normality plots with tests\n\n\nNonparametric Tests&gt;One Sample … (or legacy dialogues&gt;one sample KS)\n\n\nTickle SPSS under the chin and whisper sweet nothings into its ear\n\n\n\nThese methods give different results. Why is that? Essentially (I think) if you use method 1 then SPSS applies Lillifor’s correction, but if you use method 2 it doesn’t. If you use method 3 then you just look like a weirdo.\n\n\n\n\n\nSo, is it better to use Lillifor’s correction or not? In the additional website material for my SPSS book, which no-one ever reads (the web material, not the book …) I wrote (self-plaigerism alert):\n\n\n\n\n\n“If you want to test whether a model is a good fit of your data you can use a goodness-of-fit test (you can read about these in the chapter on categorical data analysis in the book), which has a chi-square test statistic (with the associated distribution). One problem with this test is that it needs a certain sample size to be accurate. The K–S test was developed as a test of whether a distribution of scores matches a hypothesized distribution (Massey, 1951). One good thing about the test is that the distribution of the K–S test statistic does not depend on the hypothesized distribution (in other words, the hypothesized distribution doesn’t have to be a particular distribution). It is also what is known as an exact test, which means that it can be used on small samples. It also appears to have more power to detect deviations from the hypothesized distribution than the chi-square test (Lilliefors, 1967). However, one major limitation of the K–S test is that if location (i.e. the mean) and shape parameters (i.e. the standard deviation) are estimated from the data then the K–S test is very conservative, which means it fails to detect deviations from the distribution of interest (i.e. normal). What Lilliefors did was to adjust the critical values for significance for the K–S test to make it less conservative (Lilliefors, 1967) using Monte Carlo simulations (these new values were about two thirds the size of the standard values). He also reported that this test was more powerful than a standard chi-square test (and obviously the standard K–S test).\n\n\n\n\n\nAnother test you’ll use to test normality is the Shapiro-Wilk test (Shapiro & Wilk, 1965) which was developed specifically to test whether a distribution is normal (whereas the K–S test can be used to test against other distributions than normal). They concluded that their test was ‘comparatively quite sensitive to a wide range of non-normality, even with samples as small as n = 20. It seems to be especially sensitive to asymmetry, long-tailedness and to some degree to short-tailedness.’ (p. 608). To test the power of these tests they applied them to several samples (n = 20) from various non-normal distributions. In each case they took 500 samples which allowed them to see how many times (in 500) the test correctly identified a deviation from normality (this is the power of the test). They show in these simulations (see table 7 in their paper) that the S-W test is considerably more powerful to detect deviations from normality than the K–S test. They verified this general conclusion in a much more extensive set of simulations as well (Shapiro, Wilk, & Chen, 1968).” \n\n\n\n\n\nSo there you go. More people have probably read that now than when it was on the additional materials for the book. It Looks like Lillifor’s correction is a good thing (power wise) but you probably don’t want to be using K-S tests anyway really, or if you do interpret them within the context of the size of your sample and look at graphical displays of your scores too.\n\n\n\n\n\n\n\nCitationBibTeX citation:@online{field2012,\n  author = {Field, Andy},\n  title = {FAQ \\#1: {K-S} {Tests} in {SPSS}},\n  date = {2012-11-14},\n  url = {https://profandyfield.com/posts/2012_11_14_ks/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2012. “FAQ #1: K-S Tests in SPSS.” November\n14, 2012. https://profandyfield.com/posts/2012_11_14_ks/."
  },
  {
    "objectID": "posts/2017_01_03_stinkfiske/index.html",
    "href": "posts/2017_01_03_stinkfiske/index.html",
    "title": "StinkFiske",
    "section": "",
    "text": "Many of you will have seen former APS president Professor Susan Fiske’s recently leaked an opinion piece in the APS observer and the outcry it has caused. It’s been a bit of a StinkFiske.1\n1 I thought Tool fans would appreciate this label.I’m late in on this, but in my defence I have a 6 week old child to help keep alive and I’m on shared parental leave, so I’m writing this instead of, you know, enjoying one of the rare moments I get to myself. I really enjoyed (and agreed with) Andrew Gelman’s blog post about it, and there are other good pieces by, amongst others, Chris Chambers. I won’t pretend to have read other ones, so forgive me if I’m repeating someone else. It wouldn’t be the first time.\nThe Gelman and Chamber’s blogs will give you the background of why Fiske’s piece has caused such waves. I don’t want to retread old ground, so the short version is that she has basically accused a bunch of people (who she refuses to name) of being ‘methodological terrorists’ who go around ruining people’s careers by posting critiques on social media. She goes onto argue that this sort of criticism is better conducted in private behind the (let’s face it) wholly flawed peer review system. She cites anecdotal examples of students leaving science for fear that (shock horror) someone might criticise their work.\nThe situation hasn’t been helped by her choice of evocative language. Let’s be clear here, I don’t agree with anything Professor Fiske writes, or the way she wrote it. However, I think it has been interesting and useful in getting people to think about why she believes what she believes. I particularly recommend Gelman’s one for some insight into the whole history of the situation and his take on where Fiske might be coming from.2\n2 In general, Gelman’s blogs are well worth reading if you’re interested in statistics.I follow a lot of methodologists on Twitter and the ensuing carnage has been informative and thought-provoking. The reaction has tended to focus on the lack of evidence for the claims she makes, and counterarguments against her view. However much you might disagree with her view though, I think it plausibly represents the views of a great number of psychologists/scientists. As the days have gone on since I read Fiske’s piece I find myself less and less focussed on her individual view and more and more asking myself why people might share these views and what we need to do to douse the flames with white poppies.\n\nI want to start with an anecdote. My PhD and first couple of years of post doc was spent failing to replicate a bunch of studies that showed Evaluative Conditioning (essentially preference learning through association). I did a shit-tonne of experiments, they all failed to replicate the basic phenomenon. The original studies were by a group at KU Leuven. I tried to get them published, that didn’t go too well.3 I emailed the lead author (Frank Baeyens) throughout my PhD and he was always very helpful, constructive and open to discussing my failures - even after I published a paper suggesting that their results might have been an artefact of their methodology. The upshot was that they invited me (expenses paid) to Belgium to discuss things. Which we did. They then tried to kill me in the most merciful way they could think of: Belgian beer. My point is, they cared about science and about working out what was going on. We could sit down with a beer and forge long-standing friendships over our disagreements. It wasn’t personal - everyone just wanted to understand better the phenomenon we were trying (as best we both could) to capture.\n3 I did eventually get my 12 experiments published in the Netherlands Journal of Psychology in 2008, 10 years after completing my PhD, where it sank without trace.That’s how science should be: it’s about updating your beliefs as new evidence emerges and it’s not about the people doing it. Why is it that scientists feel so threatened by failed replications and re-analysis of their data? I’m going to brain dump some thoughts.\n \n\nI consider myself at least aligned with (and possibly a fully fledged member of) the “self-appointed data police”, but I have at times (the minority of times I hasten to add) found discussions of some work a bit ‘witch-hunty’. I have some sympathy for some people feeling attacked. However, as someone who keeps a fairly close eye on methodological stuff and follows quite a lot of people who I suspect Fiske was directing her polemic at, on the whole people are civil and really just want to make science better.4 I really believe that the data police have their hearts in the right place. Yes, statisticians have hearts.\n4 The exceptions are the daily spats between some frequentists and Bayesians who seem to thrive on being rude to each other. \n\nI think one reason why people might share Fiske’s views is that critiques tend to garner more interest when they change the conclusions of the study negatively, and because of the well-known selection bias for significant studies this invariably entails ‘look, the significant effect is not significant when the data police do things properly’. Wouldn’t it be fun, just for a change, to have a critique along the lines of ‘I did something the authors didn’t think of to improve the analysis, and the original conclusions stand up’. Let’s really let our imaginations wander to scenarios along the lines of ‘We re-examined this study of null results using some reasonable subjective priors to obtain Bayesian estimates of the model parameters and there’s greater evidence than the authors thought that the substantive effect under investigation could be big enough to warrant further investigation.’ In this last case, no-one would be doubting the integrity of the original authors but, other things being equal, there’s no difference in any of these situations: there’s data, there’s one analysis of it and some conclusions, then another analysis of it and some other conclusions.\nMy point is that researchers are likely to feel less defensive, if the focus or re-analysis within our discipline broadens from de-bunking. Re-analysis that reaches the same conclusions as the original paper has just as much value as debunking, but either the data police don’t do that sort of thing, or when we do no-one pays it any attention. We can’t control hits and retweets (and a good debunking story is always going to generate interest) but we can affect the broader culture of critique and make it more neutral.\nWe also need to get away from this notion of doing analysis the correct way. Of course there are ways to do things incorrectly, but there is rarely one correct way. In a recent study by Silberzahn et al 61 data analysts were given the same dataset and research question and asked to analyse the data resulting in a variety of models fit to the data. We can usefully re-analyse data/conclusions without falling into the judgemental terminology of correct/incorrect.\nWe need ‘re-analysing data’ to become a norm rather than the current exceptions that get widely publicised because they challenge the conclusions of the paper in a bad way. To make it a norm, we need new a whole new system really because as click-baity as retractions are, science is about updating beliefs in the light of new evidence. Surely that ethos is best served by papers that are open to re-analysis, commentary and debate. Some hurdles are how to stop that debate getting buried, and how to reward/incentivise that debate (i.e. give people credit for the time they spend contributing to these ongoing discussions of theories). It feels like the traditional system on peer-reviewed ‘articles’ that stand as static documents of ‘truth’ poorly serves these aims. Quite how we create the sea change necessary to think of, present, and cite ‘journal articles’ that are dynamic pieces of knowledge in a constant state of flux is another matter. Of course, there is also the question of how we re-invent CVs because we all know how much academics love their CVs and all of the incentive structures currently favour lists of ‘static’ knowledge.\n \n\nThe second reason why I think some people might have sympathy with Fiske’s views is that many scientists find it difficult to disentangle critique of their work from accusations of dishonesty. It is understandable that emotions run high: academia is not a job it’s a way of life, and for most of us the line between home and work is completely blurred. We invest emotionally in what we do, and criticism of your work can feel like criticism of you.5 In psychology at least, the situation isn’t helped by the selective nature of methodological critique in recent years (see above) and the very public cases of actual misconduct unearthed through methodological critique (insert your own example here, but Diederik Stapel is possibly the most famous).6 I think we could all benefit from accepting that being a scientist is an ongoing learning curve. If we knew everything, there would be no point in us doing our jobs.\n5 Should you ever need a case study then come up to me and slag off one of my recent textbooks (old editions are fair game, even I think they’re crap), I will probably cry.6 English readers can enjoy a translation of his autobiography thanks to Nick BrownLet me give you a personal example. I am regarded by some as a statistics ‘expert’ (at least within Psychology), which of course is a joke because I have no formal training in statistics. Nevertheless, I like statistics more than I like psychology, and I enjoy learning about it. My textbooks are a document of my learning. If I could create a black hole that would suck editions 1 to 3 of my SPSS book into it, I happily would because they contain some fairly embarrassing things that reflect what I thought at the time was the ‘truth’. I didn’t know any better, but I do now. Give me a dataset now and I’ll do a much better job of analysing it than I would have in 1998 when I started writing the SPSS book. Three years ago I didn’t have a clue what Bayesian statistics was, these days I still don’t, but I get the gist and have some vague sense of how to apply it in a way that I think (hopefully) isn’t wrong. Perhaps I should be embarrassed that I needed to ask Richard Morey to critique the Bayesian bits of my last textbook, and that he found areas where my understanding was off, but I learnt a lot from it. Likewise, someone reanalysing my data I hope, teaches me something. Andrew Gelman makes a similar point. Let’s not see re-analysis as judgement of competence, because we are all at the mercy of our knowledge base at any given time. My knowledge base of statistics in 2016 is different to in 1998, so let re-analysis be about helping people to improve how they do their job.\nIf we accept that scientists are on a learning curve then they will make mistakes. I don’t believe that most scientists are dishonest, but I do believe that they make honest mistakes that are perpetuated by (1) poor education, and (2) the wrong incentive structures.\n \n\nAnecdotally, I get hundreds of emails a year asking statistics questions from people aspiring to publish their research (not just in psychology). None of them seem dishonest, but some of them certainly harbour some misconceptions about data analysis and what’s appropriate. Hoekstra, Kiers, and Johnson (2012) provide some evidence for researchers not routinely checking the assumptions of their models, but again I think this likely reflects perceived norms or poor education than it does malpractice.\nIt is of course ridiculous that we are expected to be both expert theoreticians in some specialist area of a discipline and simultaneously remain at the cutting edge of ever-increasingly complex statistical tools. It’s bonkers, it really is. I’ve reached the point where I spend so much time thinking/reading/doing statistics that I barely have room in my head for psychology. Within this context, I am certain that people are trying their best with their data, but let’s be clear - they are up against it for many reasons and there will always be some a-hole like me who has abandoned psychology for a life of nitpicking everyone else’s analyses.\nOne major obstacle is the perpetuation of poor practice. The problem of education boils down to the fact that training in psychological research methods and data analysis tends to be quite rule-based. I did a report for the HEA a few years back on statistics teaching in UK psychology degree programmes (Field 2014). There is amazing consistency in what statistical methods are taught to undergraduate psychologists in the UK, and it won’t surprise anyone that it is very based on Null Hypothesis Significance Testing (NHST), p values etc. Relatively few institutions delve into effect sizes, or Bayesian approaches. There’s nothing necessarily wrong with teaching NHST (I say this mainly to wind up the Bayesian’s on Twitter …) because it is so widely used, but it is important to also teach its limitations and to offer alternative approaches. It’s not clear how much this is done, but I think awareness of the issues has radically increased compared to when I was a postgraduate in 1763.\nOne problem that teaching NHST does create is that it is very easy to be recipe-book about it: if you don’t understand what you’re doing just look at p and follow the rule. Of course, I’m absolutely guilty of this in my textbooks because it is such an easy trap to fall into.7 The nuances of NHST are tricky, so for students who struggle with statistics the line of least resistance is ‘follow this simple rule’. For those that then go onto PhDs, and are supervised by people who also blindly follow the rules (because that’s what they were taught too), and who are then incentivised to get ‘significant results’ (see later) you have, frankly, a recipe for disaster.\n7 In my defence, I have over the years tried hard to lace my books with a healthy dose of critique of blindly following p value based decision rules, but even so …There are many reasons why NHST is so prevalent in teaching and research. I wrote a blog in 2012 that is strangely relevant here (and until I’m proved otherwise, I believe to be the first recorded use of the word ‘fuckwizardy’, which I’m disappointed hasn’t caught on, so give it a read and insert that word liberally into conversation from now on - thanks). In it, I gave a few ideas about why NHST is so prevalent in psychological science, and why that will be slow to change. The take home points were: (1) researchers don’t have time to be experts on statistics and their research topic (see above); (2) people tend to teach what they know, modules have to fit in with other modules/faculty expertise, so deviating from decades of established research/teaching practice is difficult; (3) as long as reviewers/journals don’t update their own statistics knowledge we’re stuck between a rock and hard place if we start deviating from the norm; (4) textbooks tend to tow a conservative line (ahem!).\nA problem I didn’t mention in that blog is that some teachers don’t themselves understand what they’re teaching. Haller and Kraus (2002) (and Oakes (1986) before them) showed that 80% of methodology instructors and 90% of active researchers held one misconception about the p value. Similarly, a study by Belia et al. (2005) showed that researchers have difficulty interpreting confidence intervals. So, poor education perpetuates poor education. Of course, we need to try to improve training for the future generations of researchers, but for those for whom it’s too late, open and constructive critique offers a way to help them not keep making the same mistakes. However, critique needs to be more ‘there are a multitude of reasons why you probably did it your way, but let me show you an alternative’ and a bit less ‘you are stupid for not using Bayes’.\nIn the long term though, improving our statistical literacy/training will result in better-informed reviewers and editors in the future. Bad practice will wither as the ‘norms’ progress beyond the recipe book.\n \n\nAnother reason why people might ‘in good faith’ make poor data-based decisions is because the incentive structures in academia are completely screwy: individuals are incentivised, good science is not. Promotions are based on publications and grants, grants are based (to some extent) on likely success and track record (which of course is indexed by publications), and publications are - as is well known - hugely skewed towards significant results. Of course, academics are supposed to be great teachers, engage with the community and all that, but ask anyone in an academic job what matters when it comes to promotion and it’ll be grants and publications.8\n8 In 2010 when I was promoted to professor I had to go through an interview process as the final formality. The research side of my CV was as you would expect to get a chair; however, unlike comparable applications I had a lot more teaching stuff including my textbooks and a National Teaching fellowship (I was one of only 4–5 people in the entire university to have one of those at the time). During my interview my teaching was not mentioned once - it was all about grants, research leadership etc.Scientists are rewarded for publishable results, and publishable results invariable means significant results. Mix this with poor training (i.e. awareness of things like p-hacking) and you can see how easily (even with the best intentions) researcher degrees of freedom can filter into data analysis. This is why registered reports are such a brilliant idea because they do a decent job of incentivising ideas/methods above the results. Also it offers an opportunity to correct well-intentioned but poor data-analysis practice before data are collected and analysed.\nI actually think incentive structures in academia need a massive overhaul to put science as the priority, but that’s a whole other stream of consciousness …\n \n\nThis has ended up as a much more directionless rant than I planned, and it’s now time to go and get my 2-year old from nursery so I need to wrap up. I think my main point would be that open critique of science is essential, not because people are dishonest and we need to flush out that dishonesty, but because many scientists are doing the best they can, using what they’ve been taught. In many cases, they won’t even realise the mistakes they’re making, public conversation can help them, but it should be in the spirit of improvement. Second, let’s change the incentive structures in science away from the individual and towards the collective. Finally, everyone practice open science because it’s awesome."
  },
  {
    "objectID": "posts/2017_01_03_stinkfiske/index.html#stinkfiske",
    "href": "posts/2017_01_03_stinkfiske/index.html#stinkfiske",
    "title": "StinkFiske",
    "section": "",
    "text": "Many of you will have seen former APS president Professor Susan Fiske’s recently leaked an opinion piece in the APS observer and the outcry it has caused. It’s been a bit of a StinkFiske.1\n1 I thought Tool fans would appreciate this label.I’m late in on this, but in my defence I have a 6 week old child to help keep alive and I’m on shared parental leave, so I’m writing this instead of, you know, enjoying one of the rare moments I get to myself. I really enjoyed (and agreed with) Andrew Gelman’s blog post about it, and there are other good pieces by, amongst others, Chris Chambers. I won’t pretend to have read other ones, so forgive me if I’m repeating someone else. It wouldn’t be the first time.\nThe Gelman and Chamber’s blogs will give you the background of why Fiske’s piece has caused such waves. I don’t want to retread old ground, so the short version is that she has basically accused a bunch of people (who she refuses to name) of being ‘methodological terrorists’ who go around ruining people’s careers by posting critiques on social media. She goes onto argue that this sort of criticism is better conducted in private behind the (let’s face it) wholly flawed peer review system. She cites anecdotal examples of students leaving science for fear that (shock horror) someone might criticise their work.\nThe situation hasn’t been helped by her choice of evocative language. Let’s be clear here, I don’t agree with anything Professor Fiske writes, or the way she wrote it. However, I think it has been interesting and useful in getting people to think about why she believes what she believes. I particularly recommend Gelman’s one for some insight into the whole history of the situation and his take on where Fiske might be coming from.2\n2 In general, Gelman’s blogs are well worth reading if you’re interested in statistics.I follow a lot of methodologists on Twitter and the ensuing carnage has been informative and thought-provoking. The reaction has tended to focus on the lack of evidence for the claims she makes, and counterarguments against her view. However much you might disagree with her view though, I think it plausibly represents the views of a great number of psychologists/scientists. As the days have gone on since I read Fiske’s piece I find myself less and less focussed on her individual view and more and more asking myself why people might share these views and what we need to do to douse the flames with white poppies.\n\nI want to start with an anecdote. My PhD and first couple of years of post doc was spent failing to replicate a bunch of studies that showed Evaluative Conditioning (essentially preference learning through association). I did a shit-tonne of experiments, they all failed to replicate the basic phenomenon. The original studies were by a group at KU Leuven. I tried to get them published, that didn’t go too well.3 I emailed the lead author (Frank Baeyens) throughout my PhD and he was always very helpful, constructive and open to discussing my failures - even after I published a paper suggesting that their results might have been an artefact of their methodology. The upshot was that they invited me (expenses paid) to Belgium to discuss things. Which we did. They then tried to kill me in the most merciful way they could think of: Belgian beer. My point is, they cared about science and about working out what was going on. We could sit down with a beer and forge long-standing friendships over our disagreements. It wasn’t personal - everyone just wanted to understand better the phenomenon we were trying (as best we both could) to capture.\n3 I did eventually get my 12 experiments published in the Netherlands Journal of Psychology in 2008, 10 years after completing my PhD, where it sank without trace.That’s how science should be: it’s about updating your beliefs as new evidence emerges and it’s not about the people doing it. Why is it that scientists feel so threatened by failed replications and re-analysis of their data? I’m going to brain dump some thoughts.\n \n\nI consider myself at least aligned with (and possibly a fully fledged member of) the “self-appointed data police”, but I have at times (the minority of times I hasten to add) found discussions of some work a bit ‘witch-hunty’. I have some sympathy for some people feeling attacked. However, as someone who keeps a fairly close eye on methodological stuff and follows quite a lot of people who I suspect Fiske was directing her polemic at, on the whole people are civil and really just want to make science better.4 I really believe that the data police have their hearts in the right place. Yes, statisticians have hearts.\n4 The exceptions are the daily spats between some frequentists and Bayesians who seem to thrive on being rude to each other. \n\nI think one reason why people might share Fiske’s views is that critiques tend to garner more interest when they change the conclusions of the study negatively, and because of the well-known selection bias for significant studies this invariably entails ‘look, the significant effect is not significant when the data police do things properly’. Wouldn’t it be fun, just for a change, to have a critique along the lines of ‘I did something the authors didn’t think of to improve the analysis, and the original conclusions stand up’. Let’s really let our imaginations wander to scenarios along the lines of ‘We re-examined this study of null results using some reasonable subjective priors to obtain Bayesian estimates of the model parameters and there’s greater evidence than the authors thought that the substantive effect under investigation could be big enough to warrant further investigation.’ In this last case, no-one would be doubting the integrity of the original authors but, other things being equal, there’s no difference in any of these situations: there’s data, there’s one analysis of it and some conclusions, then another analysis of it and some other conclusions.\nMy point is that researchers are likely to feel less defensive, if the focus or re-analysis within our discipline broadens from de-bunking. Re-analysis that reaches the same conclusions as the original paper has just as much value as debunking, but either the data police don’t do that sort of thing, or when we do no-one pays it any attention. We can’t control hits and retweets (and a good debunking story is always going to generate interest) but we can affect the broader culture of critique and make it more neutral.\nWe also need to get away from this notion of doing analysis the correct way. Of course there are ways to do things incorrectly, but there is rarely one correct way. In a recent study by Silberzahn et al 61 data analysts were given the same dataset and research question and asked to analyse the data resulting in a variety of models fit to the data. We can usefully re-analyse data/conclusions without falling into the judgemental terminology of correct/incorrect.\nWe need ‘re-analysing data’ to become a norm rather than the current exceptions that get widely publicised because they challenge the conclusions of the paper in a bad way. To make it a norm, we need new a whole new system really because as click-baity as retractions are, science is about updating beliefs in the light of new evidence. Surely that ethos is best served by papers that are open to re-analysis, commentary and debate. Some hurdles are how to stop that debate getting buried, and how to reward/incentivise that debate (i.e. give people credit for the time they spend contributing to these ongoing discussions of theories). It feels like the traditional system on peer-reviewed ‘articles’ that stand as static documents of ‘truth’ poorly serves these aims. Quite how we create the sea change necessary to think of, present, and cite ‘journal articles’ that are dynamic pieces of knowledge in a constant state of flux is another matter. Of course, there is also the question of how we re-invent CVs because we all know how much academics love their CVs and all of the incentive structures currently favour lists of ‘static’ knowledge.\n \n\nThe second reason why I think some people might have sympathy with Fiske’s views is that many scientists find it difficult to disentangle critique of their work from accusations of dishonesty. It is understandable that emotions run high: academia is not a job it’s a way of life, and for most of us the line between home and work is completely blurred. We invest emotionally in what we do, and criticism of your work can feel like criticism of you.5 In psychology at least, the situation isn’t helped by the selective nature of methodological critique in recent years (see above) and the very public cases of actual misconduct unearthed through methodological critique (insert your own example here, but Diederik Stapel is possibly the most famous).6 I think we could all benefit from accepting that being a scientist is an ongoing learning curve. If we knew everything, there would be no point in us doing our jobs.\n5 Should you ever need a case study then come up to me and slag off one of my recent textbooks (old editions are fair game, even I think they’re crap), I will probably cry.6 English readers can enjoy a translation of his autobiography thanks to Nick BrownLet me give you a personal example. I am regarded by some as a statistics ‘expert’ (at least within Psychology), which of course is a joke because I have no formal training in statistics. Nevertheless, I like statistics more than I like psychology, and I enjoy learning about it. My textbooks are a document of my learning. If I could create a black hole that would suck editions 1 to 3 of my SPSS book into it, I happily would because they contain some fairly embarrassing things that reflect what I thought at the time was the ‘truth’. I didn’t know any better, but I do now. Give me a dataset now and I’ll do a much better job of analysing it than I would have in 1998 when I started writing the SPSS book. Three years ago I didn’t have a clue what Bayesian statistics was, these days I still don’t, but I get the gist and have some vague sense of how to apply it in a way that I think (hopefully) isn’t wrong. Perhaps I should be embarrassed that I needed to ask Richard Morey to critique the Bayesian bits of my last textbook, and that he found areas where my understanding was off, but I learnt a lot from it. Likewise, someone reanalysing my data I hope, teaches me something. Andrew Gelman makes a similar point. Let’s not see re-analysis as judgement of competence, because we are all at the mercy of our knowledge base at any given time. My knowledge base of statistics in 2016 is different to in 1998, so let re-analysis be about helping people to improve how they do their job.\nIf we accept that scientists are on a learning curve then they will make mistakes. I don’t believe that most scientists are dishonest, but I do believe that they make honest mistakes that are perpetuated by (1) poor education, and (2) the wrong incentive structures.\n \n\nAnecdotally, I get hundreds of emails a year asking statistics questions from people aspiring to publish their research (not just in psychology). None of them seem dishonest, but some of them certainly harbour some misconceptions about data analysis and what’s appropriate. Hoekstra, Kiers, and Johnson (2012) provide some evidence for researchers not routinely checking the assumptions of their models, but again I think this likely reflects perceived norms or poor education than it does malpractice.\nIt is of course ridiculous that we are expected to be both expert theoreticians in some specialist area of a discipline and simultaneously remain at the cutting edge of ever-increasingly complex statistical tools. It’s bonkers, it really is. I’ve reached the point where I spend so much time thinking/reading/doing statistics that I barely have room in my head for psychology. Within this context, I am certain that people are trying their best with their data, but let’s be clear - they are up against it for many reasons and there will always be some a-hole like me who has abandoned psychology for a life of nitpicking everyone else’s analyses.\nOne major obstacle is the perpetuation of poor practice. The problem of education boils down to the fact that training in psychological research methods and data analysis tends to be quite rule-based. I did a report for the HEA a few years back on statistics teaching in UK psychology degree programmes (Field 2014). There is amazing consistency in what statistical methods are taught to undergraduate psychologists in the UK, and it won’t surprise anyone that it is very based on Null Hypothesis Significance Testing (NHST), p values etc. Relatively few institutions delve into effect sizes, or Bayesian approaches. There’s nothing necessarily wrong with teaching NHST (I say this mainly to wind up the Bayesian’s on Twitter …) because it is so widely used, but it is important to also teach its limitations and to offer alternative approaches. It’s not clear how much this is done, but I think awareness of the issues has radically increased compared to when I was a postgraduate in 1763.\nOne problem that teaching NHST does create is that it is very easy to be recipe-book about it: if you don’t understand what you’re doing just look at p and follow the rule. Of course, I’m absolutely guilty of this in my textbooks because it is such an easy trap to fall into.7 The nuances of NHST are tricky, so for students who struggle with statistics the line of least resistance is ‘follow this simple rule’. For those that then go onto PhDs, and are supervised by people who also blindly follow the rules (because that’s what they were taught too), and who are then incentivised to get ‘significant results’ (see later) you have, frankly, a recipe for disaster.\n7 In my defence, I have over the years tried hard to lace my books with a healthy dose of critique of blindly following p value based decision rules, but even so …There are many reasons why NHST is so prevalent in teaching and research. I wrote a blog in 2012 that is strangely relevant here (and until I’m proved otherwise, I believe to be the first recorded use of the word ‘fuckwizardy’, which I’m disappointed hasn’t caught on, so give it a read and insert that word liberally into conversation from now on - thanks). In it, I gave a few ideas about why NHST is so prevalent in psychological science, and why that will be slow to change. The take home points were: (1) researchers don’t have time to be experts on statistics and their research topic (see above); (2) people tend to teach what they know, modules have to fit in with other modules/faculty expertise, so deviating from decades of established research/teaching practice is difficult; (3) as long as reviewers/journals don’t update their own statistics knowledge we’re stuck between a rock and hard place if we start deviating from the norm; (4) textbooks tend to tow a conservative line (ahem!).\nA problem I didn’t mention in that blog is that some teachers don’t themselves understand what they’re teaching. Haller and Kraus (2002) (and Oakes (1986) before them) showed that 80% of methodology instructors and 90% of active researchers held one misconception about the p value. Similarly, a study by Belia et al. (2005) showed that researchers have difficulty interpreting confidence intervals. So, poor education perpetuates poor education. Of course, we need to try to improve training for the future generations of researchers, but for those for whom it’s too late, open and constructive critique offers a way to help them not keep making the same mistakes. However, critique needs to be more ‘there are a multitude of reasons why you probably did it your way, but let me show you an alternative’ and a bit less ‘you are stupid for not using Bayes’.\nIn the long term though, improving our statistical literacy/training will result in better-informed reviewers and editors in the future. Bad practice will wither as the ‘norms’ progress beyond the recipe book.\n \n\nAnother reason why people might ‘in good faith’ make poor data-based decisions is because the incentive structures in academia are completely screwy: individuals are incentivised, good science is not. Promotions are based on publications and grants, grants are based (to some extent) on likely success and track record (which of course is indexed by publications), and publications are - as is well known - hugely skewed towards significant results. Of course, academics are supposed to be great teachers, engage with the community and all that, but ask anyone in an academic job what matters when it comes to promotion and it’ll be grants and publications.8\n8 In 2010 when I was promoted to professor I had to go through an interview process as the final formality. The research side of my CV was as you would expect to get a chair; however, unlike comparable applications I had a lot more teaching stuff including my textbooks and a National Teaching fellowship (I was one of only 4–5 people in the entire university to have one of those at the time). During my interview my teaching was not mentioned once - it was all about grants, research leadership etc.Scientists are rewarded for publishable results, and publishable results invariable means significant results. Mix this with poor training (i.e. awareness of things like p-hacking) and you can see how easily (even with the best intentions) researcher degrees of freedom can filter into data analysis. This is why registered reports are such a brilliant idea because they do a decent job of incentivising ideas/methods above the results. Also it offers an opportunity to correct well-intentioned but poor data-analysis practice before data are collected and analysed.\nI actually think incentive structures in academia need a massive overhaul to put science as the priority, but that’s a whole other stream of consciousness …\n \n\nThis has ended up as a much more directionless rant than I planned, and it’s now time to go and get my 2-year old from nursery so I need to wrap up. I think my main point would be that open critique of science is essential, not because people are dishonest and we need to flush out that dishonesty, but because many scientists are doing the best they can, using what they’ve been taught. In many cases, they won’t even realise the mistakes they’re making, public conversation can help them, but it should be in the spirit of improvement. Second, let’s change the incentive structures in science away from the individual and towards the collective. Finally, everyone practice open science because it’s awesome."
  },
  {
    "objectID": "posts/2016_04_28_ais/index.html",
    "href": "posts/2016_04_28_ais/index.html",
    "title": "If you’re not doing something different, you’re not doing anything at all.",
    "section": "",
    "text": "Yesterday was the official launch of my new textbook An Adventure in Statistics: The Reality Enigma. Although a few ‘print to order’ copies are floating about, the ‘proper’ hi-res print copies won’t be available for a few more weeks, but I thought it was a good opportunity to blog something about the book and perhaps textbook writing more generally. I’m going to start by telling you something about the book. Then I will try to give you an idea of the timeline and some rough statistics that probably don’t do justice to the emotional and physical investment that goes into a textbook."
  },
  {
    "objectID": "posts/2016_04_28_ais/index.html#a-history-of-an-adventure-in-statistics",
    "href": "posts/2016_04_28_ais/index.html#a-history-of-an-adventure-in-statistics",
    "title": "If you’re not doing something different, you’re not doing anything at all.",
    "section": "A history of An Adventure in Statistics",
    "text": "A history of An Adventure in Statistics\nVisualization guru (and sculptor) Edward Tufte apparently has a small sign taped to his computer screen that says “If you’re not doing something different, you’re not doing anything at all.” It’s a note that I don’t have taped to my monitor, but I probably should because I like ‘different’, and I strive for ‘different’ not always in a good way.\nIn 2008 I was in Rotterdam updating my SPSS book (third edition) and like all of my books I had a long list of things from the previous edition that I hated and wanted to change. It would be easy to just change the SPSS screenshots and slap a new cover on the front, but I wanted to do something different. After all “If you’re not doing something different, you’re not doing anything at all.”\nI thought it would be interesting to try to embed the academic content of the book within a fictional story. I didn’t have a story though, and I had only 6 months to update the book. It would be impossible. So I copped out: I book-ended each chapter with an anecdote from the only story I had to hand – my life. Some thought it was different, but to me it was a poor imitation of what I could have done.\nA couple of years later I was approached to write a stats book for the ‘for dummies’ range. I was tempted. I spoke to my editor at SAGE (who publish my statistics books) because of potential overlap with the SPSS book. This led to a conversation with Ziyad Marar who runs the London office of SAGE. I’ve known Ziyad a long time – he signed my first book – but trust me, he rarely phones me. That’s true of most people because I go to great lengths to tell everyone how uncomfortable telephones make me, but a call from Ziyad is a particularly rare and beautiful thing. The gist of that conversation was that Ziyad convinced me to write new book for SAGE instead. He said, something to the effect of:\n\n‘Why not write that book for us? We will let you do whatever you like express yourself fully.’ “What?” I asked, “You’d give me complete control even after ‘the incident’?” “Yes”. He replied (after what I like to mis-remember as a dramatic pause).\n\nZiyad was offering me the opportunity to set my imagination free, to go somewhere that perhaps other publishers would not let me go, to try something without needing to justify it with research, or pedagogy. An opportunity to follow my heart and not my head, but what did my heart want to do? I briefly considered whether it was possible to put even more penis jokes into a statistics textbook, but I’d been there, done that, worn the phallus and “If you’re not doing something different, you’re not doing anything at all.”\nI thought back to 2008, to the idea of writing a fictional story through which a student learns statistics through a shared adventure with the main character. I thought about collaborating with a graphic novel illustrator to bring the story to life. I didn’t know anything about writing fiction: but, I didn’t know anything about logistic regression and multilevel models before I wrote 60-page chapters about them. Not knowing something should never be an obstacle to writing about it.\nI got on board a badass illustrator, James Iles, to create graphic novel strips to bring the story to life. There have been a few pivotal moments during the book’s life but none more than the moment that James replied to my advert on freelancer.com. He fought off about 80 other applicants to get the gig, and although I deluded myself that the choice of illustrator was a complex, make-or-break, decision, my gut instinct always pointed to James. He’d done storyboarding for Doctor Who, and I fucking love Doctor Who. If James was good enough Doctor Who, he was certainly going to be good enough for me. Unknown to me at the time, I hadn’t just found an exceptionally talented artist, but I’d also found someone who would put as much passion and care into the book as I would."
  },
  {
    "objectID": "posts/2016_04_28_ais/index.html#what-is-an-adventure-in-statistics-all-about",
    "href": "posts/2016_04_28_ais/index.html#what-is-an-adventure-in-statistics-all-about",
    "title": "If you’re not doing something different, you’re not doing anything at all.",
    "section": "What is An Adventure in Statistics all about?",
    "text": "What is An Adventure in Statistics all about?\nAn adventure in statistics is set in a future in which the invention of the reality prism, a kind of hat that splits reality into the subjective and objective has bought society to collapse by showing everyone the truth. Without blind belief, no-one tried anymore. In the wake of this ‘reality revolution’ society fragmented into people who held onto the pre-technological past (the Clocktorians) and those who embraced the ever-accelerating technology of the new world (the chippers). Society had become a mix of the ultra-modern and the old fashioned.\nInto this world I put Zach, a rock musician, and his girlfriend Dr. Alice Nightingale. They are part of the first generation since the revolution to believe that they can change the world. Zach through his music, and Alice through her research. Then Alice suddenly disappears leaving Zach with a broken heart, a song playing on repeat and a scientific report that makes no sense to him. Fearing the worst, he sets out to find her. Strange things happen: people collapse and lose their memories, he gets messages from someone called Milton, and the word JIG:SAW haunts him. Zach feels that something is terribly wrong and that Alice is in danger, but her vanishing triggers an even worse thought: that after 10 years they have drifted apart.\nAt a simple level An Adventure in Statistics is a story about Zach searching for Alice, and seeking the truth, but it’s also about the unlikely friendship he develops with a sarcastic cat, it’s about him facing his fear of science and numbers, it’s about him learning to believe in himself. It’s a story about love, about not forgetting who you are. It’s about searching for the heartbeats that hide in the gaps between you and the people you love. It’s about having faith in others.\nOf course, it’s also about fitting models, robust methods, classical and Bayesian estimation, significance testing and whole bunch of other tedious statistical things, but hopefully you’ll be so engrossed in the story that you won’t notice them. Or they might be a welcome relief from the terrible fiction. Time will tell."
  },
  {
    "objectID": "posts/2016_04_28_ais/index.html#what-goes-into-creating-a-textbook",
    "href": "posts/2016_04_28_ais/index.html#what-goes-into-creating-a-textbook",
    "title": "If you’re not doing something different, you’re not doing anything at all.",
    "section": "What goes into creating a textbook?",
    "text": "What goes into creating a textbook?\nWhat does writing a textbook involve? That is hard to explain. For an adventure in statistics I really enjoyed the writing (especially the fictional story), on the whole it has been the most rewarding experience of my academic career. However, rest assured that if you decide to write a textbook, you will hit some motivational dark times. Very dark times.\n\nThe timeline\nI had the initial idea in 2008, I wrote the proposal in January 2011 (final version March 2011). The final contract with SAGE was signed in April 2011. Around this time, I started discussing with SAGE my idea to have graphic novel elements and a story. I started making notes about a potential story and characters in a black book and using Scrivener. I started writing in January 2014. By this point James Iles had just come on board. (SAGE are doing some videos where James and I discuss how we worked, so I won’t say more on that.) At the point that I started writing I had a lot of ideas, most of the characters in place and a decent idea of what would happen at the beginning and end of the story, and some bits in the middle. A lot of the story developed as I wrote. (One thing I learned in writing this book is that even though I thought I’d done a lot of planning, I should have done an awful lot more before writing the first word!) June 2014 my wife and I had our first child. I took unpaid paternity leave and did quite a long stretch of writing (4 months) where I’d spend the day doing dad stuff until about 3-4pm and then start work, writing until 1-3am. I generally work better at night. The first draft was finished around April 2015. We had feedback from a fiction editor (Gillian Stern) on the story which came to me May 2015. I did a re-draft of the entire book based on that, which I finished around August 2015. I then had a bunch more feedback on the story from Robin, my development editor at SAGE, and on the statistics stuff and story from my wife. I did a third and final draft which was submitted October 2015. January 2016 I received the copy editor’s comments for the entire book for approval (or not). March 2016 I received proofs of the entire book, which I spent 2-3 weeks reading/correcting working well into the night most nights. April 2016 I received the corrected proofs to approve. In a sense then, it’s consumed 8 years of my life (as an ambition), but really it’s more like 4 years of work, 2 of them intensive.\n\n\nThe anatomy of An Adventure in Statistics\n\nI don’t know exactly how many hours I spent on the book, but I spent probably 2 years casually collecting ideas and thoughts, and developing ideas for the structure and so on. I spent another 21 months pretty much doing not a lot else but writing or re-drafting the book. I had my university job to do as well, so it’s impossible to really know how many hours it took to create, but it’s probably somewhere in the region of 4000 hours. That’s just to the point of submitting the manuscript.\nI wrote 297,676 words, ~1.6 million characters, 13,421 paragraphs and 28,768 lines. In terms of word length that’s about 3-4 psychology PhD theses, or if you assume the average research paper is about 5000 words then it’s about 60 research papers. In 2 years. I will get precisely no credit in the REF for this activity. [I’m not saying I should, I’m just making the point that you really are putting your research career on hold and investing a lot of creativity/energy into something that isn’t valued by the system that universities value. I am fortunate to be able to do this but I think this is a really tough balancing act for early-career scientists who want to write books.]\nGiven the book had three drafts, and I had to read proofs, I have read at least 1.19 million of my own words. It’ll be a lot more than that because of stuff you write and then delete.\nI used Scrivener to plan the story. My project document in which I gathered ideas (e.g., plot ideas, character outlines, descriptions of locations, venues, objects, concepts, artwork ideas etc.) contains another 87,204 words and quite a few images – in addition to the 297,676 word in the book itself.\nI created 603 diagrams. [Not all of them are the book because this includes old versions of diagrams, and image files that I used in diagrams – for example, an image of a normal curve that I drop into a finished diagram]. I used Omnigraffle incidentally for my diagrams, and graphs and stat-y stuff would have been created using R, most often with ggplot2.\nI created 185 data-related files (data files, R-scripts etc.)\nI wrote ~4000 lines of R-code (to generate data, create graphs, run analyses etc.).\nAt some point I will have to produce a bunch of online stuff – powerpoint presentations, handouts, answers to tasks in the book etc.\nBasically, it was a lot of fucking work."
  },
  {
    "objectID": "posts/2016_04_28_ais/index.html#the-beginning-and-the-end",
    "href": "posts/2016_04_28_ais/index.html#the-beginning-and-the-end",
    "title": "If you’re not doing something different, you’re not doing anything at all.",
    "section": "The beginning and the end",
    "text": "The beginning and the end\n\n\n\nJames Iles (Right) and I (Left) at the book launch\n\n\nYesterday the book was launched: it is both a beginning and an end. Beginnings can be exciting. It is the beginning of the public life of An Adventure in Statistics. It might be the beginning of it being a well-received book? The beginning of it inspiring young scientists? The beginning of people thinking differently about teaching statistics? That’d be nice but my excitement is laced with fear because beginnings can be scary too: today could be the beginning of seeing the book through a reality prism that shows me the objective truth in the form of scathing reviews, poor sales, sympathetic looks, and five wasted years.\nYesterday was also an end. Primarily an end to my work on the book (well, apart from a bunch of online materials …). I have never liked endings. When I was a child and people would come to stay, I always felt hollow when they left. For over 2 years, the characters in this book – especially Zach, Alice, Milton and Celia – have been the houseguests of my mind. We’ve had a lot of fun times. We’ve worked hard and played hard. We’ve had lots of late night conversations, we’ve shared our deepest feelings, we’ve discussed life, and they’ve helped me to see the world through different eyes. Yesterday they left me to find their own way in the world and I’m going to miss them. I feel a little hollow. I never thought I’d miss writing a statistics textbook.\nIt’s a scary time. I am proud of and excited about the book, and of what James and I have created. I’m also a little terrified that no-one else will share my enthusiasm after all, it’s different to other statistics textbooks. People don’t always like ‘different’. Tufte’s words are a comfort though because if it’s true that “If you’re not doing something different, you’re not doing anything at all.” then I feel that, with An Adventure in Statistics I have at least done something.\nAndy\nSome of this blog is adapted from a speech I gave at the launch, which you can watch here"
  },
  {
    "objectID": "posts/2016_04_28_ais/index.html#links",
    "href": "posts/2016_04_28_ais/index.html#links",
    "title": "If you’re not doing something different, you’re not doing anything at all.",
    "section": "Links",
    "text": "Links\n\nDownload the preface and chapter 1.\nRead the article in the Times Higher Education Supplement about the book.\nThe book can be ordered direct from SAGE, or from your local Amazon or other retailer."
  },
  {
    "objectID": "posts/2014_10_31_oxytocin/index.html",
    "href": "posts/2014_10_31_oxytocin/index.html",
    "title": "Perhaps my oxytocin was low when I read this paper",
    "section": "",
    "text": "I’m writing a new textbook on introductory statistics, and I decided to include an example based on Paul Zak‘s intriguing work on the role of the hormone oxytocin in trust between strangers. In particular, I started looking at his 2005 paper in Nature (Kosfeld et al. 2005). Yes, Nature, one of the top science journals. A journal with an impact factor of about 38, and a rejection rate probably fairly close to 100%. It’s a journal you’d expect published pretty decent stuff and subjects articles to fairly rigorous scrutiny.\nBefore I begin, I have no axe to grind here with anyone. I just want to comment on some stuff I found and leave everyone else to do what they like with that information. I have no doubt Dr. Zak has done a lot of other work on which he bases his theory, I’m not trying to undermine that work, I’m more wanting to make a point about the state of the top journals in science. All my code here is for R.\nThe data I was looking at relates to an experiment in which participants were asked to invest money in a trustee (a stranger). If they invested, then the total funds for the investor and trustee increased. If the trustee shares the proceeds then both players end up better off, but if the trustee does not repay the investors’ trust by splitting the fund then the trustee ends up better off and the investor worse off. The question is, will investors trust the trustees to split the funds? If they do then they will invest, if not they won’t. Critically, one group of investors were exposed to exogenous oxytocin (N = 29), whereas a placebo group were not (N = 29). The oxytocin group invested significantly more than the placebo control group suggesting that oxytocin had causally influenced their levels of trust in the trustee. This is the sort of finding that the media loves.\nThe paper reports a few experiments, I want to focus on the data specifically related to trust shown in Figure 2a (reproduced below):\n\n\nFigure 2a from Kosfeld et al.\n\nThe good thing about this figure is that it shows relative frequencies, which means that with the aid of a ruler and a spreadsheet we can reconstruct the data. Based on the figure the raw data is as follows:\n\nlibrary(tidyverse)\n\nplacebo &lt;- tibble(\n  Group = \"Placebo\",\n  MU = c(3, 3, 4, 4, 4, 5, 6, 6, 6, 6, 6, 7, 7, 8, 8, 9, 9, 11, 11, 11, 12, 12, 12, 12, 12, 12),\n) \n\noxytocin &lt;- tibble(\n  Group = \"Oxytocin\",\n  MU = c(3, 4, 4, 6, 6, 7, 8, 8, 8, 8, 9, 9, 10, 10, 10, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12)\n) \n\nzak &lt;- bind_rows(placebo, oxytocin) |&gt; \n  mutate(\n    Group = as_factor(Group)\n  )\n\nThe problem being that this gives us only N = 26 in the placebo group. Bollocks! Ok, well perhaps they reported the wrong N. Here’s their table of descriptives:\n\nLet’s have a look at the descriptives I get:\n\nzak_tbl &lt;- zak |&gt; \n  group_by(Group) |&gt; \n  summarize(\n    Mean = mean(MU), \n    Median = median(MU),\n    SD = sd(MU),\n    N = n()\n  )\n\n\nknitr::kable(zak_tbl, dp = 1)\n\n\n\nGroup\nMean\nMedian\nSD\nN\n\n\n\nPlacebo\n7.923077\n7.5\n3.186510\n26\n\n\nOxytocin\n9.551724\n10.0\n2.848386\n29\n\n\n\n\n\nFor the oxytocin group the mean, median and SD match, but for the placebo group they don’t. Hmmm. So, there must be missing cases. Based on where the median is, I guessed that the three missing cases might be values of 10. In other words, Figure 2a in the paper, ought to look like this:\n\n\nFigure 2a from Kosfeld et al.\n\nSo, let’s adjust placebo group data and recalculate the summary stats:\n\nzak &lt;- zak |&gt; \n  add_row(Group = \"Placebo\", MU = 10) |&gt; \n  add_row(Group = \"Placebo\", MU = 10) |&gt; \n  add_row(Group = \"Placebo\", MU = 10)\n\nzak_tbl &lt;- zak |&gt; \n  group_by(Group) |&gt; \n  summarize(\n    Mean = mean(MU), \n    Median = median(MU),\n    SD = sd(MU),\n    N = n()\n  )\n\n\nknitr::kable(zak_tbl, dp = 1)\n\n\n\nGroup\nMean\nMedian\nSD\nN\n\n\n\nOxytocin\n9.551724\n10\n2.848386\n29\n\n\nPlacebo\n8.137931\n8\n3.079009\n29\n\n\n\n\n\nThey now match the table in the paper. So, this gives me confidence that I have probably correctly reconstructed the raw data despite Figure 2’s best efforts to throw me off of the scent. Of course, I could be wrong. Let’s see if my figures match their analysis. They did a Mann-Whitney U that yielded a p-value of 0.05887, which they halved to report one-tailed as .029. Notwithstanding the fact that you probably shouldn’t do one-tailed tests, ever, they conclude a significant between group difference. I replicate their p-value, again convincing me that my reconstructed data matches their raw data:\n\nwilcox.test(MU~Group, zak)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  MU by Group\nW = 540, p-value = 0.05887\nalternative hypothesis: true location shift is not equal to 0\n\n\nSo, all well and good. There are better ways to look at this than a Mann-Whitney test though, so let’s use some of Rand Wilcox’s robust tests. First off, a trimmed mean and bootstrap:\n\nlibrary(WRS2)\n\nyuenbt(MU~Group, data = zak, tr=.2, alpha=.05, nboot = 2000, side = T)\n\nCall:\nyuenbt(formula = MU ~ Group, data = zak, tr = 0.2, nboot = 2000, \n    side = T, alpha = 0.05)\n\nTest statistic: 1.7731 (df = NA), p-value = 0.057\n\nTrimmed mean difference:  1.89474 \n95 percent confidence interval:\n-0.0832     3.8727 \n\n\nGives us a similar p-value to the Mann-Whitney and a confidence interval for the difference that contains zero. However, the data are very skewed indeed: Perhaps we’re better off comparing the medians of the two groups. (Medians are no-where near as biased by skew as means):\n\npb2gen(MU~Group, data = zak, alpha=.05, nboot=2000, est = \"median\")\n\nCall:\npb2gen(formula = MU ~ Group, data = zak, est = \"median\", nboot = 2000, \n    alpha = 0.05)\n\nTest statistic: 2, p-value = 0.1915\n95% confidence interval:\n-1    6 \n\n\nThe p-value is now a larger .179 (which even if you decide to halve it won’t get you below the, not very magic, .05 threshold for significance). So, the means might be significantly different depending on your view of one-tailed tests, but the medians certainly are not. Of course null hypothesis significance testing is bollocks anyway (see my book, or this blog) so maybe we should just look at the effect size. Or maybe we shouldn’t because the group means and SDs will be biased by the skew (SDs especially because you square the initial bias to compute it). Cohen’s d is based on means and SDs so if these statistics are biased then d will be too. I did it anyway though, just for a laugh:\n\nlibrary(effectsize)\ncohens_d(MU~Group, data = zak)\n\nCohen's d |        95% CI\n-------------------------\n0.48      | [-0.05, 1.00]\n\n- Estimated using pooled SD.\n\n\nThe result? About half a standard deviation difference (notwithstanding the bias). That’s not too shabby, although it’d be even more un-shabby if the estimate wasn’t biased. Finally, and notwithstanding various objections to using uninformed priors in Bayesian analysis) we can use the BayesFactor packaged to work out a Bayes Factor.\n\nlibrary(BayesFactor)\nttestBF(formula = MU~Group, data = zak)\n\nBayes factor analysis\n--------------\n[1] Alt., r=0.707 : 1.037284 ±0.01%\n\nAgainst denominator:\n  Null, mu1-mu2 = 0 \n---\nBayes factor type: BFindepSample, JZS\n\n\nThe Bayes factor is 1.03, which means that there is almost exactly equal evidence for the null hypothesis as the alternative hypothesis. In other words, there is no support for the hypothesis that oxytocin affected trust.\nSo, Nature, one of the top journals in science, published a paper where the evidence for oxytocin affecting trust was debatable at best. Let’s not even get into the fact that this was based on N = 58. Like I said, I’m sure Dr. Zak has done many other studies and I have no interest in trying to undermine what he or his colleagues do, I just want to comment on this isolated piece of research and offer an alternative interpretation of the data. There’s lots of stuff I’ve done myself that with the benefit of experience I’d rather forget about, so, hey, I’m not standing on any kind of scientific high ground here. What I would say is that in this particular study, based on the things least affected by the shape of the data (medians) and a (admittedly using uninformed priors) Bayesian analysis there is not really a lot of evidence that oxytocin affected trust.\n\n\n\n\n\n\n\nReferences\n\nKosfeld, Michael, Markus Heinrichs, Paul J. Zak, Urs Fischbacher, and Ernst Fehr. 2005. “Oxytocin Increases Trust in Humans.” Nature 435 (7042): 673–76. https://doi.org/10.1038/nature03701.\n\nCitationBibTeX citation:@online{field2014,\n  author = {Field, Andy},\n  title = {Perhaps My Oxytocin Was Low When {I} Read This Paper},\n  date = {2014-10-31},\n  url = {https://profandyfield.com/posts/2014_10_31_oxytocin/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nField, Andy. 2014. “Perhaps My Oxytocin Was Low When I Read This\nPaper.” October 31, 2014. https://profandyfield.com/posts/2014_10_31_oxytocin/."
  },
  {
    "objectID": "posts/2016_03_29_sepultura/index.html",
    "href": "posts/2016_03_29_sepultura/index.html",
    "title": "Max or No Max?",
    "section": "",
    "text": "There’s been a recent spat between the heavy metal bands Sepultura and Soulfly. For those unaware of the history, 50% of Sepulture used to be the Cavalera brothers (Max and Igor) until Max (the frontman and guitarist) left the band in 1996 and formed Soulfly. The full story is here. There’s a lot of bad blood even 20 years later, and according to a recent story on metal sucks, Soulfly’s manager (and Max’s wife) Gloria Cavalier recently posted a fairly pointed post on her Facebook page. This got picked up by my favourite podcast (the metal sucks podcast). What has this got to do with me, or statistics? Well, one of the presenters of the metal sucks podcasts asked me this over Twitter:\nAfter a very brief comment about needing to operationalise ‘better’, I decided that rather than reading book proofs I’d do a tongue in cheek analysis of what is better max or no max and here it is.\nFirst we need to operationalise ‘better’. I have done this by accepting subjective opinion as determining ‘better’ and specifically ratings of albums on amazon.com (although I am English metal sucks is US based, so I thought I’d pander to them and take ratings from the US site). Our questions then becomes ‘is max or no max rated higher by the sorts of people who leave reviews on Amazon’. We have operationalised our questions and turned it into a scientific statement, which we can test with data. [There are all sorts of problems with using these ratings, not least of which is that they tend to be positively biased, and they likely reflect a certain type of person who reviews, often reviews reflect things other than the music (e.g., arrived quickly 5*), and so on … but fuck it, this is not serious science, just a bit of a laugh.]\nYou can generate the data using this R code (data correct as of today):\nCodelibrary(tidyverse)\n\ncreate_tibble &lt;- function(name, year, data){\n  tibble::tibble(\n    Album = rep(name, length(data)),\n    Year = rep(year, length(data)),\n    Rating = data\n  )\n}\n\nmorbid &lt;- create_tibble(\"Morbid\", \"1986\", c(rep(1,2), rep(2, 4), rep(3, 3), rep(4, 8), rep(5, 36)))\nschizo &lt;- create_tibble(\"Schizo\", \"1987\",  c(rep(1,1), rep(2, 2), rep(3, 4), rep(4, 10), rep(5, 33)))\nremains &lt;- create_tibble(\"Remains\", \"1989\",  c(2, rep(3, 5), rep(4, 9), rep(5, 104)))\narise &lt;- create_tibble(\"Arise\", \"1991\", c(rep(2, 2), rep(4, 16), rep(5, 89)))\nchaos &lt;- create_tibble(\"Chaos\", \"1993\", c(rep(1,4), rep(2, 2), rep(3, 9), rep(4, 20), rep(5, 120)))\nroots &lt;- create_tibble(\"Roots\", \"1996\", c(rep(1,9), rep(2, 8), rep(3, 17), rep(4, 24), rep(5, 94)))\nagainst &lt;- create_tibble(\"Against\", \"1998\", c(rep(1,16), rep(2, 14), rep(3, 11), rep(4, 20), rep(5, 32)))\nnation &lt;- create_tibble(\"Nation\", \"2001\", c(rep(1,3), rep(2, 7), rep(3, 6), rep(4, 22), rep(5, 19)))\nroorback &lt;- create_tibble(\"Roorback\", \"2003\", c(rep(1,6), rep(2, 6), rep(3, 5), rep(4, 13), rep(5, 20)))\ndante &lt;- create_tibble(\"Dante\", \"2006\", c(rep(1,1), rep(2, 3), rep(3, 4), rep(4, 8), rep(5, 30)))\nalex &lt;- create_tibble(\"Alex\", \"2009\", c(rep(1,1), rep(2, 1), rep(3, 3), rep(4, 6), rep(5, 18)))\nkairos &lt;- create_tibble(\"Kairos\", \"2011\", c(rep(1,3), rep(2, 2), rep(3, 2), rep(4, 6), rep(5, 33)))\nmediator &lt;- create_tibble(\"Mediator\", \"2013\", c(rep(1,0), rep(2, 3), rep(3, 4), rep(4, 6), rep(5, 21)))\n  \nsepultura &lt;- rbind(morbid, schizo, remains, arise, chaos, roots, against, nation, dante, alex, kairos, mediator) |&gt; \n  dplyr::mutate(\n    Band = ifelse(as.numeric(Year) &lt; 1998, \"Sepultura Max\", \"Sepultura No Max\"),\n  )\n\n  \n  soulfly &lt;- create_tibble(\"Soulfly\", \"1998\", c(rep(1,8), rep(2, 9), rep(3, 4), rep(4, 16), rep(5, 89)))\n  primitive &lt;- create_tibble(\"Primitive\", \"2000\", c(rep(1,11), rep(2, 5), rep(3, 5), rep(4, 19), rep(5, 53)))\n  three &lt;- create_tibble(\"Three\", \"2002\",c(rep(1,1), rep(2, 10), rep(3, 12), rep(4, 7), rep(5, 19)))\n  prophecy &lt;- create_tibble(\"Prophecy\", \"2004\",c(rep(1,2), rep(2, 5), rep(3, 5), rep(4, 25), rep(5, 42)))\n  darkages &lt;- create_tibble(\"Dark Ages\", \"2005\",c(rep(1,1), rep(2, 1), rep(3, 5), rep(4, 18), rep(5, 36)))\n  conquer &lt;- create_tibble(\"Conquer\", \"2008\",c(rep(1,1), rep(2, 0), rep(3, 5), rep(4, 5), rep(5, 31)))\n  omen &lt;- create_tibble(\"Omen\", \"2010\",c(rep(1,0), rep(2, 2), rep(3, 1), rep(4, 6), rep(5, 17)))\n  enslaved &lt;- create_tibble(\"Enslaved\", \"2012\",c(rep(1,1), rep(2,1), rep(3, 4), rep(4, 2), rep(5, 30)))\n  savages &lt;- create_tibble(\"Savages\", \"2013\",c(rep(1,0), rep(2, 2), rep(3, 3), rep(4, 10), rep(5, 27)))\n  archangel &lt;- create_tibble(\"Archangel\", \"2015\",c(rep(1,3), rep(2, 2), rep(3, 4), rep(4, 7), rep(5, 21)))\n\n\n  soulfly &lt;- rbind(soulfly, primitive, three, prophecy, darkages, conquer, omen, enslaved, savages, archangel) |&gt; \n    dplyr::mutate(\n      Band = \"Soulfly\"\n  )\n  \nmaxvsnomax &lt;- dplyr::bind_rows(sepultura, soulfly) |&gt; \n    dplyr::mutate(\n      Band = forcats::as_factor(Band),\n      Album = forcats::as_factor(Album),\n    )\n\n# create data that excludes data fro Max's period in sepultura\npostmax &lt;- maxvsnomax |&gt; \n  filter(Band != \"Sepultura Max\")"
  },
  {
    "objectID": "posts/2016_03_29_sepultura/index.html#post-sepultura-max-or-no-max",
    "href": "posts/2016_03_29_sepultura/index.html#post-sepultura-max-or-no-max",
    "title": "Max or No Max?",
    "section": "Post Sepultura: Max or No Max",
    "text": "Post Sepultura: Max or No Max\nThe first question is whether post-max Sepultura or Soulfly are rated higher. Let’s create some plots.\n\nCodeggplot(postmax, aes(x = Rating, fill = Band, colour = Band)) +\n  geom_histogram(binwidth = 1, alpha = 0.7) +\n  facet_wrap(~Band) +\n  theme_minimal()\n\n\n\n\n\n\nFigure 1: Histograms of all ratings for Soulfly and (Non-Max Era) Sepultura\n\n\n\n\n\nCodeggplot(postmax, aes(x = Year, y = Rating, colour = Band)) +\n  stat_summary(fun.data = \"mean_cl_normal\", geom = \"pointrange\") +\n  stat_summary(fun = \"mean\", geom = \"line\", aes(group = Band)) +\n  coord_cartesian(ylim = c(1, 5)) +\n  theme_minimal()\n\n\n\n\n\n\nFigure 2: Mean ratings of Soulfly and (Non-Max Era) Sepultura by year of album release\n\n\n\n\nFigure 1 shows that the data are hideously skewed with people tending to give positive reviews and 4-5* ratings. @fig_means shows the mean ratings by year post Max’s departure (note they released albums in different years so the dots are out of synch, but it’s a useful timeline). @fig_means seems to suggest that after the first couple of albums, both bands are rated fairly similarly: the Soulfly line is higher but error bars overlap a lot for all but the first albums.\nThere are a lot of ways you could look at these data. The first thing is the skew. That messes up estimates of confidence intervals and significance tests … but our sample is likely big enough that we can rely on the central limit theorem to do its magic and let us assume that the sampling distribution is normal (beautifully explained in my new book!)\nI’m going to fit three models. The first is an intercept only model (a baseline with no predictors), the second allows intercepts to vary across albums (which allows ratings to vary by album, which seems like a sensible thing to do because albums will vary in quality) the third predicts ratings from the band (Sepultura vs Soulfly).\n\nCodelibrary(nlme)\nmax_mod &lt;- gls(Rating ~ 1, data = postmax, method = \"ML\")\nmax_ri &lt;- lme(Rating ~ 1, random = ~1|Album, data = postmax, method = \"ML\")\nmax_band &lt;- update(max_ri, .~. + Band)\nanova(max_mod, max_ri, max_band)\n\n         Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nmax_mod      1  2 2889.412 2899.013 -1442.706                        \nmax_ri       2  3 2853.747 2868.148 -1423.873 1 vs 2 37.66536  &lt;.0001\nmax_band     3  4 2854.309 2873.510 -1423.155 2 vs 3  1.43806  0.2305\n\n\nBy comparing models we can see that album ratings varied very significantly (not surprising), the p-value is &lt; .0001, but that band did not significantly predict ratings overall (p = .231). If you like you can look at the summary of the model\n\nCodesummary(max_band)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: postmax \n       AIC     BIC    logLik\n  2854.309 2873.51 -1423.154\n\nRandom effects:\n Formula: ~1 | Album\n        (Intercept) Residual\nStdDev:   0.2705842 1.166457\n\nFixed effects:  Rating ~ Band \n               Value Std.Error  DF   t-value p-value\n(Intercept) 4.078740 0.1311196 882 31.107015  0.0000\nBandSoulfly 0.204237 0.1650047  14  1.237765  0.2362\n Correlation: \n            (Intr)\nBandSoulfly -0.795\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.9717684 -0.3367275  0.4998698  0.6230082  1.2686186 \n\nNumber of Observations: 898\nNumber of Groups: 16 \n\n\nThe difference in ratings between Sepultura and Soulfly was b = 0.20. Ratings for soulfully were higher, but not significantly so (if we allow ratings to vary over albums, if you take that random effect out you’ll get a very different picture because that variability will go into the fixed effect of ‘band’.)."
  },
  {
    "objectID": "posts/2016_03_29_sepultura/index.html#max-or-no-max",
    "href": "posts/2016_03_29_sepultura/index.html#max-or-no-max",
    "title": "Max or No Max?",
    "section": "Max or No Max",
    "text": "Max or No Max\nJust because this isn’t fun enough, we could also just look at whether either Sepultura (post 1996) or Soulfly can compete with the Max-era-Sepultura heyday. I’m going to fit three models but this time including the early Sepultura albums (with max). The models are the same as before except that the fixed effect of band now has three levels: Sepultura Max, Sepultura no-Max and Soulfly:\n\nCodemax_mod &lt;- gls(Rating ~ 1, data = maxvsnomax, method = \"ML\")\nmax_ri &lt;- lme(Rating ~ 1, random = ~1|Album, data = maxvsnomax, method = \"ML\")\nmax_band &lt;- update(max_ri, .~. + Band)\nanova(max_mod, max_ri, max_band)\n\n         Model df      AIC      BIC    logLik   Test   L.Ratio p-value\nmax_mod      1  2 4686.930 4697.601 -2341.465                         \nmax_ri       2  3 4583.966 4599.973 -2288.983 1 vs 2 104.96454  &lt;.0001\nmax_band     3  5 4581.436 4608.114 -2285.718 2 vs 3   6.52947  0.0382\n\n\nAlbum ratings varied very significantly (not surprising), the p-value is &lt; .0001, and the band did significantly predict ratings overall (p = .038). If you like you can look at the summary of the model\n\nCodesummary(max_band)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: maxvsnomax \n       AIC      BIC    logLik\n  4581.436 4608.114 -2285.718\n\nRandom effects:\n Formula: ~1 | Album\n        (Intercept) Residual\nStdDev:     0.25458 1.062036\n\nFixed effects:  Rating ~ Band \n                         Value Std.Error   DF  t-value p-value\n(Intercept)           4.545918 0.1136968 1512 39.98281  0.0000\nBandSepultura No Max -0.465626 0.1669412   19 -2.78916  0.0117\nBandSoulfly          -0.262609 0.1471749   19 -1.78433  0.0903\n Correlation: \n                     (Intr) BndSNM\nBandSepultura No Max -0.681       \nBandSoulfly          -0.773  0.526\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-3.3954974 -0.3147123  0.3708523  0.6268751  1.3987442 \n\nNumber of Observations: 1534\nNumber of Groups: 22 \n\n\nThe difference in ratings between Sepultura without Max compared to with him was b = -0.47 and significant at p = .012 (ratings for post-max Sepultura are significantly worse than for the Max-era Sepultura). The difference in ratings between Soulfly compared two Max-era Sepultura was b = -0.26 and not significant (p = .09) (ratings for Soulfly are not significantly worse than for the Max-era Sepultura). A couple of points here, p-values are silly, so don’t read too much into them, but the parameter (the bs) which quantifies the effect is a bit smaller for Soulfly."
  },
  {
    "objectID": "posts/2016_03_29_sepultura/index.html#confidence-intervals",
    "href": "posts/2016_03_29_sepultura/index.html#confidence-intervals",
    "title": "Max or No Max?",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nInterestingly if you write yourself a little bootstrap routine to get some robust confidence intervals around the parameters:\n\nCodelibrary(boot)\n\nboot_lme &lt;- function(data, indices){\n    data &lt;- data[indices,] # select obs. in bootstrap sample\n    model &lt;- lme(Rating ~ Band, random = ~1|Album, data = data, method = \"ML\")\n    fixef(model) # return coefficient vector\n}\n\nmax_boot &lt;- boot(maxvsnomax, boot_lme, 1000)\nmax_boot\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = maxvsnomax, statistic = boot_lme, R = 1000)\n\n\nBootstrap Statistics :\n      original       bias    std. error\nt1*  4.5459183 -0.001065884  0.03882691\nt2* -0.4656258  0.008973167  0.08060762\nt3* -0.2626088  0.001218160  0.06088377\n\nCodeboot.ci(max_boot, index = 1, type = \"perc\")\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = max_boot, type = \"perc\", index = 1)\n\nIntervals : \nLevel     Percentile     \n95%   ( 4.467,  4.615 )  \nCalculations and Intervals on Original Scale\n\nCodeboot.ci(max_boot, index = 2, type = \"perc\")\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = max_boot, type = \"perc\", index = 2)\n\nIntervals : \nLevel     Percentile     \n95%   (-0.6227, -0.2951 )  \nCalculations and Intervals on Original Scale\n\nCodeboot.ci(max_boot, index = 3, type = \"perc\")\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = max_boot, type = \"perc\", index = 3)\n\nIntervals : \nLevel     Percentile     \n95%   (-0.3816, -0.1429 )  \nCalculations and Intervals on Original Scale\n\n\nThe difference in ratings between Sepultura without Max compared to with him was b = -0.47 [-0.62, -0.31]. The difference in ratings between Soulfly compared to Max-era Sepultura was b = -0.26 [-0.39, -0.15].1 This suggests that both soulfully and post-Max Sepultura yield negative parameters that reflect (to the degree that you believe that a confidence interval tells you about the population parameter…) a negative effect in the population. In other words, both bands are rated worse than Max-era Sepultura.\n1 These figures might differ slightly from the output because each time I generate the blog the bootstrap will re-run and results change slightly. I can’t be bothered to write inline code to update the values: they’ll be roughly the same."
  },
  {
    "objectID": "posts/2016_03_29_sepultura/index.html#summary",
    "href": "posts/2016_03_29_sepultura/index.html#summary",
    "title": "Max or No Max?",
    "section": "Summary",
    "text": "Summary\nLook, this is just a bit of fun and an excuse to show you how to use a bootstrap on a multilevel model, and how you can use data to try to answer pointless questions thrown at you on Twitter. Based on this hastily thrown together analysis that makes a lot of assumptions about a lot of things, my 120 character twitter response will be: Sepultura Max better than everything, but post 1996 Max is no better than No Max;-)"
  }
]